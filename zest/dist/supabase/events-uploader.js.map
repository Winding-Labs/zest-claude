{
  "version": 3,
  "sources": ["..\\src\\auth\\session-manager.ts", "..\\src\\config\\constants.ts", "..\\src\\utils\\logger.ts", "..\\src\\utils\\queue-manager.ts", "..\\src\\supabase\\events-uploader.ts"],
  "sourcesContent": [
    "/**\r\n * Session management\r\n *\r\n * Handles session persistence, validation, and token refresh\r\n */\r\n\r\nimport { mkdir, readFile, unlink, writeFile } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport { PROACTIVE_REFRESH_THRESHOLD_MS, SESSION_FILE, WEB_APP_URL } from \"../config/constants.js\";\r\nimport { logger } from \"../utils/logger.js\";\r\n\r\nexport interface AuthSession {\r\n  accessToken: string;\r\n  refreshToken: string;\r\n  expiresAt: number; // Access token expiration (milliseconds)\r\n  refreshTokenExpiresAt?: number; // Refresh token expiration (milliseconds) - optional for backward compatibility\r\n  userId: string;\r\n  email: string;\r\n  workspaceId?: string;\r\n  workspaceName?: string;\r\n}\r\n\r\n/**\r\n * Load session from file\r\n */\r\nexport async function loadSession(): Promise<AuthSession | null> {\r\n  try {\r\n    const content = await readFile(SESSION_FILE, \"utf-8\");\r\n    const session = JSON.parse(content) as AuthSession;\r\n\r\n    // Validate session structure\r\n    if (\r\n      !session.accessToken ||\r\n      !session.refreshToken ||\r\n      !session.expiresAt ||\r\n      !session.userId ||\r\n      !session.email\r\n    ) {\r\n      logger.warn(\"Invalid session structure, clearing session\");\r\n      await clearSession();\r\n      return null;\r\n    }\r\n\r\n    const now = Date.now();\r\n\r\n    // Check if refresh token is expired (only if expiration is set - many configs have refresh tokens that never expire)\r\n    if (session.refreshTokenExpiresAt && session.refreshTokenExpiresAt < now) {\r\n      logger.warn(\"Refresh token expired, user must re-authenticate\");\r\n      await clearSession();\r\n      return null;\r\n    }\r\n\r\n    // Check if access token is expired\r\n    if (session.expiresAt < now) {\r\n      logger.debug(\"Access token expired, attempting refresh\");\r\n      try {\r\n        return await refreshSession(session);\r\n      } catch (error) {\r\n        logger.warn(\"Failed to refresh session\", error);\r\n        await clearSession();\r\n        return null;\r\n      }\r\n    }\r\n\r\n    return session;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist - not an error\r\n      return null;\r\n    }\r\n    logger.error(\"Failed to load session\", error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Save session to file with secure permissions\r\n */\r\nexport async function saveSession(session: AuthSession): Promise<void> {\r\n  try {\r\n    // Ensure directory exists\r\n    await mkdir(dirname(SESSION_FILE), { recursive: true, mode: 0o700 });\r\n\r\n    // Write session file\r\n    await writeFile(SESSION_FILE, JSON.stringify(session, null, 2), {\r\n      encoding: \"utf-8\",\r\n      mode: 0o600, // Readable/writable by owner only\r\n    });\r\n\r\n    logger.info(\"Session saved successfully\");\r\n  } catch (error) {\r\n    logger.error(\"Failed to save session\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Clear session file\r\n */\r\nexport async function clearSession(): Promise<void> {\r\n  try {\r\n    await unlink(SESSION_FILE);\r\n    logger.info(\"Session cleared successfully\");\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist - not an error\r\n      return;\r\n    }\r\n    logger.error(\"Failed to clear session\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Refresh an expired session using the refresh token\r\n */\r\nexport async function refreshSession(session: AuthSession): Promise<AuthSession> {\r\n  try {\r\n    logger.debug(\"Refreshing session\");\r\n\r\n    const response = await fetch(`${WEB_APP_URL}/api/auth/extension/refresh`, {\r\n      method: \"POST\",\r\n      headers: {\r\n        \"Content-Type\": \"application/json\",\r\n      },\r\n      body: JSON.stringify({\r\n        refreshToken: session.refreshToken,\r\n      }),\r\n    });\r\n\r\n    if (!response.ok) {\r\n      throw new Error(`Token refresh failed: ${response.status} ${response.statusText}`);\r\n    }\r\n\r\n    const data = (await response.json()) as {\r\n      accessToken: string;\r\n      refreshToken: string;\r\n      expiresIn: number; // seconds until access token expiration\r\n      refreshTokenExpiresIn?: number; // seconds until refresh token expiration\r\n    };\r\n\r\n    // Use actual expiration from Supabase (convert seconds to milliseconds)\r\n    const now = Date.now();\r\n    const expiresAt = now + data.expiresIn * 1000;\r\n\r\n    // Calculate refresh token expiration (if provided, otherwise keep existing or undefined for \"never expires\")\r\n    const refreshTokenExpiresAt = data.refreshTokenExpiresIn\r\n      ? now + data.refreshTokenExpiresIn * 1000\r\n      : session.refreshTokenExpiresAt; // Keep existing or undefined (never expires)\r\n\r\n    const newSession: AuthSession = {\r\n      ...session,\r\n      accessToken: data.accessToken,\r\n      refreshToken: data.refreshToken,\r\n      expiresAt,\r\n      refreshTokenExpiresAt,\r\n    };\r\n\r\n    logger.debug(\r\n      `Access token will expire in ${data.expiresIn} seconds (${new Date(expiresAt).toISOString()})`,\r\n    );\r\n    if (refreshTokenExpiresAt) {\r\n      logger.debug(`Refresh token will expire at ${new Date(refreshTokenExpiresAt).toISOString()}`);\r\n    } else {\r\n      logger.debug(\"Refresh token does not expire\");\r\n    }\r\n\r\n    await saveSession(newSession);\r\n    logger.info(\"Session refreshed successfully\");\r\n\r\n    return newSession;\r\n  } catch (error) {\r\n    logger.error(\"Failed to refresh session\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Check if user is currently authenticated\r\n */\r\nexport async function isAuthenticated(): Promise<boolean> {\r\n  const session = await loadSession();\r\n  return session !== null && session.expiresAt > Date.now();\r\n}\r\n\r\n/**\r\n * Get current session (refresh if needed)\r\n *\r\n * Proactively refreshes tokens 5 minutes before expiration\r\n */\r\nexport async function getValidSession(): Promise<AuthSession | null> {\r\n  const session = await loadSession();\r\n  if (!session) {\r\n    return null;\r\n  }\r\n\r\n  const now = Date.now();\r\n  const timeUntilExpiration = session.expiresAt - now;\r\n\r\n  // Refresh if expired or expiring soon (within 5 minutes)\r\n  if (timeUntilExpiration < PROACTIVE_REFRESH_THRESHOLD_MS) {\r\n    try {\r\n      logger.debug(\r\n        `Token ${timeUntilExpiration < 0 ? \"expired\" : `expiring in ${Math.round(timeUntilExpiration / 1000)}s`}, refreshing...`,\r\n      );\r\n      return await refreshSession(session);\r\n    } catch (error) {\r\n      logger.warn(\"Failed to refresh session\", error);\r\n      return null; // Can't use expired/expiring session\r\n    }\r\n  }\r\n\r\n  return session;\r\n}\r\n",
    "/**\r\n * Application constants and configuration values\r\n */\r\n\r\nimport { homedir } from \"node:os\";\r\nimport { join } from \"node:path\";\r\n\r\n// Base directories\r\nexport const CLAUDE_ZEST_DIR = join(\r\n  homedir(),\r\n  `.claude-zest${process.env.NODE_ENV === \"development\" ? \"-dev\" : \"\"}`,\r\n);\r\nexport const QUEUE_DIR = join(CLAUDE_ZEST_DIR, \"queue\");\r\nexport const LOGS_DIR = join(CLAUDE_ZEST_DIR, \"logs\");\r\nexport const STATE_DIR = join(CLAUDE_ZEST_DIR, \"state\");\r\nexport const DELETION_CACHE_DIR = join(CLAUDE_ZEST_DIR, \"cache\", \"deletions\");\r\n\r\n// File paths\r\nexport const SESSION_FILE = join(CLAUDE_ZEST_DIR, \"session.json\"); // Auth session + workspace info\r\nexport const SETTINGS_FILE = join(CLAUDE_ZEST_DIR, \"settings.json\"); // User preferences\r\nexport const LOG_FILE = join(LOGS_DIR, \"plugin.log\");\r\nexport const SYNC_LOG_FILE = join(LOGS_DIR, \"sync.log\");\r\nexport const DAEMON_PID_FILE = join(CLAUDE_ZEST_DIR, \"daemon.pid\");\r\n\r\n// Queue files\r\nexport const EVENTS_QUEUE_FILE = join(QUEUE_DIR, \"events.jsonl\");\r\nexport const SESSIONS_QUEUE_FILE = join(QUEUE_DIR, \"chat-sessions.jsonl\");\r\nexport const MESSAGES_QUEUE_FILE = join(QUEUE_DIR, \"chat-messages.jsonl\");\r\n\r\n// Platform and source identifiers\r\nexport const PLATFORM = \"terminal\";\r\nexport const SOURCE = \"claude-code\";\r\nexport const CLIENT_ID = \"claude-cli\";\r\n\r\n// Sync configuration\r\nexport const SYNC_INTERVAL_MS = 60000; // 60 seconds\r\nexport const MAX_RETRY_ATTEMPTS = 3;\r\nexport const RETRY_BACKOFF_MS = 5000;\r\n\r\n// Cache configuration\r\nexport const DELETION_CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes\r\n\r\n// Authentication configuration\r\nexport const PROACTIVE_REFRESH_THRESHOLD_MS = 5 * 60 * 1000; // Refresh tokens 5 minutes before expiration\r\n\r\n// Content size limits\r\nexport const MAX_DIFF_SIZE_BYTES = 10 * 1024 * 1024; // 10MB\r\nexport const MAX_CONTENT_PREVIEW_LENGTH = 1000; // characters\r\nexport const MAX_SESSION_TITLE_LENGTH = 100; // characters\r\nexport const MIN_SESSION_TITLE_LENGTH = 3; // characters\r\n\r\n// Session quality filters\r\nexport const MIN_MESSAGES_PER_SESSION = 3; // Minimum messages required to upload a session\r\nexport const STALE_SESSION_AGE_MS = 7 * 24 * 60 * 60 * 1000; // 7 days in milliseconds\r\n\r\n// API endpoints (configured from .env at build time)\r\n// Values are baked into the bundle during build\r\nexport const WEB_APP_URL = process.env.ZEST_WEB_APP_URL || \"http://localhost:3000\";\r\nexport const SUPABASE_URL = process.env.ZEST_SUPABASE_URL || \"\";\r\nexport const SUPABASE_ANON_KEY = process.env.ZEST_SUPABASE_ANON_KEY || \"\";\r\n\r\n// Claude project directories\r\nexport const CLAUDE_PROJECTS_DIR = join(homedir(), \".claude\", \"projects\");\r\n\r\n// Filter patterns for commands/messages to exclude from tracking\r\nexport const EXCLUDED_COMMAND_PATTERNS = [\r\n  // Claude Code built-in commands\r\n  /^\\/(add-dir|agents|bashes|bug|clear|compact|config|context|cost|doctor|exit|export|help|hooks|ide|init|install-github-app|login|logout|mcp|memory|model|output-style|permissions|plugin|pr-comments|privacy-settings|release-notes|resume|review|rewind|sandbox|security-review|stats|status|statusline|terminal-setup|todos|usage|vim)\\b/i,\r\n\r\n  // Zest plugin commands (like /zest:status, /zest-dev:status, etc.)\r\n  /^\\/zest[^:\\s]*:/i,\r\n\r\n  // Messages containing Zest command tags (e.g., <command-name>/zest-dev:status</command-name>)\r\n  /<command-name>\\/zest[^<]*<\\/command-name>/i,\r\n\r\n  // Messages containing Zest CLI script paths (e.g., \"node .../dist/commands/sync-cli.js\")\r\n  /node\\s+.*\\/dist\\/commands\\/.*-cli\\.js/i,\r\n];\r\n",
    "/**\r\n * Logging utilities\r\n *\r\n * Handles logging to console and file system\r\n */\r\n\r\nimport { appendFile, mkdir } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport { LOG_FILE } from \"../config/constants.js\";\r\n\r\ntype LogLevel = \"debug\" | \"info\" | \"warn\" | \"error\";\r\n\r\nclass Logger {\r\n  private minLevel: LogLevel = \"info\";\r\n\r\n  private levels: Record<LogLevel, number> = {\r\n    debug: 0,\r\n    info: 1,\r\n    warn: 2,\r\n    error: 3,\r\n  };\r\n\r\n  setLevel(level: LogLevel): void {\r\n    this.minLevel = level;\r\n  }\r\n\r\n  private async writeToFile(message: string): Promise<void> {\r\n    try {\r\n      await mkdir(dirname(LOG_FILE), { recursive: true });\r\n      const timestamp = new Date().toISOString();\r\n      await appendFile(LOG_FILE, `[${timestamp}] ${message}\\n`, \"utf-8\");\r\n    } catch (error) {\r\n      // Silently fail - don't crash if we can't write logs\r\n      console.error(\"Failed to write to log file:\", error);\r\n    }\r\n  }\r\n\r\n  private shouldLog(level: LogLevel): boolean {\r\n    return this.levels[level] >= this.levels[this.minLevel];\r\n  }\r\n\r\n  debug(message: string, ...args: unknown[]): void {\r\n    if (this.shouldLog(\"debug\")) {\r\n      // Only write to file, don't clutter console\r\n      this.writeToFile(`DEBUG: ${message} ${args.length > 0 ? JSON.stringify(args) : \"\"}`);\r\n    }\r\n  }\r\n\r\n  info(message: string, ...args: unknown[]): void {\r\n    if (this.shouldLog(\"info\")) {\r\n      // Only write to file, don't clutter console\r\n      this.writeToFile(`INFO: ${message} ${args.length > 0 ? JSON.stringify(args) : \"\"}`);\r\n    }\r\n  }\r\n\r\n  warn(message: string, ...args: unknown[]): void {\r\n    if (this.shouldLog(\"warn\")) {\r\n      // Show warnings to user\r\n      console.warn(`[Zest:Warn] ${message}`, ...args);\r\n      this.writeToFile(`WARN: ${message} ${args.length > 0 ? JSON.stringify(args) : \"\"}`);\r\n    }\r\n  }\r\n\r\n  error(message: string, error?: unknown): void {\r\n    if (this.shouldLog(\"error\")) {\r\n      // Show errors to user\r\n      console.error(`[Zest:Error] ${message}`, error);\r\n      this.writeToFile(\r\n        `ERROR: ${message} ${error instanceof Error ? error.stack : JSON.stringify(error)}`,\r\n      );\r\n    }\r\n  }\r\n}\r\n\r\nexport const logger = new Logger();\r\n",
    "/**\r\n * Local queue management for data persistence\r\n *\r\n * Manages JSONL queue files for events, sessions, and messages\r\n * Provides file locking to prevent corruption during concurrent writes\r\n */\r\n\r\nimport { appendFile, mkdir, readFile, stat, unlink, writeFile } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport {\r\n  EVENTS_QUEUE_FILE,\r\n  MESSAGES_QUEUE_FILE,\r\n  QUEUE_DIR,\r\n  SESSIONS_QUEUE_FILE,\r\n} from \"../config/constants.js\";\r\nimport type {\r\n  ClaudeExtractedEvent,\r\n  ClaudeExtractedMessage,\r\n  ClaudeExtractedSession,\r\n} from \"../types/index.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n// Simple file-based locking mechanism\r\nconst locks = new Map<string, Promise<void>>();\r\n\r\n/**\r\n * Acquire a lock for a file to prevent concurrent writes\r\n */\r\nasync function withLock<T>(filePath: string, fn: () => Promise<T>): Promise<T> {\r\n  // Wait for existing lock if present\r\n  while (locks.has(filePath)) {\r\n    await locks.get(filePath);\r\n  }\r\n\r\n  // Create new lock\r\n  let releaseLock: () => void;\r\n  const lockPromise = new Promise<void>((resolve) => {\r\n    releaseLock = resolve;\r\n  });\r\n  locks.set(filePath, lockPromise);\r\n\r\n  try {\r\n    return await fn();\r\n  } finally {\r\n    // Release lock\r\n    locks.delete(filePath);\r\n    releaseLock!();\r\n  }\r\n}\r\n\r\n/**\r\n * Ensure directory exists, creating it if necessary\r\n */\r\nasync function ensureDirectory(dirPath: string): Promise<void> {\r\n  try {\r\n    await stat(dirPath);\r\n  } catch {\r\n    await mkdir(dirPath, { recursive: true, mode: 0o700 });\r\n    logger.debug(`Created directory: ${dirPath}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Read all entries from a JSONL file\r\n */\r\nasync function readJsonl<T>(filePath: string): Promise<T[]> {\r\n  try {\r\n    const content = await readFile(filePath, \"utf8\");\r\n    const lines = content.trim().split(\"\\n\").filter(Boolean);\r\n\r\n    const results: T[] = [];\r\n    for (let i = 0; i < lines.length; i++) {\r\n      try {\r\n        results.push(JSON.parse(lines[i]));\r\n      } catch (error) {\r\n        logger.warn(`Failed to parse line ${i + 1} in ${filePath}:`, error);\r\n        // Continue processing other lines\r\n      }\r\n    }\r\n\r\n    return results;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist yet, return empty array\r\n      return [];\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Count lines in a JSONL file\r\n */\r\nasync function countLines(filePath: string): Promise<number> {\r\n  try {\r\n    const content = await readFile(filePath, \"utf8\");\r\n    const lines = content.trim().split(\"\\n\").filter(Boolean);\r\n    return lines.length;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      return 0;\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Delete a file (clear queue)\r\n */\r\nasync function deleteFile(filePath: string): Promise<void> {\r\n  try {\r\n    await unlink(filePath);\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist, nothing to delete\r\n      return;\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Public API\r\n// ============================================================================\r\n\r\n/**\r\n * Enqueue a code digest event extracted from Claude Code CLI\r\n * Skips events that are already in the queue (deduplication)\r\n */\r\nexport async function enqueueEvent(event: ClaudeExtractedEvent): Promise<void> {\r\n  try {\r\n    // Use lock to ensure atomicity of read-check-write\r\n    await withLock(EVENTS_QUEUE_FILE, async () => {\r\n      // Check if event already exists (inside lock to prevent race conditions)\r\n      const existingEvents = await readJsonl<ClaudeExtractedEvent>(EVENTS_QUEUE_FILE);\r\n      const isDuplicate = existingEvents.some((evt) => evt.id === event.id);\r\n\r\n      if (isDuplicate) {\r\n        logger.debug(\"Skipping duplicate event\", {\r\n          eventId: event.id,\r\n          documentUri: event.document_uri,\r\n        });\r\n        return;\r\n      }\r\n\r\n      // Ensure directory exists\r\n      await ensureDirectory(dirname(EVENTS_QUEUE_FILE));\r\n\r\n      // Append JSON line\r\n      const line = JSON.stringify(event) + \"\\n\";\r\n      await appendFile(EVENTS_QUEUE_FILE, line, \"utf8\");\r\n\r\n      logger.debug(\"Enqueued event\", { eventId: event.id, documentUri: event.document_uri });\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to enqueue event:\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Enqueue a chat session extracted from Claude Code CLI\r\n * Skips sessions that are already in the queue (deduplication)\r\n */\r\nexport async function enqueueChatSession(session: ClaudeExtractedSession): Promise<void> {\r\n  try {\r\n    // Use lock to ensure atomicity of read-check-write\r\n    await withLock(SESSIONS_QUEUE_FILE, async () => {\r\n      // Check if session already exists (inside lock to prevent race conditions)\r\n      const existingSessions = await readJsonl<ClaudeExtractedSession>(SESSIONS_QUEUE_FILE);\r\n      const isDuplicate = existingSessions.some((sess) => sess.id === session.id);\r\n\r\n      if (isDuplicate) {\r\n        logger.debug(\"Skipping duplicate session\", { sessionId: session.id });\r\n        return;\r\n      }\r\n\r\n      // Ensure directory exists\r\n      await ensureDirectory(dirname(SESSIONS_QUEUE_FILE));\r\n\r\n      // Append JSON line\r\n      const line = JSON.stringify(session) + \"\\n\";\r\n      await appendFile(SESSIONS_QUEUE_FILE, line, \"utf8\");\r\n\r\n      logger.debug(\"Enqueued session\", { sessionId: session.id });\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to enqueue session:\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Enqueue a chat message extracted from Claude Code CLI\r\n * Skips messages that are already in the queue (deduplication)\r\n */\r\nexport async function enqueueChatMessage(message: ClaudeExtractedMessage): Promise<void> {\r\n  try {\r\n    // Use lock to ensure atomicity of read-check-write\r\n    await withLock(MESSAGES_QUEUE_FILE, async () => {\r\n      // Check if message already exists (inside lock to prevent race conditions)\r\n      const existingMessages = await readJsonl<ClaudeExtractedMessage>(MESSAGES_QUEUE_FILE);\r\n      const isDuplicate = existingMessages.some((msg) => msg.id === message.id);\r\n\r\n      if (isDuplicate) {\r\n        logger.debug(\"Skipping duplicate message\", {\r\n          messageId: message.id,\r\n          sessionId: message.session_id,\r\n          messageIndex: message.message_index,\r\n        });\r\n        return;\r\n      }\r\n\r\n      // Ensure directory exists\r\n      await ensureDirectory(dirname(MESSAGES_QUEUE_FILE));\r\n\r\n      // Append JSON line\r\n      const line = JSON.stringify(message) + \"\\n\";\r\n      await appendFile(MESSAGES_QUEUE_FILE, line, \"utf8\");\r\n\r\n      logger.debug(\"Enqueued message\", {\r\n        sessionId: message.session_id,\r\n        messageIndex: message.message_index,\r\n      });\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to enqueue message:\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Read all entries from a queue file\r\n */\r\nexport async function readQueue<T>(queueFile: string): Promise<T[]> {\r\n  try {\r\n    return await readJsonl<T>(queueFile);\r\n  } catch (error) {\r\n    logger.error(`Failed to read queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Write entries to a queue file (overwrites existing content)\r\n */\r\nexport async function writeQueue<T>(queueFile: string, items: T[]): Promise<void> {\r\n  try {\r\n    await withLock(queueFile, async () => {\r\n      await ensureDirectory(dirname(queueFile));\r\n\r\n      // Write all items as JSONL\r\n      const content =\r\n        items.map((item) => JSON.stringify(item)).join(\"\\n\") + (items.length > 0 ? \"\\n\" : \"\");\r\n      await writeFile(queueFile, content, \"utf8\");\r\n\r\n      logger.debug(`Wrote ${items.length} items to queue file: ${queueFile}`);\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to write queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Atomically update queue files with a transform function\r\n * Ensures no race condition between read and write\r\n *\r\n * The entire read-modify-write cycle happens inside a lock\r\n */\r\nexport async function atomicUpdateQueue<T>(\r\n  queueFile: string,\r\n  transform: (currentItems: T[]) => T[],\r\n): Promise<void> {\r\n  try {\r\n    await withLock(queueFile, async () => {\r\n      // Read current state (inside lock)\r\n      const currentItems = await readJsonl<T>(queueFile);\r\n\r\n      // Apply transformation\r\n      const newItems = transform(currentItems);\r\n\r\n      // Write back (still inside lock)\r\n      await ensureDirectory(dirname(queueFile));\r\n      const content =\r\n        newItems.map((item) => JSON.stringify(item)).join(\"\\n\") + (newItems.length > 0 ? \"\\n\" : \"\");\r\n      await writeFile(queueFile, content, \"utf8\");\r\n\r\n      logger.debug(\r\n        `Atomically updated queue file: ${queueFile} (${currentItems.length} → ${newItems.length} items)`,\r\n      );\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to atomically update queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Clear a queue file (delete it)\r\n */\r\nexport async function clearQueue(queueFile: string): Promise<void> {\r\n  try {\r\n    await withLock(queueFile, async () => {\r\n      await deleteFile(queueFile);\r\n      logger.debug(`Cleared queue file: ${queueFile}`);\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to clear queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Get statistics about queued items\r\n */\r\nexport async function getQueueStats(): Promise<{\r\n  events: number;\r\n  sessions: number;\r\n  messages: number;\r\n}> {\r\n  try {\r\n    const [events, sessions, messages] = await Promise.all([\r\n      countLines(EVENTS_QUEUE_FILE),\r\n      countLines(SESSIONS_QUEUE_FILE),\r\n      countLines(MESSAGES_QUEUE_FILE),\r\n    ]);\r\n\r\n    return { events, sessions, messages };\r\n  } catch (error) {\r\n    logger.error(\"Failed to get queue stats:\", error);\r\n    return { events: 0, sessions: 0, messages: 0 };\r\n  }\r\n}\r\n\r\n/**\r\n * Ensure queue directory exists (call on initialization)\r\n */\r\nexport async function initializeQueue(): Promise<void> {\r\n  try {\r\n    await ensureDirectory(QUEUE_DIR);\r\n    logger.debug(\"Queue directory initialized\");\r\n  } catch (error) {\r\n    logger.error(\"Failed to initialize queue directory:\", error);\r\n    throw error;\r\n  }\r\n}\r\n",
    "/**\r\n * Events uploader\r\n *\r\n * Uploads code digest events from queue to Supabase\r\n */\r\n\r\nimport type { SupabaseClient } from \"@supabase/supabase-js\";\r\nimport type { Database } from \"@zest/types/database.types\";\r\nimport { getValidSession } from \"../auth/session-manager.js\";\r\nimport { EVENTS_QUEUE_FILE, PLATFORM, SOURCE } from \"../config/constants.js\";\r\nimport type { ClaudeExtractedEvent, CodeDigestEventInsert } from \"../types/index.js\";\r\nimport { logger } from \"../utils/logger.js\";\r\nimport { clearQueue, readQueue } from \"../utils/queue-manager.js\";\r\n\r\n/**\r\n * Deduplicate events by ID, keeping the most recent version\r\n */\r\nfunction deduplicateEvents(events: ClaudeExtractedEvent[]): ClaudeExtractedEvent[] {\r\n  const eventMap = new Map<string, ClaudeExtractedEvent>();\r\n\r\n  for (const event of events) {\r\n    if (!event.id) continue;\r\n\r\n    const existing = eventMap.get(event.id);\r\n    if (!existing) {\r\n      eventMap.set(event.id, event);\r\n      continue;\r\n    }\r\n\r\n    // Keep the event with the most recent timestamp\r\n    const existingTime = existing.timestamp ? new Date(existing.timestamp).getTime() : 0;\r\n    const currentTime = event.timestamp ? new Date(event.timestamp).getTime() : 0;\r\n\r\n    if (currentTime >= existingTime) {\r\n      eventMap.set(event.id, event);\r\n    }\r\n  }\r\n\r\n  return Array.from(eventMap.values());\r\n}\r\n\r\n/**\r\n * Upload all queued code digest events to Supabase\r\n */\r\nexport async function uploadEvents(\r\n  supabase: SupabaseClient<Database>,\r\n): Promise<{ success: boolean; uploaded: number }> {\r\n  try {\r\n    const session = await getValidSession();\r\n    if (!session) {\r\n      logger.debug(\"Not authenticated, skipping events upload\");\r\n      return { success: false, uploaded: 0 };\r\n    }\r\n\r\n    // Read queued events\r\n    const queuedEvents = await readQueue<ClaudeExtractedEvent>(EVENTS_QUEUE_FILE);\r\n\r\n    if (queuedEvents.length === 0) {\r\n      logger.debug(\"No events to upload\");\r\n      return { success: true, uploaded: 0 };\r\n    }\r\n\r\n    // Deduplicate events (queue might contain duplicate entries from multiple extractions)\r\n    const uniqueEvents = deduplicateEvents(queuedEvents);\r\n\r\n    if (uniqueEvents.length < queuedEvents.length) {\r\n      logger.info(\r\n        `Deduplicated events: ${queuedEvents.length} → ${uniqueEvents.length} (removed ${queuedEvents.length - uniqueEvents.length} duplicates)`,\r\n      );\r\n    }\r\n\r\n    logger.info(`Uploading ${uniqueEvents.length} code digest events`);\r\n\r\n    // Transform extracted data to full insert data\r\n    const eventsToUpload: CodeDigestEventInsert[] = uniqueEvents.map((e) => ({\r\n      ...e,\r\n      event_type: \"file.changed\",\r\n      user_id: session.userId,\r\n      platform: PLATFORM,\r\n      source: SOURCE,\r\n    }));\r\n\r\n    // Upload events in batches\r\n    const batchSize = 100;\r\n    let uploadedCount = 0;\r\n\r\n    for (let i = 0; i < eventsToUpload.length; i += batchSize) {\r\n      const batch = eventsToUpload.slice(i, i + batchSize);\r\n\r\n      const { error } = await supabase\r\n        .from(\"code_digest_events\")\r\n        .upsert(batch, { onConflict: \"id\" });\r\n\r\n      if (error) {\r\n        logger.error(`Failed to upload events batch ${i / batchSize + 1}`, error);\r\n        return { success: false, uploaded: uploadedCount };\r\n      }\r\n\r\n      uploadedCount += batch.length;\r\n      logger.debug(`✓ Uploaded batch ${i / batchSize + 1} (${batch.length} events)`);\r\n    }\r\n\r\n    // Clear queue on success\r\n    await clearQueue(EVENTS_QUEUE_FILE);\r\n\r\n    logger.info(`✓ Events upload completed: ${uploadedCount} events`);\r\n    return { success: true, uploaded: uploadedCount };\r\n  } catch (error) {\r\n    logger.error(\"Failed to upload events\", error);\r\n    return { success: false, uploaded: 0 };\r\n  }\r\n}\r\n\r\n/**\r\n * Upload events with retry logic\r\n */\r\nexport async function uploadEventsWithRetry(\r\n  supabase: SupabaseClient<Database>,\r\n  maxRetries = 3,\r\n  backoffMs = 5000,\r\n): Promise<{ success: boolean; uploaded: number }> {\r\n  let lastError: Error | null = null;\r\n\r\n  for (let attempt = 1; attempt <= maxRetries; attempt++) {\r\n    try {\r\n      const result = await uploadEvents(supabase);\r\n      if (result.success) {\r\n        return result;\r\n      }\r\n\r\n      // If not successful but no exception thrown, don't retry (likely auth issue)\r\n      return result;\r\n    } catch (error) {\r\n      lastError = error as Error;\r\n      logger.warn(`Events upload attempt ${attempt}/${maxRetries} failed: ${lastError.message}`);\r\n\r\n      if (attempt < maxRetries) {\r\n        const delay = backoffMs * attempt; // Exponential backoff\r\n        logger.debug(`Retrying in ${delay}ms...`);\r\n        await new Promise((resolve) => setTimeout(resolve, delay));\r\n      }\r\n    }\r\n  }\r\n\r\n  logger.error(`Events upload failed after ${maxRetries} attempts`, lastError);\r\n  return { success: false, uploaded: 0 };\r\n}\r\n"
  ],
  "mappings": ";AAMA,kBAAS;AACT,oBAAS;;;ACHT;AACA;AAGO,IAAM,kBAAkB,KAC7B,QAAQ,GACR,eAAwD,QAC1D;AACO,IAAM,YAAY,KAAK,iBAAiB,OAAO;AAC/C,IAAM,WAAW,KAAK,iBAAiB,MAAM;AAC7C,IAAM,YAAY,KAAK,iBAAiB,OAAO;AAC/C,IAAM,qBAAqB,KAAK,iBAAiB,SAAS,WAAW;AAGrE,IAAM,eAAe,KAAK,iBAAiB,cAAc;AACzD,IAAM,gBAAgB,KAAK,iBAAiB,eAAe;AAC3D,IAAM,WAAW,KAAK,UAAU,YAAY;AAC5C,IAAM,gBAAgB,KAAK,UAAU,UAAU;AAC/C,IAAM,kBAAkB,KAAK,iBAAiB,YAAY;AAG1D,IAAM,oBAAoB,KAAK,WAAW,cAAc;AACxD,IAAM,sBAAsB,KAAK,WAAW,qBAAqB;AACjE,IAAM,sBAAsB,KAAK,WAAW,qBAAqB;AAGjE,IAAM,WAAW;AACjB,IAAM,SAAS;AASf,IAAM,wBAAwB,IAAI,KAAK;AAGvC,IAAM,iCAAiC,IAAI,KAAK;AAGhD,IAAM,sBAAsB,KAAK,OAAO;AAOxC,IAAM,uBAAuB,IAAI,KAAK,KAAK,KAAK;AAIhD,IAAM,cAAc;AAKpB,IAAM,sBAAsB,KAAK,QAAQ,GAAG,WAAW,UAAU;;;ACxDxE;AACA;AAKA,MAAM,OAAO;AAAA,EACH,WAAqB;AAAA,EAErB,SAAmC;AAAA,IACzC,OAAO;AAAA,IACP,MAAM;AAAA,IACN,MAAM;AAAA,IACN,OAAO;AAAA,EACT;AAAA,EAEA,QAAQ,CAAC,OAAuB;AAAA,IAC9B,KAAK,WAAW;AAAA;AAAA,OAGJ,YAAW,CAAC,SAAgC;AAAA,IACxD,IAAI;AAAA,MACF,MAAM,MAAM,QAAQ,QAAQ,GAAG,EAAE,WAAW,KAAK,CAAC;AAAA,MAClD,MAAM,YAAY,IAAI,KAAK,EAAE,YAAY;AAAA,MACzC,MAAM,WAAW,UAAU,IAAI,cAAc;AAAA,GAAa,OAAO;AAAA,MACjE,OAAO,OAAO;AAAA,MAEd,QAAQ,MAAM,gCAAgC,KAAK;AAAA;AAAA;AAAA,EAI/C,SAAS,CAAC,OAA0B;AAAA,IAC1C,OAAO,KAAK,OAAO,UAAU,KAAK,OAAO,KAAK;AAAA;AAAA,EAGhD,KAAK,CAAC,YAAoB,MAAuB;AAAA,IAC/C,IAAI,KAAK,UAAU,OAAO,GAAG;AAAA,MAE3B,KAAK,YAAY,UAAU,WAAW,KAAK,SAAS,IAAI,KAAK,UAAU,IAAI,IAAI,IAAI;AAAA,IACrF;AAAA;AAAA,EAGF,IAAI,CAAC,YAAoB,MAAuB;AAAA,IAC9C,IAAI,KAAK,UAAU,MAAM,GAAG;AAAA,MAE1B,KAAK,YAAY,SAAS,WAAW,KAAK,SAAS,IAAI,KAAK,UAAU,IAAI,IAAI,IAAI;AAAA,IACpF;AAAA;AAAA,EAGF,IAAI,CAAC,YAAoB,MAAuB;AAAA,IAC9C,IAAI,KAAK,UAAU,MAAM,GAAG;AAAA,MAE1B,QAAQ,KAAK,eAAe,WAAW,GAAG,IAAI;AAAA,MAC9C,KAAK,YAAY,SAAS,WAAW,KAAK,SAAS,IAAI,KAAK,UAAU,IAAI,IAAI,IAAI;AAAA,IACpF;AAAA;AAAA,EAGF,KAAK,CAAC,SAAiB,OAAuB;AAAA,IAC5C,IAAI,KAAK,UAAU,OAAO,GAAG;AAAA,MAE3B,QAAQ,MAAM,gBAAgB,WAAW,KAAK;AAAA,MAC9C,KAAK,YACH,UAAU,WAAW,iBAAiB,QAAQ,MAAM,QAAQ,KAAK,UAAU,KAAK,GAClF;AAAA,IACF;AAAA;AAEJ;AAEO,IAAM,SAAS,IAAI;;;AFjD1B,eAAsB,WAAW,GAAgC;AAAA,EAC/D,IAAI;AAAA,IACF,MAAM,UAAU,MAAM,SAAS,cAAc,OAAO;AAAA,IACpD,MAAM,UAAU,KAAK,MAAM,OAAO;AAAA,IAGlC,KACG,QAAQ,gBACR,QAAQ,iBACR,QAAQ,cACR,QAAQ,WACR,QAAQ,OACT;AAAA,MACA,OAAO,KAAK,6CAA6C;AAAA,MACzD,MAAM,aAAa;AAAA,MACnB,OAAO;AAAA,IACT;AAAA,IAEA,MAAM,MAAM,KAAK,IAAI;AAAA,IAGrB,IAAI,QAAQ,yBAAyB,QAAQ,wBAAwB,KAAK;AAAA,MACxE,OAAO,KAAK,kDAAkD;AAAA,MAC9D,MAAM,aAAa;AAAA,MACnB,OAAO;AAAA,IACT;AAAA,IAGA,IAAI,QAAQ,YAAY,KAAK;AAAA,MAC3B,OAAO,MAAM,0CAA0C;AAAA,MACvD,IAAI;AAAA,QACF,OAAO,MAAM,eAAe,OAAO;AAAA,QACnC,OAAO,OAAO;AAAA,QACd,OAAO,KAAK,6BAA6B,KAAK;AAAA,QAC9C,MAAM,aAAa;AAAA,QACnB,OAAO;AAAA;AAAA,IAEX;AAAA,IAEA,OAAO;AAAA,IACP,OAAO,OAAO;AAAA,IACd,IAAK,MAAgC,SAAS,UAAU;AAAA,MAEtD,OAAO;AAAA,IACT;AAAA,IACA,OAAO,MAAM,0BAA0B,KAAK;AAAA,IAC5C,OAAO;AAAA;AAAA;AAOX,eAAsB,WAAW,CAAC,SAAqC;AAAA,EACrE,IAAI;AAAA,IAEF,MAAM,OAAM,SAAQ,YAAY,GAAG,EAAE,WAAW,MAAM,MAAM,IAAM,CAAC;AAAA,IAGnE,MAAM,UAAU,cAAc,KAAK,UAAU,SAAS,MAAM,CAAC,GAAG;AAAA,MAC9D,UAAU;AAAA,MACV,MAAM;AAAA,IACR,CAAC;AAAA,IAED,OAAO,KAAK,4BAA4B;AAAA,IACxC,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,0BAA0B,KAAK;AAAA,IAC5C,MAAM;AAAA;AAAA;AAOV,eAAsB,YAAY,GAAkB;AAAA,EAClD,IAAI;AAAA,IACF,MAAM,OAAO,YAAY;AAAA,IACzB,OAAO,KAAK,8BAA8B;AAAA,IAC1C,OAAO,OAAO;AAAA,IACd,IAAK,MAAgC,SAAS,UAAU;AAAA,MAEtD;AAAA,IACF;AAAA,IACA,OAAO,MAAM,2BAA2B,KAAK;AAAA,IAC7C,MAAM;AAAA;AAAA;AAOV,eAAsB,cAAc,CAAC,SAA4C;AAAA,EAC/E,IAAI;AAAA,IACF,OAAO,MAAM,oBAAoB;AAAA,IAEjC,MAAM,WAAW,MAAM,MAAM,GAAG,0CAA0C;AAAA,MACxE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,cAAc,QAAQ;AAAA,MACxB,CAAC;AAAA,IACH,CAAC;AAAA,IAED,KAAK,SAAS,IAAI;AAAA,MAChB,MAAM,IAAI,MAAM,yBAAyB,SAAS,UAAU,SAAS,YAAY;AAAA,IACnF;AAAA,IAEA,MAAM,OAAQ,MAAM,SAAS,KAAK;AAAA,IAQlC,MAAM,MAAM,KAAK,IAAI;AAAA,IACrB,MAAM,YAAY,MAAM,KAAK,YAAY;AAAA,IAGzC,MAAM,wBAAwB,KAAK,wBAC/B,MAAM,KAAK,wBAAwB,OACnC,QAAQ;AAAA,IAEZ,MAAM,aAA0B;AAAA,SAC3B;AAAA,MACH,aAAa,KAAK;AAAA,MAClB,cAAc,KAAK;AAAA,MACnB;AAAA,MACA;AAAA,IACF;AAAA,IAEA,OAAO,MACL,+BAA+B,KAAK,sBAAsB,IAAI,KAAK,SAAS,EAAE,YAAY,IAC5F;AAAA,IACA,IAAI,uBAAuB;AAAA,MACzB,OAAO,MAAM,gCAAgC,IAAI,KAAK,qBAAqB,EAAE,YAAY,GAAG;AAAA,IAC9F,EAAO;AAAA,MACL,OAAO,MAAM,+BAA+B;AAAA;AAAA,IAG9C,MAAM,YAAY,UAAU;AAAA,IAC5B,OAAO,KAAK,gCAAgC;AAAA,IAE5C,OAAO;AAAA,IACP,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,6BAA6B,KAAK;AAAA,IAC/C,MAAM;AAAA;AAAA;AAiBV,eAAsB,eAAe,GAAgC;AAAA,EACnE,MAAM,UAAU,MAAM,YAAY;AAAA,EAClC,KAAK,SAAS;AAAA,IACZ,OAAO;AAAA,EACT;AAAA,EAEA,MAAM,MAAM,KAAK,IAAI;AAAA,EACrB,MAAM,sBAAsB,QAAQ,YAAY;AAAA,EAGhD,IAAI,sBAAsB,gCAAgC;AAAA,IACxD,IAAI;AAAA,MACF,OAAO,MACL,SAAS,sBAAsB,IAAI,YAAY,eAAe,KAAK,MAAM,sBAAsB,IAAI,qBACrG;AAAA,MACA,OAAO,MAAM,eAAe,OAAO;AAAA,MACnC,OAAO,OAAO;AAAA,MACd,OAAO,KAAK,6BAA6B,KAAK;AAAA,MAC9C,OAAO;AAAA;AAAA,EAEX;AAAA,EAEA,OAAO;AAAA;;;AG7MT,uBAAS,sBAAY,oBAAO,2BAAgB,sBAAQ;AAgBpD,IAAM,QAAQ,IAAI;AAKlB,eAAe,QAAW,CAAC,UAAkB,IAAkC;AAAA,EAE7E,OAAO,MAAM,IAAI,QAAQ,GAAG;AAAA,IAC1B,MAAM,MAAM,IAAI,QAAQ;AAAA,EAC1B;AAAA,EAGA,IAAI;AAAA,EACJ,MAAM,cAAc,IAAI,QAAc,CAAC,YAAY;AAAA,IACjD,cAAc;AAAA,GACf;AAAA,EACD,MAAM,IAAI,UAAU,WAAW;AAAA,EAE/B,IAAI;AAAA,IACF,OAAO,MAAM,GAAG;AAAA,YAChB;AAAA,IAEA,MAAM,OAAO,QAAQ;AAAA,IACrB,YAAa;AAAA;AAAA;AAmBjB,eAAe,SAAY,CAAC,UAAgC;AAAA,EAC1D,IAAI;AAAA,IACF,MAAM,UAAU,MAAM,UAAS,UAAU,MAAM;AAAA,IAC/C,MAAM,QAAQ,QAAQ,KAAK,EAAE,MAAM;AAAA,CAAI,EAAE,OAAO,OAAO;AAAA,IAEvD,MAAM,UAAe,CAAC;AAAA,IACtB,SAAS,IAAI,EAAG,IAAI,MAAM,QAAQ,KAAK;AAAA,MACrC,IAAI;AAAA,QACF,QAAQ,KAAK,KAAK,MAAM,MAAM,EAAE,CAAC;AAAA,QACjC,OAAO,OAAO;AAAA,QACd,OAAO,KAAK,wBAAwB,IAAI,QAAQ,aAAa,KAAK;AAAA;AAAA,IAGtE;AAAA,IAEA,OAAO;AAAA,IACP,OAAO,OAAO;AAAA,IACd,IAAK,MAAgC,SAAS,UAAU;AAAA,MAEtD,OAAO,CAAC;AAAA,IACV;AAAA,IACA,MAAM;AAAA;AAAA;AAuBV,eAAe,UAAU,CAAC,UAAiC;AAAA,EACzD,IAAI;AAAA,IACF,MAAM,QAAO,QAAQ;AAAA,IACrB,OAAO,OAAO;AAAA,IACd,IAAK,MAAgC,SAAS,UAAU;AAAA,MAEtD;AAAA,IACF;AAAA,IACA,MAAM;AAAA;AAAA;AAqHV,eAAsB,SAAY,CAAC,WAAiC;AAAA,EAClE,IAAI;AAAA,IACF,OAAO,MAAM,UAAa,SAAS;AAAA,IACnC,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,6BAA6B,cAAc,KAAK;AAAA,IAC7D,MAAM;AAAA;AAAA;AA8DV,eAAsB,UAAU,CAAC,WAAkC;AAAA,EACjE,IAAI;AAAA,IACF,MAAM,SAAS,WAAW,YAAY;AAAA,MACpC,MAAM,WAAW,SAAS;AAAA,MAC1B,OAAO,MAAM,uBAAuB,WAAW;AAAA,KAChD;AAAA,IACD,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,8BAA8B,cAAc,KAAK;AAAA,IAC9D,MAAM;AAAA;AAAA;;;ACpSV,SAAS,iBAAiB,CAAC,QAAwD;AAAA,EACjF,MAAM,WAAW,IAAI;AAAA,EAErB,WAAW,SAAS,QAAQ;AAAA,IAC1B,KAAK,MAAM;AAAA,MAAI;AAAA,IAEf,MAAM,WAAW,SAAS,IAAI,MAAM,EAAE;AAAA,IACtC,KAAK,UAAU;AAAA,MACb,SAAS,IAAI,MAAM,IAAI,KAAK;AAAA,MAC5B;AAAA,IACF;AAAA,IAGA,MAAM,eAAe,SAAS,YAAY,IAAI,KAAK,SAAS,SAAS,EAAE,QAAQ,IAAI;AAAA,IACnF,MAAM,cAAc,MAAM,YAAY,IAAI,KAAK,MAAM,SAAS,EAAE,QAAQ,IAAI;AAAA,IAE5E,IAAI,eAAe,cAAc;AAAA,MAC/B,SAAS,IAAI,MAAM,IAAI,KAAK;AAAA,IAC9B;AAAA,EACF;AAAA,EAEA,OAAO,MAAM,KAAK,SAAS,OAAO,CAAC;AAAA;AAMrC,eAAsB,YAAY,CAChC,UACiD;AAAA,EACjD,IAAI;AAAA,IACF,MAAM,UAAU,MAAM,gBAAgB;AAAA,IACtC,KAAK,SAAS;AAAA,MACZ,OAAO,MAAM,2CAA2C;AAAA,MACxD,OAAO,EAAE,SAAS,OAAO,UAAU,EAAE;AAAA,IACvC;AAAA,IAGA,MAAM,eAAe,MAAM,UAAgC,iBAAiB;AAAA,IAE5E,IAAI,aAAa,WAAW,GAAG;AAAA,MAC7B,OAAO,MAAM,qBAAqB;AAAA,MAClC,OAAO,EAAE,SAAS,MAAM,UAAU,EAAE;AAAA,IACtC;AAAA,IAGA,MAAM,eAAe,kBAAkB,YAAY;AAAA,IAEnD,IAAI,aAAa,SAAS,aAAa,QAAQ;AAAA,MAC7C,OAAO,KACL,wBAAwB,aAAa,YAAW,aAAa,mBAAmB,aAAa,SAAS,aAAa,oBACrH;AAAA,IACF;AAAA,IAEA,OAAO,KAAK,aAAa,aAAa,2BAA2B;AAAA,IAGjE,MAAM,iBAA0C,aAAa,IAAI,CAAC,OAAO;AAAA,SACpE;AAAA,MACH,YAAY;AAAA,MACZ,SAAS,QAAQ;AAAA,MACjB,UAAU;AAAA,MACV,QAAQ;AAAA,IACV,EAAE;AAAA,IAGF,MAAM,YAAY;AAAA,IAClB,IAAI,gBAAgB;AAAA,IAEpB,SAAS,IAAI,EAAG,IAAI,eAAe,QAAQ,KAAK,WAAW;AAAA,MACzD,MAAM,QAAQ,eAAe,MAAM,GAAG,IAAI,SAAS;AAAA,MAEnD,QAAQ,UAAU,MAAM,SACrB,KAAK,oBAAoB,EACzB,OAAO,OAAO,EAAE,YAAY,KAAK,CAAC;AAAA,MAErC,IAAI,OAAO;AAAA,QACT,OAAO,MAAM,iCAAiC,IAAI,YAAY,KAAK,KAAK;AAAA,QACxE,OAAO,EAAE,SAAS,OAAO,UAAU,cAAc;AAAA,MACnD;AAAA,MAEA,iBAAiB,MAAM;AAAA,MACvB,OAAO,MAAM,oBAAmB,IAAI,YAAY,MAAM,MAAM,gBAAgB;AAAA,IAC9E;AAAA,IAGA,MAAM,WAAW,iBAAiB;AAAA,IAElC,OAAO,KAAK,8BAA6B,sBAAsB;AAAA,IAC/D,OAAO,EAAE,SAAS,MAAM,UAAU,cAAc;AAAA,IAChD,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,2BAA2B,KAAK;AAAA,IAC7C,OAAO,EAAE,SAAS,OAAO,UAAU,EAAE;AAAA;AAAA;AAOzC,eAAsB,qBAAqB,CACzC,UACA,aAAa,GACb,YAAY,MACqC;AAAA,EACjD,IAAI,YAA0B;AAAA,EAE9B,SAAS,UAAU,EAAG,WAAW,YAAY,WAAW;AAAA,IACtD,IAAI;AAAA,MACF,MAAM,SAAS,MAAM,aAAa,QAAQ;AAAA,MAC1C,IAAI,OAAO,SAAS;AAAA,QAClB,OAAO;AAAA,MACT;AAAA,MAGA,OAAO;AAAA,MACP,OAAO,OAAO;AAAA,MACd,YAAY;AAAA,MACZ,OAAO,KAAK,yBAAyB,WAAW,sBAAsB,UAAU,SAAS;AAAA,MAEzF,IAAI,UAAU,YAAY;AAAA,QACxB,MAAM,QAAQ,YAAY;AAAA,QAC1B,OAAO,MAAM,eAAe,YAAY;AAAA,QACxC,MAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,KAAK,CAAC;AAAA,MAC3D;AAAA;AAAA,EAEJ;AAAA,EAEA,OAAO,MAAM,8BAA8B,uBAAuB,SAAS;AAAA,EAC3E,OAAO,EAAE,SAAS,OAAO,UAAU,EAAE;AAAA;",
  "debugId": "580A2D9C9558A18B64756E2164756E21",
  "names": []
}