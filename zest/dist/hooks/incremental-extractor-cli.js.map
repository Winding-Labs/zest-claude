{
  "version": 3,
  "sources": ["../src/config/constants.ts", "../src/utils/fs-utils.ts", "../src/utils/log-rotation.ts", "../src/utils/logger.ts", "../src/utils/deletion-cache.ts", "../src/hooks/incremental-extractor-cli.ts", "../src/utils/debounce-manager.ts", "../src/utils/file-lock.ts", "../src/utils/daemon-manager.ts", "../src/utils/extraction-helpers.ts", "../src/auth/session-manager.ts", "../src/utils/command-filters.ts", "../src/extractors/extraction-utils.ts", "../../../node_modules/diff/libesm/diff/base.js", "../../../node_modules/diff/libesm/diff/character.js", "../../../node_modules/diff/libesm/util/string.js", "../../../node_modules/diff/libesm/diff/word.js", "../../../node_modules/diff/libesm/diff/line.js", "../../../node_modules/diff/libesm/diff/sentence.js", "../../../node_modules/diff/libesm/diff/css.js", "../../../node_modules/diff/libesm/diff/json.js", "../../../node_modules/diff/libesm/diff/array.js", "../src/utils/diff-utils.ts", "../src/extractors/message-parser.ts", "../src/utils/queue-manager.ts", "../src/utils/state-manager.ts"],
  "sourcesContent": [
    "/**\r\n * Application constants and configuration values\r\n */\r\n\r\nimport { homedir } from \"node:os\";\r\nimport { join } from \"node:path\";\r\n\r\n// Claude Code directories\r\n// Respects CLAUDE_INSTALL_PATH environment variable for non-standard installations\r\nexport const CLAUDE_INSTALL_DIR = process.env.CLAUDE_INSTALL_PATH || join(homedir(), \".claude\");\r\nexport const CLAUDE_PROJECTS_DIR = join(CLAUDE_INSTALL_DIR, \"projects\");\r\nexport const CLAUDE_SETTINGS_FILE = join(CLAUDE_INSTALL_DIR, \"settings.json\");\r\n\r\n// Base directories\r\nexport const CLAUDE_ZEST_DIR = join(CLAUDE_INSTALL_DIR, \"..\", \".claude-zest\");\r\nexport const QUEUE_DIR = join(CLAUDE_ZEST_DIR, \"queue\");\r\nexport const LOGS_DIR = join(CLAUDE_ZEST_DIR, \"logs\");\r\nexport const STATE_DIR = join(CLAUDE_ZEST_DIR, \"state\");\r\nexport const DELETION_CACHE_DIR = join(CLAUDE_ZEST_DIR, \"cache\", \"deletions\");\r\n\r\n// File paths\r\nexport const SESSION_FILE = join(CLAUDE_ZEST_DIR, \"session.json\"); // Auth session + workspace info\r\nexport const SETTINGS_FILE = join(CLAUDE_ZEST_DIR, \"settings.json\"); // User preferences\r\nexport const DAEMON_PID_FILE = join(CLAUDE_ZEST_DIR, \"daemon.pid\");\r\nexport const STATUSLINE_SCRIPT_PATH = join(CLAUDE_ZEST_DIR, \"statusline.mjs\"); // Status line script (.mjs for ESM support)\r\nexport const STATUS_CACHE_FILE = join(CLAUDE_ZEST_DIR, \"status-cache.json\"); // Status cache for version checks and sync errors\r\n\r\n// Queue files\r\nexport const EVENTS_QUEUE_FILE = join(QUEUE_DIR, \"events.jsonl\");\r\nexport const SESSIONS_QUEUE_FILE = join(QUEUE_DIR, \"chat-sessions.jsonl\");\r\nexport const MESSAGES_QUEUE_FILE = join(QUEUE_DIR, \"chat-messages.jsonl\");\r\n\r\n// Platform and source identifiers\r\nexport const PLATFORM = \"terminal\";\r\nexport const SOURCE = \"claude-code\";\r\nexport const CLIENT_ID = \"claude-cli\";\r\n\r\n// Sync configuration\r\nexport const SYNC_INTERVAL_MS = 60000; // 60 seconds\r\nexport const MAX_RETRY_ATTEMPTS = 3;\r\nexport const RETRY_BACKOFF_MS = 5000;\r\n\r\n// File locking configuration\r\nexport const LOCK_RETRY_MS = 50; // Retry interval when lock is held by another process\r\nexport const LOCK_MAX_RETRIES = 300; // Max retries (10 seconds total)\r\n\r\n// Debounce configuration (prevents duplicate hook executions)\r\nexport const DEBOUNCE_DIR = join(CLAUDE_ZEST_DIR, \"debounce\");\r\nexport const DEBOUNCE_WINDOW_MS = 500; // First-wins debounce window\r\nexport const DEBOUNCE_TRAILING_MS = 300; // Trailing debounce: wait after last hook before processing\r\n\r\n// Delayed extraction configuration (for PostToolUse trailing debounce)\r\nexport const DELAYED_EXTRACTION_INITIAL_DELAY_MS = 500; // Initial wait before checking if hooks settled\r\nexport const DELAYED_EXTRACTION_MAX_WAIT_MS = 10000; // Maximum total wait time\r\nexport const DELAYED_EXTRACTION_CHECK_INTERVAL_MS = 300; // How often to check if hooks settled\r\n\r\n// Cache configuration\r\nexport const DELETION_CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes\r\n\r\n// Log rotation configuration\r\nexport const LOG_RETENTION_DAYS = 7; // Delete log files older than 7 days\r\n\r\n// Authentication configuration\r\nexport const PROACTIVE_REFRESH_THRESHOLD_MS = 5 * 60 * 1000; // Proactively refresh JWT/access tokens 5 minutes before expiration\r\n\r\n// Content size limits\r\nexport const MAX_DIFF_SIZE_BYTES = 10 * 1024 * 1024; // 10MB\r\nexport const MAX_CONTENT_PREVIEW_LENGTH = 1000; // characters\r\nexport const MAX_SESSION_TITLE_LENGTH = 100; // characters\r\nexport const MIN_SESSION_TITLE_LENGTH = 3; // characters\r\n\r\n// Session quality filters\r\nexport const MIN_MESSAGES_PER_SESSION = 3; // Minimum messages required to upload a session\r\nexport const STALE_SESSION_AGE_MS = 7 * 24 * 60 * 60 * 1000; // 7 days in milliseconds\r\n\r\n// API endpoints (configured from .env at build time)\r\n// Values are baked into the bundle during build\r\nexport const WEB_APP_URL = process.env.ZEST_WEB_APP_URL || \"http://localhost:3000\";\r\nexport const SUPABASE_URL = process.env.ZEST_SUPABASE_URL || \"\";\r\nexport const SUPABASE_ANON_KEY = process.env.ZEST_SUPABASE_ANON_KEY || \"\";\r\n\r\n// Filter patterns for commands/messages to exclude from tracking\r\nexport const EXCLUDED_COMMAND_PATTERNS = [\r\n  // Claude Code built-in commands\r\n  /^\\/(add-dir|agents|bashes|bug|clear|compact|config|context|cost|doctor|exit|export|help|hooks|ide|init|install-github-app|login|logout|mcp|memory|model|output-style|permissions|plugin|pr-comments|privacy-settings|release-notes|resume|review|rewind|sandbox|security-review|stats|status|statusline|terminal-setup|todos|usage|vim)\\b/i,\r\n\r\n  // Zest plugin commands (like /zest:status, /zest:login, etc.)\r\n  /^\\/zest[^:\\s]*:/i,\r\n\r\n  // Messages containing Zest command tags (e.g., <command-name>/zest:status</command-name>)\r\n  /<command-name>\\/zest[^<]*<\\/command-name>/i,\r\n\r\n  // Messages containing Zest CLI script paths (e.g., \"node .../dist/commands/sync-cli.js\")\r\n  /node\\s+.*\\/dist\\/commands\\/.*-cli\\.js/i,\r\n];\r\n\r\nexport const ZEST_SESSION_NAMESPACE = \"1b671a64-40d5-491e-99b0-da01ff1f3341\";\r\n\r\n// Version check configuration\r\n// If ZEST_MARKETPLACE_PLUGIN_JSON_URL is not set, version checking will be disabled\r\nexport const MARKETPLACE_PLUGIN_JSON_URL = process.env.ZEST_MARKETPLACE_PLUGIN_JSON_URL || \"\";\r\nexport const VERSION_CHECK_TIMEOUT_MS = 5000; // 5 seconds\r\nexport const UPDATE_CHECK_CACHE_TTL_MS = 60 * 60 * 1000; // 1 hour - how long to cache update check results\r\n\r\n// Daemon management configuration\r\nexport const DAEMON_FRESH_PID_THRESHOLD_MS = 2000; // 2 seconds - how recently PID file must be modified to skip restart\r\n",
    "/**\r\n * Filesystem utility functions\r\n *\r\n * Shared helpers for file and directory operations\r\n *\r\n * Note: This module intentionally has no dependencies on logger.ts\r\n * to avoid circular dependencies (logger.ts uses ensureDirectory).\r\n */\r\n\r\nimport { mkdir, stat } from \"node:fs/promises\";\r\n\r\n/**\r\n * Ensure directory exists, creating it if necessary\r\n * Creates parent directories recursively with secure permissions (mode 0o700)\r\n *\r\n * @param dirPath - Path to the directory to ensure exists\r\n */\r\nexport async function ensureDirectory(dirPath: string): Promise<void> {\r\n  try {\r\n    await stat(dirPath);\r\n  } catch {\r\n    await mkdir(dirPath, { recursive: true, mode: 0o700 });\r\n  }\r\n}\r\n",
    "/**\r\n * Log rotation utilities\r\n *\r\n * Provides date-based log file paths and automatic cleanup of stale logs.\r\n */\r\n\r\nimport { readdir, unlink } from \"node:fs/promises\";\r\nimport { join } from \"node:path\";\r\nimport { LOG_RETENTION_DAYS, LOGS_DIR } from \"../config/constants.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n// Throttle cleanup to run at most once per hour\r\nconst CLEANUP_THROTTLE_MS = 60 * 60 * 1000; // 1 hour\r\nlet lastCleanupTime: Record<string, number> = {};\r\n\r\n/**\r\n * Get current date string in YYYY-MM-DD format (UTC)\r\n */\r\nexport function getDateString(): string {\r\n  return new Date().toISOString().split(\"T\")[0];\r\n}\r\n\r\n/**\r\n * Get date-based log file path\r\n * @param logPrefix - Prefix for the log file (e.g., \"plugin\" or \"sync\")\r\n * @returns Full path like ~/.claude-zest/logs/plugin-2026-01-09.log\r\n */\r\nexport function getDatedLogPath(logPrefix: string): string {\r\n  const dateStr = getDateString();\r\n  return join(LOGS_DIR, `${logPrefix}-${dateStr}.log`);\r\n}\r\n\r\n/**\r\n * Parse date from log filename\r\n * @param filename - Filename like \"plugin-2026-01-09.log\"\r\n * @param logPrefix - Prefix to match (e.g., \"plugin\")\r\n * @returns Date object or null if doesn't match pattern\r\n */\r\nfunction parseDateFromFilename(filename: string, logPrefix: string): Date | null {\r\n  const pattern = new RegExp(`^${logPrefix}-(\\\\d{4}-\\\\d{2}-\\\\d{2})\\\\.log$`);\r\n  const match = filename.match(pattern);\r\n\r\n  if (!match) {\r\n    return null;\r\n  }\r\n\r\n  const date = new Date(match[1] + \"T00:00:00Z\");\r\n  return Number.isNaN(date.getTime()) ? null : date;\r\n}\r\n\r\n/**\r\n * Clean up stale log files older than retention period\r\n * Throttled to run at most once per hour per logPrefix\r\n *\r\n * @param logPrefix - Prefix of logs to clean (e.g., \"plugin\" or \"sync\")\r\n */\r\nexport async function cleanupStaleLogs(logPrefix: string): Promise<void> {\r\n  const now = Date.now();\r\n  const lastCleanup = lastCleanupTime[logPrefix] || 0;\r\n\r\n  // Throttle: skip if cleaned up less than an hour ago\r\n  if (now - lastCleanup < CLEANUP_THROTTLE_MS) {\r\n    return;\r\n  }\r\n\r\n  lastCleanupTime[logPrefix] = now;\r\n\r\n  try {\r\n    await ensureDirectory(LOGS_DIR);\r\n    const files = await readdir(LOGS_DIR);\r\n    const cutoffDate = new Date(now - LOG_RETENTION_DAYS * 24 * 60 * 60 * 1000);\r\n\r\n    for (const file of files) {\r\n      const fileDate = parseDateFromFilename(file, logPrefix);\r\n\r\n      if (fileDate && fileDate < cutoffDate) {\r\n        const filePath = join(LOGS_DIR, file);\r\n        try {\r\n          await unlink(filePath);\r\n        } catch (error) {\r\n          logger.error(`Failed to delete old log file ${file}`, error);\r\n        }\r\n      }\r\n    }\r\n  } catch (error) {\r\n    logger.error(\"Failed to cleanup old logs\", error);\r\n  }\r\n}\r\n\r\n/**\r\n * Force cleanup regardless of throttle (for daemon startup)\r\n * @param logPrefix - Prefix of logs to clean (e.g., \"plugin\" or \"sync\")\r\n */\r\nexport async function forceCleanupStaleLogs(logPrefix: string): Promise<void> {\r\n  // Reset throttle to force cleanup\r\n  lastCleanupTime[logPrefix] = 0;\r\n  await cleanupStaleLogs(logPrefix);\r\n}\r\n",
    "/**\r\n * Logging utilities\r\n *\r\n * Handles logging to console and file system with daily log rotation.\r\n * Log files are named with dates (e.g., plugin-2026-01-09.log) and\r\n * automatically cleaned up after LOG_RETENTION_DAYS.\r\n */\r\n\r\nimport { appendFile } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { cleanupStaleLogs, getDatedLogPath } from \"./log-rotation.js\";\r\n\r\ntype LogLevel = \"debug\" | \"info\" | \"warn\" | \"error\";\r\n\r\nclass Logger {\r\n  private minLevel: LogLevel = \"info\";\r\n  private readonly logPrefix: string;\r\n\r\n  private levels: Record<LogLevel, number> = {\r\n    debug: 0,\r\n    info: 1,\r\n    warn: 2,\r\n    error: 3,\r\n  };\r\n\r\n  constructor(logPrefix = \"plugin\") {\r\n    this.logPrefix = logPrefix;\r\n  }\r\n\r\n  setLevel(level: LogLevel): void {\r\n    this.minLevel = level;\r\n  }\r\n\r\n  private async writeToFile(message: string): Promise<void> {\r\n    try {\r\n      // Get date-based log path (handles date rollover automatically)\r\n      const logFilePath = getDatedLogPath(this.logPrefix);\r\n      await ensureDirectory(dirname(logFilePath));\r\n      const timestamp = new Date().toISOString();\r\n      await appendFile(logFilePath, `[${timestamp}] ${message}\\n`, \"utf-8\");\r\n\r\n      // Trigger cleanup (throttled to once per hour)\r\n      cleanupStaleLogs(this.logPrefix);\r\n    } catch (error) {\r\n      // Silently fail - don't crash if we can't write logs\r\n      console.error(\"Failed to write to log file:\", error);\r\n    }\r\n  }\r\n\r\n  private shouldLog(level: LogLevel): boolean {\r\n    return this.levels[level] >= this.levels[this.minLevel];\r\n  }\r\n\r\n  debug(message: string, ...args: unknown[]): void {\r\n    if (this.shouldLog(\"debug\")) {\r\n      // Only write to file, don't clutter console\r\n      this.writeToFile(`DEBUG: ${message} ${args.length > 0 ? JSON.stringify(args) : \"\"}`);\r\n    }\r\n  }\r\n\r\n  info(message: string, ...args: unknown[]): void {\r\n    if (this.shouldLog(\"info\")) {\r\n      // Only write to file, don't clutter console\r\n      this.writeToFile(`INFO: ${message} ${args.length > 0 ? JSON.stringify(args) : \"\"}`);\r\n    }\r\n  }\r\n\r\n  warn(message: string, ...args: unknown[]): void {\r\n    if (this.shouldLog(\"warn\")) {\r\n      // Show warnings to user\r\n      console.warn(`[Zest:Warn] ${message}`, ...args);\r\n      this.writeToFile(`WARN: ${message} ${args.length > 0 ? JSON.stringify(args) : \"\"}`);\r\n    }\r\n  }\r\n\r\n  error(message: string, error?: unknown): void {\r\n    if (this.shouldLog(\"error\")) {\r\n      // Show errors to user\r\n      console.error(`[Zest:Error] ${message}`, error);\r\n      this.writeToFile(\r\n        `ERROR: ${message} ${error instanceof Error ? error.stack : JSON.stringify(error)}`,\r\n      );\r\n    }\r\n  }\r\n}\r\n\r\nexport const logger = new Logger();\r\n",
    "/**\r\n * Deletion cache manager\r\n *\r\n * Stores file content before deletion (PreToolUse) so it can be used\r\n * to generate diffs after deletion (PostToolUse)\r\n */\r\n\r\nimport { readdir, readFile, rm, stat, writeFile } from \"node:fs/promises\";\r\nimport { join } from \"node:path\";\r\nimport { DELETION_CACHE_DIR, DELETION_CACHE_TTL_MS } from \"../config/constants.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\ninterface CachedDeletion {\r\n  filePath: string;\r\n  content: string;\r\n  timestamp: number;\r\n  sessionId: string;\r\n}\r\n\r\n/**\r\n * Generate cache key from file path and session\r\n */\r\nfunction getCacheKey(filePath: string, sessionId: string): string {\r\n  // Use simple hash of filepath to avoid filesystem issues\r\n  const hash = Buffer.from(filePath).toString(\"base64\").replace(/[/+=]/g, \"_\");\r\n  return `${sessionId}_${hash}.json`;\r\n}\r\n\r\n/**\r\n * Store file content before deletion\r\n */\r\nexport async function cacheFileForDeletion(\r\n  filePath: string,\r\n  content: string,\r\n  sessionId: string,\r\n): Promise<void> {\r\n  try {\r\n    await ensureDirectory(DELETION_CACHE_DIR);\r\n\r\n    const cached: CachedDeletion = {\r\n      filePath,\r\n      content,\r\n      timestamp: Date.now(),\r\n      sessionId,\r\n    };\r\n\r\n    const cacheKey = getCacheKey(filePath, sessionId);\r\n    const cachePath = join(DELETION_CACHE_DIR, cacheKey);\r\n\r\n    await writeFile(cachePath, JSON.stringify(cached, null, 2), \"utf-8\");\r\n    logger.debug(`Cached file content: ${filePath} (${content.length} chars)`);\r\n  } catch (error) {\r\n    logger.error(`Failed to cache file for deletion: ${filePath}`, error);\r\n  }\r\n}\r\n\r\n/**\r\n * Retrieve cached file content for diff generation\r\n * Removes the cache entry after retrieval\r\n */\r\nexport async function getCachedFileContent(\r\n  filePath: string,\r\n  sessionId: string,\r\n): Promise<string | null> {\r\n  try {\r\n    const cacheKey = getCacheKey(filePath, sessionId);\r\n    const cachePath = join(DELETION_CACHE_DIR, cacheKey);\r\n\r\n    try {\r\n      const content = await readFile(cachePath, \"utf-8\");\r\n      const cached: CachedDeletion = JSON.parse(content);\r\n\r\n      // Check if cache is still valid (not expired)\r\n      const age = Date.now() - cached.timestamp;\r\n\r\n      if (age > DELETION_CACHE_TTL_MS) {\r\n        logger.debug(`Cache expired for ${filePath} (${age}ms old)`);\r\n        await rm(cachePath).catch(() => {}); // Clean up expired cache\r\n        return null;\r\n      }\r\n\r\n      // Clean up cache after retrieval\r\n      await rm(cachePath).catch(() => {});\r\n\r\n      logger.debug(`Retrieved cached content for ${filePath} (${cached.content.length} chars)`);\r\n      return cached.content;\r\n    } catch (readError) {\r\n      // Cache file doesn't exist\r\n      logger.debug(`Cache not found for ${filePath}`);\r\n      return null;\r\n    }\r\n  } catch (error) {\r\n    logger.error(`Failed to retrieve cached content: ${filePath}`, error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Clean up old cache entries\r\n * Called periodically to prevent cache buildup\r\n */\r\nexport async function cleanupOldCache(): Promise<void> {\r\n  try {\r\n    await ensureDirectory(DELETION_CACHE_DIR);\r\n    const files = await readdir(DELETION_CACHE_DIR);\r\n    const now = Date.now();\r\n\r\n    for (const file of files) {\r\n      try {\r\n        const filePath = join(DELETION_CACHE_DIR, file);\r\n        const stats = await stat(filePath);\r\n\r\n        // Delete files older than TTL\r\n        const age = now - stats.mtimeMs;\r\n        if (age > DELETION_CACHE_TTL_MS) {\r\n          await rm(filePath);\r\n          logger.debug(`Cleaned up old cache entry: ${file} (${age}ms old)`);\r\n        }\r\n      } catch (error) {\r\n        // Ignore errors for individual files\r\n        logger.debug(`Failed to clean up cache file ${file}:`, error);\r\n      }\r\n    }\r\n  } catch (error) {\r\n    logger.error(\"Failed to cleanup old cache:\", error);\r\n  }\r\n}\r\n",
    "#!/usr/bin/env node\r\n\r\n/**\r\n * CLI handler for incremental extraction on PostToolUse events\r\n *\r\n * Called by Claude Code hooks after a tool completes\r\n * Extracts only new messages/diffs since last extraction\r\n *\r\n * Usage: node dist/hooks/incremental-extractor-cli.js\r\n */\r\n\r\nimport { spawn } from \"node:child_process\";\r\nimport { dirname, join } from \"node:path\";\r\nimport { fileURLToPath } from \"node:url\";\r\nimport { registerHookFired } from \"../utils/debounce-manager.js\";\r\nimport { findConversationFile } from \"../utils/extraction-helpers.js\";\r\nimport { logger } from \"../utils/logger.js\";\r\n\r\n// Get the directory of the current module\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = dirname(__filename);\r\n\r\nasync function main() {\r\n  const projectDir = process.env.CLAUDE_PROJECT_DIR;\r\n\r\n  try {\r\n    if (!projectDir) {\r\n      logger.warn(\"CLAUDE_PROJECT_DIR not set\");\r\n      process.exit(0);\r\n    }\r\n\r\n    const sessionInfo = await findConversationFile(projectDir);\r\n    if (!sessionInfo) {\r\n      logger.warn(\"Could not find conversation file\");\r\n      process.exit(0);\r\n    }\r\n\r\n    const { conversationFile, sessionId } = sessionInfo;\r\n\r\n    // TRAILING DEBOUNCE: Register this hook fired, don't process immediately\r\n    await registerHookFired(\"PostToolUse\", sessionId);\r\n\r\n    // Spawn delayed extractor - it will wait for hooks to settle, then process once\r\n    spawnDelayedExtractor(sessionId, conversationFile);\r\n  } catch (error) {\r\n    logger.error(\"Failed to perform incremental extraction:\", error);\r\n    // Exit with 0 to avoid disrupting Claude's operation\r\n    process.exit(0);\r\n  }\r\n}\r\n\r\n/**\r\n * Spawn delayed extractor as detached background process\r\n * This catches assistant messages and tool results written AFTER PostToolUse completes\r\n */\r\nfunction spawnDelayedExtractor(sessionId: string, conversationFile: string): void {\r\n  try {\r\n    const delayedExtractorPath = join(__dirname, \"delayed-extractor-cli.js\");\r\n\r\n    // Spawn as detached background process\r\n    const child = spawn(\"node\", [delayedExtractorPath, sessionId, conversationFile], {\r\n      detached: true,\r\n      stdio: \"ignore\", // Don't pipe output\r\n      env: process.env, // Pass environment variables\r\n    });\r\n\r\n    // Detach from parent so it can exit independently\r\n    child.unref();\r\n  } catch (error) {\r\n    logger.error(\"Failed to spawn delayed extractor:\", error);\r\n    // Don't fail the main hook - delayed extraction is optional\r\n  }\r\n}\r\n\r\nmain().catch((error) => {\r\n  console.error(\"Incremental extractor error:\", error);\r\n  process.exit(1);\r\n});\r\n",
    "/**\r\n * Debounce manager to prevent duplicate hook executions\r\n *\r\n * Claude Code sometimes fires hooks twice for the same action.\r\n * This module provides TWO debouncing strategies:\r\n *\r\n * 1. First-wins (shouldSkipDuplicate): Process first, skip duplicates\r\n *    - Good for: SessionStart, SessionEnd, PreToolUse\r\n *\r\n * 2. Trailing debounce (registerHookFired + shouldProcessNow): Wait for storm to settle\r\n *    - Good for: PostToolUse (wait for all rapid-fire hooks to finish)\r\n */\r\n\r\nimport { readdir, readFile, stat, unlink, writeFile } from \"node:fs/promises\";\r\nimport { join } from \"node:path\";\r\nimport { DEBOUNCE_DIR, DEBOUNCE_TRAILING_MS, DEBOUNCE_WINDOW_MS } from \"../config/constants.js\";\r\nimport { withFileLock } from \"./file-lock.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\ninterface DebounceInfo {\r\n  timestamp: number;\r\n  pid: number;\r\n  count?: number; // How many hooks have fired in this window\r\n}\r\n\r\n/**\r\n * STRATEGY 1: First-wins debounce (with file locking for atomicity)\r\n *\r\n * Check if this execution should be skipped (duplicate within debounce window)\r\n * Returns true if we should SKIP this execution\r\n *\r\n * Uses file locking to prevent race conditions when multiple processes\r\n * check the debounce file simultaneously.\r\n *\r\n * Use for: SessionStart, SessionEnd, PreToolUse\r\n */\r\nexport async function shouldSkipDuplicate(hookType: string, sessionId: string): Promise<boolean> {\r\n  const debounceFile = join(DEBOUNCE_DIR, `${hookType}-${sessionId}.json`);\r\n\r\n  try {\r\n    await ensureDirectory(DEBOUNCE_DIR);\r\n\r\n    // Use file locking to make the check-and-write atomic\r\n    return await withFileLock(debounceFile, async () => {\r\n      const now = Date.now();\r\n\r\n      // Try to read existing debounce file\r\n      try {\r\n        const content = await readFile(debounceFile, \"utf-8\");\r\n        const info: DebounceInfo = JSON.parse(content);\r\n\r\n        // Check if within debounce window\r\n        if (now - info.timestamp < DEBOUNCE_WINDOW_MS) {\r\n          logger.info(\r\n            `Skipping duplicate ${hookType} (within ${DEBOUNCE_WINDOW_MS}ms window, PID ${info.pid} was first)`,\r\n          );\r\n          return true; // Skip this execution\r\n        }\r\n      } catch {\r\n        // File doesn't exist or invalid - this is the first execution\r\n      }\r\n\r\n      // Write our timestamp as the first executor\r\n      const newInfo: DebounceInfo = {\r\n        timestamp: now,\r\n        pid: process.pid,\r\n      };\r\n      await writeFile(debounceFile, JSON.stringify(newInfo), \"utf-8\");\r\n\r\n      return false; // Don't skip - this is the first execution\r\n    });\r\n  } catch (error) {\r\n    logger.debug(`Debounce check failed for ${hookType}:`, error);\r\n    return false; // On error, don't skip (let execution proceed)\r\n  }\r\n}\r\n\r\n/**\r\n * STRATEGY 2: Trailing debounce (for PostToolUse)\r\n *\r\n * Instead of processing immediately, each hook:\r\n * 1. Registers that it fired (updates timestamp)\r\n * 2. Skips immediate processing\r\n * 3. Spawns delayed processor that will check shouldProcessNow()\r\n *\r\n * The delayed processor:\r\n * 1. Waits TRAILING_DEBOUNCE_MS\r\n * 2. Checks if enough time has passed since last hook\r\n * 3. If yes, processes. If no, waits more.\r\n */\r\n\r\n/**\r\n * Register that a hook has fired (trailing debounce)\r\n * Returns the current count of hooks in this window\r\n */\r\nexport async function registerHookFired(hookType: string, sessionId: string): Promise<number> {\r\n  const debounceFile = join(DEBOUNCE_DIR, `trailing-${hookType}-${sessionId}.json`);\r\n\r\n  try {\r\n    await ensureDirectory(DEBOUNCE_DIR);\r\n\r\n    // Use file locking to prevent race conditions\r\n    return await withFileLock(debounceFile, async () => {\r\n      const now = Date.now();\r\n      let count = 1;\r\n\r\n      // Try to read existing file to get count\r\n      try {\r\n        const content = await readFile(debounceFile, \"utf-8\");\r\n        const info: DebounceInfo = JSON.parse(content);\r\n\r\n        // If within window, increment count\r\n        if (now - info.timestamp < 5000) {\r\n          // 5s window for counting\r\n          count = (info.count || 1) + 1;\r\n        }\r\n      } catch {\r\n        // File doesn't exist - this is the first\r\n      }\r\n\r\n      // Update with our timestamp\r\n      const newInfo: DebounceInfo = {\r\n        timestamp: now,\r\n        pid: process.pid,\r\n        count,\r\n      };\r\n      await writeFile(debounceFile, JSON.stringify(newInfo), \"utf-8\");\r\n\r\n      logger.debug(`Registered ${hookType} #${count} for session ${sessionId}`);\r\n      return count;\r\n    });\r\n  } catch (error) {\r\n    logger.debug(\"Failed to register hook:\", error);\r\n    return 1;\r\n  }\r\n}\r\n\r\n/**\r\n * Check if enough time has passed since last hook to process now\r\n * Used by delayed processor after waiting\r\n *\r\n * Returns: { shouldProcess: boolean, msSinceLastHook: number }\r\n */\r\nexport async function shouldProcessNow(\r\n  hookType: string,\r\n  sessionId: string,\r\n): Promise<{ shouldProcess: boolean; msSinceLastHook: number }> {\r\n  const debounceFile = join(DEBOUNCE_DIR, `trailing-${hookType}-${sessionId}.json`);\r\n  const now = Date.now();\r\n\r\n  try {\r\n    const content = await readFile(debounceFile, \"utf-8\");\r\n    const info: DebounceInfo = JSON.parse(content);\r\n\r\n    const msSinceLastHook = now - info.timestamp;\r\n\r\n    // Process if enough time has passed since last hook\r\n    const shouldProcess = msSinceLastHook >= DEBOUNCE_TRAILING_MS;\r\n\r\n    if (!shouldProcess) {\r\n      logger.debug(\r\n        `Not ready to process ${hookType} - only ${msSinceLastHook}ms since last hook (need ${DEBOUNCE_TRAILING_MS}ms)`,\r\n      );\r\n    }\r\n\r\n    return { shouldProcess, msSinceLastHook };\r\n  } catch {\r\n    // File doesn't exist - safe to process\r\n    return { shouldProcess: true, msSinceLastHook: Number.POSITIVE_INFINITY };\r\n  }\r\n}\r\n\r\n/**\r\n * Clean up old debounce files (older than 5 minutes)\r\n * Called at SessionEnd to prevent accumulation\r\n */\r\nexport async function cleanupDebounceFiles(): Promise<void> {\r\n  try {\r\n    const files = await readdir(DEBOUNCE_DIR).catch(() => [] as string[]);\r\n    const now = Date.now();\r\n    const maxAgeMs = 5 * 60 * 1000; // 5 minutes\r\n    let cleaned = 0;\r\n\r\n    for (const file of files) {\r\n      const filePath = join(DEBOUNCE_DIR, file);\r\n      try {\r\n        const stats = await stat(filePath);\r\n        if (now - stats.mtimeMs > maxAgeMs) {\r\n          await unlink(filePath);\r\n          cleaned++;\r\n        }\r\n      } catch {\r\n        // Ignore errors for individual files\r\n      }\r\n    }\r\n\r\n    if (cleaned > 0) {\r\n      logger.debug(`Cleaned up ${cleaned} old debounce files`);\r\n    }\r\n  } catch {\r\n    // Ignore cleanup errors - non-critical\r\n  }\r\n}\r\n",
    "/**\r\n * Cross-process file locking utility\r\n *\r\n * Provides file-based locking to prevent corruption from concurrent access\r\n * across different processes (plugin hooks vs daemon)\r\n *\r\n * Uses PID-based stale lock detection - a lock is only considered stale\r\n * if the owning process is dead, allowing long-running operations.\r\n */\r\n\r\nimport { unlinkSync } from \"node:fs\";\r\nimport { readdir, readFile, unlink, writeFile } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport { LOCK_MAX_RETRIES, LOCK_RETRY_MS, QUEUE_DIR } from \"../config/constants.js\";\r\nimport { isProcessRunning } from \"./daemon-manager.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n/**\r\n * Lock file metadata - stored in .lock files\r\n */\r\ninterface LockInfo {\r\n  pid: number;\r\n  timestamp: number; // For debugging/logging only - PID is authoritative\r\n}\r\n\r\n// Track active lock files for cleanup on process exit\r\nconst activeLockFiles = new Set<string>();\r\n\r\n/**\r\n * Check if a lock file represents a stale lock\r\n * A lock is stale ONLY if the owning process is dead\r\n * This ensures long-running operations (like uploads) don't have their locks stolen\r\n */\r\nfunction isLockStale(lockInfo: LockInfo): boolean {\r\n  return !isProcessRunning(lockInfo.pid);\r\n}\r\n\r\n/**\r\n * Acquire a file-based lock (cross-process safe)\r\n * Uses atomic file creation with 'wx' flag to prevent race conditions\r\n *\r\n * @returns true if lock was acquired, false if held by another active process\r\n */\r\nasync function acquireFileLock(filePath: string): Promise<boolean> {\r\n  const lockFile = `${filePath}.lock`;\r\n  const lockInfo: LockInfo = {\r\n    pid: process.pid,\r\n    timestamp: Date.now(),\r\n  };\r\n\r\n  try {\r\n    // Ensure parent directory exists before creating lock file\r\n    await ensureDirectory(dirname(lockFile));\r\n\r\n    // 'wx' flag = exclusive create - fails atomically if file already exists\r\n    await writeFile(lockFile, JSON.stringify(lockInfo), { flag: \"wx\" });\r\n    activeLockFiles.add(lockFile);\r\n    return true;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code !== \"EEXIST\") {\r\n      // Log more context for directory-related errors\r\n      const errCode = (error as NodeJS.ErrnoException).code;\r\n      if (errCode === \"ENOENT\" || errCode === \"EACCES\") {\r\n        logger.error(`Failed to create lock file ${lockFile}:`, error);\r\n      }\r\n      throw error; // Unexpected error - rethrow\r\n    }\r\n\r\n    // Lock file exists - check if it's stale (owning process is dead)\r\n    try {\r\n      const content = await readFile(lockFile, \"utf8\");\r\n      const existingLock: LockInfo = JSON.parse(content);\r\n\r\n      if (isLockStale(existingLock)) {\r\n        // Remove stale lock and retry\r\n        logger.debug(`Removing stale lock for ${filePath} (PID ${existingLock.pid} is dead)`);\r\n        await unlink(lockFile).catch(() => {});\r\n        return acquireFileLock(filePath); // Recursive retry\r\n      }\r\n    } catch {\r\n      // Couldn't read/parse lock file - it may be corrupted or being written\r\n      // Remove it and retry\r\n      logger.debug(`Lock file for ${filePath} is corrupted or unreadable, removing`);\r\n      await unlink(lockFile).catch(() => {});\r\n      return acquireFileLock(filePath);\r\n    }\r\n\r\n    return false; // Lock is held by an active process\r\n  }\r\n}\r\n\r\n/**\r\n * Release a file-based lock\r\n */\r\nasync function releaseFileLock(filePath: string): Promise<void> {\r\n  const lockFile = `${filePath}.lock`;\r\n  activeLockFiles.delete(lockFile);\r\n  await unlink(lockFile).catch(() => {}); // Ignore errors - file might already be gone\r\n}\r\n\r\n/**\r\n * Cleanup handler for graceful shutdown\r\n * Removes any lock files this process holds\r\n */\r\nfunction cleanupLockFiles(): void {\r\n  for (const lockFile of activeLockFiles) {\r\n    try {\r\n      unlinkSync(lockFile); // Must be sync in exit handler\r\n    } catch {\r\n      // Ignore errors during cleanup\r\n    }\r\n  }\r\n  activeLockFiles.clear();\r\n}\r\n\r\n/**\r\n * Clean up any stale lock files in the queue directory\r\n * Called during daemon restart to remove orphaned locks from crashed processes\r\n */\r\nexport async function cleanupStaleLocks(): Promise<void> {\r\n  try {\r\n    const files = await readdir(QUEUE_DIR).catch(() => [] as string[]);\r\n    const lockFiles = files.filter((f) => f.endsWith(\".lock\"));\r\n\r\n    for (const lockFileName of lockFiles) {\r\n      const lockFile = `${QUEUE_DIR}/${lockFileName}`;\r\n      try {\r\n        const content = await readFile(lockFile, \"utf8\");\r\n        const lockInfo: LockInfo = JSON.parse(content);\r\n\r\n        if (!isProcessRunning(lockInfo.pid)) {\r\n          await unlink(lockFile);\r\n          logger.info(`Cleaned up stale lock file: ${lockFileName} (PID ${lockInfo.pid} is dead)`);\r\n        }\r\n      } catch {\r\n        // Corrupted lock file - remove it\r\n        await unlink(lockFile).catch(() => {});\r\n        logger.info(`Removed corrupted lock file: ${lockFileName}`);\r\n      }\r\n    }\r\n  } catch (error) {\r\n    logger.debug(\"Failed to clean up stale locks:\", error);\r\n  }\r\n}\r\n\r\n// Set up cleanup handlers for graceful shutdown\r\nlet cleanupRegistered = false;\r\n\r\n/**\r\n * Register process exit handlers to clean up lock files\r\n * Safe to call multiple times - only registers once\r\n */\r\nexport function setupLockCleanup(): void {\r\n  if (cleanupRegistered) return;\r\n  cleanupRegistered = true;\r\n\r\n  process.on(\"exit\", cleanupLockFiles);\r\n  process.on(\"SIGINT\", () => {\r\n    cleanupLockFiles();\r\n    process.exit(0);\r\n  });\r\n  process.on(\"SIGTERM\", () => {\r\n    cleanupLockFiles();\r\n    process.exit(0);\r\n  });\r\n\r\n  logger.debug(\"Lock cleanup handlers registered\");\r\n}\r\n\r\n/**\r\n * Execute a function with exclusive file-based lock\r\n * Provides cross-process protection for file operations\r\n *\r\n * @param filePath - Path to the file to lock (creates filePath.lock)\r\n * @param fn - Function to execute while holding the lock\r\n * @returns The result of the function\r\n * @throws Error if lock cannot be acquired after max retries\r\n */\r\nexport async function withFileLock<T>(filePath: string, fn: () => Promise<T>): Promise<T> {\r\n  // Acquire file-based lock with retry\r\n  let retries = 0;\r\n  while (!(await acquireFileLock(filePath))) {\r\n    if (++retries >= LOCK_MAX_RETRIES) {\r\n      throw new Error(`Failed to acquire lock for ${filePath} after ${retries} retries`);\r\n    }\r\n    await new Promise((resolve) => setTimeout(resolve, LOCK_RETRY_MS));\r\n  }\r\n\r\n  try {\r\n    return await fn();\r\n  } finally {\r\n    await releaseFileLock(filePath);\r\n  }\r\n}\r\n",
    "/**\r\n * Daemon lifecycle management\r\n *\r\n * Handles PID tracking, daemon startup, and process detection\r\n */\r\n\r\nimport { exec, spawn } from \"node:child_process\";\r\nimport { readFileSync } from \"node:fs\";\r\nimport { readFile, stat, unlink, writeFile } from \"node:fs/promises\";\r\nimport { dirname, join } from \"node:path\";\r\nimport { fileURLToPath } from \"node:url\";\r\nimport { promisify } from \"node:util\";\r\nimport {\r\n  CLAUDE_ZEST_DIR,\r\n  DAEMON_FRESH_PID_THRESHOLD_MS,\r\n  DAEMON_PID_FILE,\r\n} from \"../config/constants.js\";\r\nimport { cleanupStaleLocks, withFileLock } from \"./file-lock.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n// Lock file to prevent concurrent daemon restarts\r\nconst DAEMON_RESTART_LOCK = join(CLAUDE_ZEST_DIR, \"daemon-restart.lock\");\r\n\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = dirname(__filename);\r\n\r\n/**\r\n * Check if a process is running (cross-platform)\r\n * Uses signal 0 which checks existence without actually sending a signal\r\n */\r\nexport function isProcessRunning(pid: number): boolean {\r\n  try {\r\n    process.kill(pid, 0);\r\n    return true;\r\n  } catch {\r\n    return false;\r\n  }\r\n}\r\n\r\n/**\r\n * Start the sync daemon as a detached background process\r\n */\r\nexport async function startDaemon(): Promise<boolean> {\r\n  try {\r\n    // Find the daemon script path\r\n    const daemonScript = join(__dirname, \"..\", \"sync-daemon.js\");\r\n\r\n    // Spawn daemon as detached background process\r\n    const daemon = spawn(process.execPath, [daemonScript], {\r\n      detached: true, // Run independently\r\n      stdio: \"ignore\", // Don't capture output\r\n      windowsHide: true, // Hide console window on Windows\r\n    });\r\n\r\n    // Unref so parent can exit without waiting for daemon\r\n    daemon.unref();\r\n\r\n    // Daemon writes its own PID file when it starts\r\n    // Wait a moment to ensure it's written\r\n    await new Promise((resolve) => setTimeout(resolve, 100));\r\n\r\n    return true;\r\n  } catch (error) {\r\n    logger.error(\"Failed to start daemon:\", error);\r\n    return false;\r\n  }\r\n}\r\n\r\n/**\r\n * Kill all running sync-daemon processes\r\n * This ensures we don't accumulate zombie daemons\r\n */\r\nasync function killAllDaemons(): Promise<void> {\r\n  try {\r\n    // First try to kill the daemon from PID file\r\n    const pid = await getDaemonPid();\r\n    if (pid) {\r\n      try {\r\n        process.kill(pid, \"SIGTERM\");\r\n      } catch {\r\n        // Process might not exist\r\n      }\r\n    }\r\n\r\n    // Also try to kill any other sync-daemon processes using pkill\r\n    // This catches zombies that weren't tracked in PID file\r\n    const execAsync = promisify(exec);\r\n\r\n    try {\r\n      // Kill all sync-daemon.js processes (excluding our own process)\r\n      await execAsync(`pkill -f 'sync-daemon.js' 2>/dev/null || true`);\r\n    } catch {\r\n      // pkill might not find any processes, which is fine\r\n    }\r\n\r\n    // Wait for processes to terminate\r\n    await new Promise((resolve) => setTimeout(resolve, 500));\r\n\r\n    // Clean up PID file\r\n    await cleanupPidFile();\r\n  } catch (error) {\r\n    logger.warn(\"Error during daemon cleanup:\", error);\r\n  }\r\n}\r\n\r\n/**\r\n * Restart daemon - kills ALL existing daemons and starts a fresh one\r\n * Uses file locking to prevent multiple hooks from starting multiple daemons\r\n */\r\nexport async function restartDaemon(): Promise<boolean> {\r\n  try {\r\n    // Use file lock to ensure only ONE process can restart the daemon at a time\r\n    return await withFileLock(DAEMON_RESTART_LOCK, async () => {\r\n      // Check if a daemon was JUST started (within threshold)\r\n      // This prevents the second hook from killing the daemon the first hook just started\r\n      const existingPid = await getDaemonPid();\r\n      if (existingPid) {\r\n        try {\r\n          const pidFileStat = await stat(DAEMON_PID_FILE);\r\n          const ageMs = Date.now() - pidFileStat.mtimeMs;\r\n\r\n          if (ageMs < DAEMON_FRESH_PID_THRESHOLD_MS) {\r\n            // PID file is fresh - daemon was just started by another hook\r\n            return true;\r\n          }\r\n        } catch {\r\n          // Ignore errors checking PID file age\r\n        }\r\n      }\r\n\r\n      // Kill ALL existing daemon processes (not just the one in PID file)\r\n      await killAllDaemons();\r\n\r\n      // Clean up any stale lock files from crashed processes\r\n      await cleanupStaleLocks();\r\n\r\n      // Start new daemon\r\n      return await startDaemon();\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to restart daemon:\", error);\r\n    return false;\r\n  }\r\n}\r\n\r\n/**\r\n * Clean up stale PID file\r\n */\r\nasync function cleanupPidFile(): Promise<void> {\r\n  try {\r\n    await unlink(DAEMON_PID_FILE);\r\n  } catch {\r\n    // Ignore errors - file might not exist\r\n  }\r\n}\r\n\r\n/**\r\n * Write PID to daemon.pid file\r\n * Called by the daemon itself when it starts\r\n */\r\nexport async function writePidFile(pid: number): Promise<void> {\r\n  try {\r\n    await ensureDirectory(dirname(DAEMON_PID_FILE));\r\n    await writeFile(DAEMON_PID_FILE, pid.toString(), \"utf-8\");\r\n    logger.debug(`Wrote PID ${pid} to daemon.pid`);\r\n  } catch (error) {\r\n    logger.error(\"Failed to write PID file:\", error);\r\n  }\r\n}\r\n\r\n/**\r\n * Get daemon PID (if running)\r\n */\r\nexport async function getDaemonPid(): Promise<number | null> {\r\n  try {\r\n    const pidData = await readFile(DAEMON_PID_FILE, \"utf-8\");\r\n    const pid = Number.parseInt(pidData.trim(), 10);\r\n\r\n    if (Number.isNaN(pid)) {\r\n      return null;\r\n    }\r\n\r\n    // Verify process exists\r\n    return isProcessRunning(pid) ? pid : null;\r\n  } catch {\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Check if daemon is running (synchronous version for statusline)\r\n * Verifies both PID file existence and process health\r\n */\r\nexport function isDaemonRunning(): boolean {\r\n  try {\r\n    const pidData = readFileSync(DAEMON_PID_FILE, \"utf-8\");\r\n    const pidStr = pidData.trim();\r\n\r\n    // Check for empty PID file\r\n    if (!pidStr) {\r\n      return false;\r\n    }\r\n\r\n    const pid = Number.parseInt(pidStr, 10);\r\n\r\n    // Check for invalid PID (NaN or non-positive)\r\n    if (Number.isNaN(pid) || pid <= 0) {\r\n      return false;\r\n    }\r\n\r\n    // Verify process exists\r\n    return isProcessRunning(pid);\r\n  } catch {\r\n    // PID file doesn't exist or can't be read\r\n    return false;\r\n  }\r\n}\r\n",
    "/**\r\n * Shared extraction helper functions for hook handlers\r\n *\r\n * Provides reusable logic for finding sessions, extracting data, and queueing events\r\n */\r\n\r\nimport { randomUUID } from \"node:crypto\";\r\nimport { stat } from \"node:fs/promises\";\r\nimport { basename, join } from \"node:path\";\r\nimport { getLanguageFromPath } from \"@zest/utils\";\r\nimport { getValidSession } from \"../auth/session-manager.js\";\r\nimport { CLAUDE_PROJECTS_DIR } from \"../config/constants.js\";\r\nimport { extractNewMessagesFromFile } from \"../extractors/message-parser.js\";\r\nimport type { ToolUse } from \"../types/extractors.js\";\r\nimport type {\r\n  ClaudeExtractedEvent,\r\n  ClaudeExtractedMessage,\r\n  ClaudeExtractedSession,\r\n} from \"../types/index.js\";\r\nimport { shouldExcludeCommand } from \"./command-filters.js\";\r\nimport { logger } from \"./logger.js\";\r\nimport { enqueueChatMessage, enqueueChatSession, enqueueEvent } from \"./queue-manager.js\";\r\nimport { readSessionState, updateLastReadLine } from \"./state-manager.js\";\r\n\r\n/**\r\n * File stats from fs.stat()\r\n */\r\ninterface FileStats {\r\n  birthtime: Date;\r\n  mtime: Date;\r\n  mtimeMs: number;\r\n  size: number;\r\n}\r\n\r\n/**\r\n * Find the most recent Bash command from JSONL file\r\n * Used by PreToolUse hook to detect rm commands before they execute\r\n */\r\nexport async function findRecentBashCommand(conversationFile: string): Promise<string | null> {\r\n  try {\r\n    const { readFile } = await import(\"node:fs/promises\");\r\n    const content = await readFile(conversationFile, \"utf-8\");\r\n    const lines = content\r\n      .trim()\r\n      .split(\"\\n\")\r\n      .filter((l) => l.trim());\r\n\r\n    // Look for the last Bash tool_use in recent lines (last 5 lines)\r\n    for (let i = lines.length - 1; i >= Math.max(0, lines.length - 5); i--) {\r\n      try {\r\n        const entry = JSON.parse(lines[i]);\r\n        if (entry.message?.content && Array.isArray(entry.message.content)) {\r\n          for (const block of entry.message.content) {\r\n            if (block.type === \"tool_use\" && (block.name === \"Bash\" || block.name === \"bash\")) {\r\n              const command = block.input?.command || block.input?.cmd;\r\n              if (command) {\r\n                // Filter out excluded commands\r\n                if (shouldExcludeCommand(command)) {\r\n                  logger.debug(\r\n                    `Filtered out excluded bash command: ${command.substring(0, 50)}...`,\r\n                  );\r\n                  return null;\r\n                }\r\n                return command;\r\n              }\r\n            }\r\n          }\r\n        }\r\n      } catch {\r\n        // Skip invalid lines\r\n      }\r\n    }\r\n\r\n    return null;\r\n  } catch (error) {\r\n    logger.debug(\"Failed to find recent Bash command:\", error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Parse Bash command to detect file deletion operations\r\n */\r\nexport function parseRmCommand(command: string): string[] {\r\n  if (!command) return [];\r\n\r\n  const cmd = command.trim();\r\n\r\n  // Match rm commands: rm, rm -rf, rm -f, etc.\r\n  // Pattern: rm [options] filepath(s)\r\n  const rmMatch = cmd.match(/^rm\\s+(?:-[a-zA-Z]+\\s+)*(.+)$/);\r\n  if (rmMatch) {\r\n    // Extract file paths (may be multiple space-separated paths)\r\n    const pathsString = rmMatch[1].trim();\r\n    // Split by spaces but respect quotes\r\n    const paths =\r\n      pathsString.match(/(?:[^\\s\"']+|\"[^\"]*\"|'[^']*')+/g)?.map((p) => p.replace(/['\"]/g, \"\")) || [];\r\n    return paths;\r\n  }\r\n\r\n  return [];\r\n}\r\n\r\n/**\r\n * Cache multiple files for deletion\r\n * Used by PreToolUse hook to store file content before rm execution\r\n */\r\nexport async function cacheFilesForDeletion(\r\n  filePaths: string[],\r\n  sessionId: string,\r\n  projectDir: string,\r\n): Promise<void> {\r\n  const { readFile } = await import(\"node:fs/promises\");\r\n  const { resolve } = await import(\"node:path\");\r\n  const { cacheFileForDeletion } = await import(\"./deletion-cache.js\");\r\n\r\n  for (const filePath of filePaths) {\r\n    try {\r\n      // Resolve to absolute path, using project directory as base for relative paths\r\n      const absolutePath = filePath.startsWith(\"/\") ? filePath : resolve(projectDir, filePath);\r\n\r\n      // Read file content\r\n      const content = await readFile(absolutePath, \"utf-8\");\r\n\r\n      // Cache the content with absolute path\r\n      await cacheFileForDeletion(absolutePath, content, sessionId);\r\n    } catch (error) {\r\n      // File might not exist or not readable\r\n      logger.debug(`Could not cache ${filePath}:`, error);\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Find the most recent conversation file for a project\r\n */\r\nexport async function findConversationFile(\r\n  projectDir: string,\r\n): Promise<{ conversationFile: string; sessionId: string; fileStats: FileStats } | null> {\r\n  try {\r\n    // Convert CWD to Claude's directory naming convention\r\n    const claudeDirName = projectDir.replace(/\\//g, \"-\");\r\n    const projectPath = join(CLAUDE_PROJECTS_DIR, claudeDirName);\r\n\r\n    logger.debug(`Looking for project directory: ${projectPath}`);\r\n\r\n    // Check if directory exists\r\n    try {\r\n      await stat(projectPath);\r\n    } catch {\r\n      logger.warn(`Project directory not found: ${projectPath}`);\r\n      return null;\r\n    }\r\n\r\n    // Find the most recent JSONL file\r\n    const { readdir } = await import(\"node:fs/promises\");\r\n    const entries = await readdir(projectPath);\r\n    const jsonlFiles = entries.filter((f) => f.endsWith(\".jsonl\"));\r\n\r\n    if (jsonlFiles.length === 0) {\r\n      logger.warn(`No session files found in ${projectPath}`);\r\n      return null;\r\n    }\r\n\r\n    // Get the most recently modified .jsonl file\r\n    let mostRecentFile = jsonlFiles[0];\r\n    let mostRecentTime = 0;\r\n\r\n    for (const file of jsonlFiles) {\r\n      const filePath = join(projectPath, file);\r\n      const stats = await stat(filePath);\r\n      if (stats.mtimeMs > mostRecentTime) {\r\n        mostRecentTime = stats.mtimeMs;\r\n        mostRecentFile = file;\r\n      }\r\n    }\r\n\r\n    const conversationFile = join(projectPath, mostRecentFile);\r\n    const sessionId = basename(mostRecentFile, \".jsonl\");\r\n    const fileStats = await stat(conversationFile);\r\n\r\n    return { conversationFile, sessionId, fileStats };\r\n  } catch (error) {\r\n    logger.error(\"Failed to find conversation file:\", error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Extract new session data (messages and tool uses) from conversation file\r\n * Single Responsibility: Extraction only\r\n */\r\nexport async function extractNewSessionData(\r\n  conversationFile: string,\r\n  sessionId: string,\r\n): Promise<{\r\n  messages: ClaudeExtractedMessage[];\r\n  toolUses: ToolUse[];\r\n  newLastReadLine: number;\r\n  lastMessageIndex: number;\r\n  isNewSession: boolean;\r\n  hasNewData: boolean;\r\n}> {\r\n  // Read extraction state\r\n  const state = await readSessionState(sessionId);\r\n  const lastReadLine = state?.lastReadLine || 0;\r\n  const lastMessageIndex = state?.lastMessageIndex ?? -1; // Start at -1 so first message is 0\r\n  const isNewSession = !state;\r\n\r\n  // Extract only new messages/tool uses\r\n  const { messages, toolUses, newLastReadLine } = await extractNewMessagesFromFile(\r\n    conversationFile,\r\n    sessionId,\r\n    lastReadLine,\r\n  );\r\n\r\n  // Assign sequential message_index to extracted messages\r\n  let nextMessageIndex = lastMessageIndex + 1;\r\n  for (const message of messages) {\r\n    message.message_index = nextMessageIndex++;\r\n  }\r\n\r\n  const hasNewData = messages.length > 0 || toolUses.length > 0;\r\n\r\n  return {\r\n    messages,\r\n    toolUses,\r\n    newLastReadLine,\r\n    lastMessageIndex: nextMessageIndex - 1, // Last assigned index\r\n    isNewSession,\r\n    hasNewData,\r\n  };\r\n}\r\n\r\n/**\r\n * Queue extracted session data (session info, messages, and events)\r\n * Single Responsibility: Queuing only\r\n */\r\nexport async function queueSessionData(\r\n  sessionId: string,\r\n  messages: ClaudeExtractedMessage[],\r\n  toolUses: ToolUse[],\r\n  fileStats: FileStats,\r\n  projectDir: string,\r\n  conversationFile: string,\r\n  newLastReadLine: number,\r\n  lastMessageIndex: number,\r\n  isNewSession: boolean,\r\n): Promise<{ messagesQueued: number; eventsQueued: number }> {\r\n  // Queue the session info (first time only)\r\n  if (isNewSession) {\r\n    const session: ClaudeExtractedSession = {\r\n      id: sessionId,\r\n      title: messages.length > 0 ? messages[0].content.substring(0, 100) : `Session ${sessionId}`,\r\n      created_at: fileStats.birthtime.toISOString(),\r\n    };\r\n    await enqueueChatSession(session);\r\n  }\r\n\r\n  // Queue all messages (minimal extracted data)\r\n  for (const message of messages) {\r\n    const extractedMessage: ClaudeExtractedMessage = {\r\n      id: message.id,\r\n      session_id: message.session_id,\r\n      message_index: message.message_index,\r\n      role: message.role,\r\n      content: message.content,\r\n      created_at: message.created_at,\r\n    };\r\n    await enqueueChatMessage(extractedMessage);\r\n  }\r\n\r\n  // Convert tool uses to code digest events with filtering\r\n  const eventsQueued = await queueToolUseEvents(toolUses, sessionId, projectDir);\r\n\r\n  // Update state with new line number and last message index\r\n  await updateLastReadLine(sessionId, conversationFile, newLastReadLine, lastMessageIndex);\r\n\r\n  return { messagesQueued: messages.length, eventsQueued };\r\n}\r\n\r\n/**\r\n * Queue tool use events (with filtering for file edits with diffs)\r\n */\r\nasync function queueToolUseEvents(\r\n  toolUses: ToolUse[],\r\n  sessionId: string,\r\n  projectDir: string,\r\n): Promise<number> {\r\n  // FILTER: Only include file edits with actual code diffs (exclude Read operations and edits without diffs)\r\n  // Get workspace ID from user's session\r\n  const session = await getValidSession();\r\n  const workspaceId = session?.workspaceId || null;\r\n\r\n  let queuedEventCount = 0;\r\n\r\n  for (const toolUse of toolUses) {\r\n    // Skip if no file path\r\n    if (!toolUse.file_path) continue;\r\n\r\n    // Skip Read operations (we only want file edits)\r\n    if (toolUse.tool_name === \"Read\" || toolUse.tool_name === \"read\") {\r\n      continue;\r\n    }\r\n\r\n    // Skip operations that don't have a diff (no actual code change)\r\n    if (!toolUse.diff) {\r\n      continue;\r\n    }\r\n\r\n    const event: ClaudeExtractedEvent = {\r\n      id: randomUUID(),\r\n      timestamp: toolUse.timestamp,\r\n      document_uri: toolUse.file_path,\r\n      language_id: getLanguageFromPath(toolUse.file_path),\r\n      workspace_folder_uri: projectDir || null,\r\n      session_id: sessionId,\r\n      workspace_id: workspaceId,\r\n      payload: {\r\n        tool_name: toolUse.tool_name,\r\n        session_id: sessionId,\r\n        diff: toolUse.diff, // Already sanitized unified diff string\r\n      },\r\n    };\r\n\r\n    await enqueueEvent(event);\r\n    queuedEventCount++;\r\n  }\r\n\r\n  return queuedEventCount;\r\n}\r\n",
    "/**\r\n * Session management\r\n *\r\n * Handles session persistence, validation, and token refresh\r\n */\r\n\r\nimport { readFile, unlink, writeFile } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport { createClient } from \"@supabase/supabase-js\";\r\nimport type { Database } from \"@zest/types/database.types\";\r\nimport {\r\n  PROACTIVE_REFRESH_THRESHOLD_MS,\r\n  SESSION_FILE,\r\n  SUPABASE_ANON_KEY,\r\n  SUPABASE_URL,\r\n} from \"../config/constants.js\";\r\nimport { ensureDirectory } from \"../utils/fs-utils.js\";\r\nimport { logger } from \"../utils/logger.js\";\r\n\r\nexport interface AuthSession {\r\n  accessToken: string;\r\n  refreshToken: string;\r\n  expiresAt: number; // Access token expiration (milliseconds)\r\n  refreshTokenExpiresAt?: number; // Refresh token expiration (milliseconds) - optional for backward compatibility\r\n  userId: string;\r\n  email: string;\r\n  workspaceId?: string;\r\n  workspaceName?: string;\r\n}\r\n\r\n/**\r\n * Load session from file\r\n */\r\nexport async function loadSession(): Promise<AuthSession | null> {\r\n  try {\r\n    const content = await readFile(SESSION_FILE, \"utf-8\");\r\n    const session = JSON.parse(content) as AuthSession;\r\n\r\n    // Validate session structure\r\n    if (\r\n      !session.accessToken ||\r\n      !session.refreshToken ||\r\n      !session.expiresAt ||\r\n      !session.userId ||\r\n      !session.email\r\n    ) {\r\n      logger.warn(\"Invalid session structure, clearing session\");\r\n      await clearSession();\r\n      return null;\r\n    }\r\n\r\n    const now = Date.now();\r\n\r\n    // Check if refresh token is expired (only if expiration is set - many configs have refresh tokens that never expire)\r\n    if (session.refreshTokenExpiresAt && session.refreshTokenExpiresAt < now) {\r\n      logger.warn(\"Refresh token expired, user must re-authenticate\");\r\n      await clearSession();\r\n      return null;\r\n    }\r\n\r\n    // Check if access token is expired\r\n    if (session.expiresAt < now) {\r\n      logger.debug(\"Access token expired, attempting refresh\");\r\n      try {\r\n        return await refreshSession(session);\r\n      } catch (error) {\r\n        logger.warn(\"Failed to refresh session\", error);\r\n        await clearSession();\r\n        return null;\r\n      }\r\n    }\r\n\r\n    return session;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist - not an error\r\n      return null;\r\n    }\r\n    logger.error(\"Failed to load session\", error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Save session to file with secure permissions\r\n */\r\nexport async function saveSession(session: AuthSession): Promise<void> {\r\n  try {\r\n    // Ensure directory exists\r\n    await ensureDirectory(dirname(SESSION_FILE));\r\n\r\n    // Write session file\r\n    await writeFile(SESSION_FILE, JSON.stringify(session, null, 2), {\r\n      encoding: \"utf-8\",\r\n      mode: 0o600, // Readable/writable by owner only\r\n    });\r\n\r\n    logger.info(\"Session saved successfully\");\r\n  } catch (error) {\r\n    logger.error(\"Failed to save session\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Clear session file\r\n */\r\nexport async function clearSession(): Promise<void> {\r\n  try {\r\n    await unlink(SESSION_FILE);\r\n    logger.info(\"Session cleared successfully\");\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist - not an error\r\n      return;\r\n    }\r\n    logger.error(\"Failed to clear session\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Refresh an expired session using the refresh token\r\n * Uses Supabase JS client library for proper token handling\r\n */\r\nexport async function refreshSession(session: AuthSession): Promise<AuthSession> {\r\n  try {\r\n    const now = Date.now();\r\n    const timeUntilExpiration = session.expiresAt - now;\r\n\r\n    logger.debug(\"=== Starting Token Refresh ===\");\r\n    logger.debug(`Current access token expires at: ${new Date(session.expiresAt).toISOString()}`);\r\n    logger.debug(`Time until expiration: ${Math.round(timeUntilExpiration / 1000)}s`);\r\n    logger.debug(`Token is ${timeUntilExpiration < 0 ? \"EXPIRED\" : \"still valid\"}`);\r\n\r\n    if (session.refreshTokenExpiresAt) {\r\n      const timeUntilRefreshExpiration = session.refreshTokenExpiresAt - now;\r\n      logger.debug(\r\n        `Refresh token expires at: ${new Date(session.refreshTokenExpiresAt).toISOString()}`,\r\n      );\r\n      logger.debug(\r\n        `Refresh token time remaining: ${Math.round(timeUntilRefreshExpiration / 1000)}s`,\r\n      );\r\n    } else {\r\n      logger.debug(\"Refresh token: Never expires\");\r\n    }\r\n\r\n    // Check configuration\r\n    if (!SUPABASE_URL || !SUPABASE_ANON_KEY) {\r\n      throw new Error(\"Supabase configuration missing (URL or anon key)\");\r\n    }\r\n\r\n    logger.debug(\"Using Supabase JS client to refresh session\");\r\n    logger.debug(`Supabase URL: ${SUPABASE_URL}`);\r\n    logger.debug(`Refresh token length: ${session.refreshToken.length} characters`);\r\n\r\n    // Create a Supabase client for token refresh\r\n    const supabase = createClient<Database>(SUPABASE_URL, SUPABASE_ANON_KEY, {\r\n      auth: {\r\n        persistSession: false,\r\n        autoRefreshToken: false,\r\n      },\r\n    });\r\n\r\n    // Use Supabase client's refreshSession method\r\n    // This properly handles OAuth client association\r\n    const { data, error } = await supabase.auth.refreshSession({\r\n      refresh_token: session.refreshToken,\r\n    });\r\n\r\n    if (error) {\r\n      logger.error(`Supabase refresh error: ${error.message}`, error);\r\n      throw new Error(`Token refresh failed: ${error.message}`);\r\n    }\r\n\r\n    if (!data.session) {\r\n      throw new Error(\"Token refresh failed: No session returned from Supabase\");\r\n    }\r\n\r\n    logger.debug(\"Refresh response received successfully from Supabase\");\r\n    logger.debug(`New access token length: ${data.session.access_token.length} characters`);\r\n    logger.debug(`New refresh token length: ${data.session.refresh_token.length} characters`);\r\n    logger.debug(`Access token expires in: ${data.session.expires_in || \"unknown\"} seconds`);\r\n\r\n    // Calculate access token expiration time\r\n    let expiresAt: number;\r\n    if (data.session.expires_at) {\r\n      // Supabase returns expires_at in seconds, convert to milliseconds\r\n      expiresAt = data.session.expires_at * 1000;\r\n    } else if (data.session.expires_in) {\r\n      // Fallback: use expires_in (seconds) to calculate expiration\r\n      expiresAt = now + data.session.expires_in * 1000;\r\n    } else {\r\n      // Default: assume 1 hour expiration (Supabase default)\r\n      expiresAt = now + 3600 * 1000;\r\n      logger.warn(\"No expiration info from Supabase, assuming 1 hour\");\r\n    }\r\n\r\n    // Refresh token expiration typically doesn't change, keep existing value\r\n    const refreshTokenExpiresAt = session.refreshTokenExpiresAt;\r\n\r\n    // Check if tokens actually changed\r\n    const accessTokenChanged = session.accessToken !== data.session.access_token;\r\n    const refreshTokenChanged = session.refreshToken !== data.session.refresh_token;\r\n\r\n    logger.debug(`Access token changed: ${accessTokenChanged}`);\r\n    logger.debug(`Refresh token changed: ${refreshTokenChanged}`);\r\n\r\n    if (!accessTokenChanged) {\r\n      logger.warn(\"  Access token did not change after refresh - this might indicate an issue\");\r\n    }\r\n    if (!refreshTokenChanged) {\r\n      logger.debug(\"Refresh token did not change (this is normal for Supabase)\");\r\n    }\r\n\r\n    const newSession: AuthSession = {\r\n      ...session,\r\n      accessToken: data.session.access_token,\r\n      refreshToken: data.session.refresh_token,\r\n      expiresAt,\r\n      refreshTokenExpiresAt,\r\n      userId: data.session.user.id,\r\n      email: data.session.user.email || session.email,\r\n    };\r\n\r\n    logger.debug(`New access token will expire at: ${new Date(expiresAt).toISOString()}`);\r\n    logger.debug(\r\n      `New expiration is ${Math.round((expiresAt - session.expiresAt) / 1000)}s from old expiration`,\r\n    );\r\n\r\n    if (refreshTokenExpiresAt) {\r\n      logger.debug(\r\n        `Refresh token will expire at: ${new Date(refreshTokenExpiresAt).toISOString()}`,\r\n      );\r\n    } else {\r\n      logger.debug(\"Refresh token does not expire\");\r\n    }\r\n\r\n    logger.debug(\"Saving new session to file...\");\r\n    await saveSession(newSession);\r\n    logger.info(\" Session refreshed and saved successfully\");\r\n    logger.debug(\"=== Token Refresh Complete ===\");\r\n\r\n    return newSession;\r\n  } catch (error) {\r\n    logger.error(\" Failed to refresh session\", error);\r\n    if (error instanceof Error) {\r\n      logger.debug(`Error type: ${error.constructor.name}`);\r\n      logger.debug(`Error message: ${error.message}`);\r\n      if (error.stack) {\r\n        logger.debug(`Error stack: ${error.stack}`);\r\n      }\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Check if user is currently authenticated\r\n */\r\nexport async function isAuthenticated(): Promise<boolean> {\r\n  const session = await loadSession();\r\n  return session !== null && session.expiresAt > Date.now();\r\n}\r\n\r\n/**\r\n * Get current session (refresh if needed)\r\n *\r\n * Proactively refreshes tokens 5 minutes before expiration\r\n */\r\nexport async function getValidSession(): Promise<AuthSession | null> {\r\n  const session = await loadSession();\r\n  if (!session) {\r\n    logger.debug(\"getValidSession: No session found\");\r\n    return null;\r\n  }\r\n\r\n  if (session.expiresAt < Date.now() + PROACTIVE_REFRESH_THRESHOLD_MS) {\r\n    try {\r\n      const refreshedSession = await refreshSession(session);\r\n      return refreshedSession;\r\n    } catch (error) {\r\n      logger.warn(\"getValidSession: Failed to refresh session\", error);\r\n      return null;\r\n    }\r\n  }\r\n  return session;\r\n}\r\n",
    "/**\r\n * Command filtering utilities\r\n *\r\n * Filters out Claude Code and Zest plugin commands from tracking\r\n */\r\n\r\nimport { EXCLUDED_COMMAND_PATTERNS } from \"../config/constants.js\";\r\nimport { extractTextContent } from \"../extractors/extraction-utils.js\";\r\nimport type { ClaudeJSONLEntry } from \"../types/extractors.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n/**\r\n * Check if a message or command should be excluded from tracking\r\n * Filters out Claude Code and Zest plugin commands\r\n */\r\nexport function shouldExcludeCommand(command: string): boolean {\r\n  const trimmedCommand = command.trim();\r\n\r\n  // Check against all excluded patterns\r\n  for (const pattern of EXCLUDED_COMMAND_PATTERNS) {\r\n    if (pattern.test(trimmedCommand)) {\r\n      return true;\r\n    }\r\n  }\r\n\r\n  return false;\r\n}\r\n\r\n/**\r\n * Check if a message is a Zest command that was explicitly typed by the user\r\n * (not a command continuation like a single digit)\r\n */\r\nexport function isExplicitZestCommand(command: string): boolean {\r\n  const trimmedCommand = command.trim();\r\n  // Match /zest: commands (e.g., /zest:workspace, /zest:status)\r\n  return /^\\/zest[^:\\s]*:/i.test(trimmedCommand);\r\n}\r\n\r\n/**\r\n * Check if a message is a digit-only command continuation (1-2 digits)\r\n * Used for commands like /zest:workspace where user can enter just \"1\" to select\r\n */\r\nexport function isDigitContinuation(message: string): boolean {\r\n  const trimmed = message.trim();\r\n  return /^\\d{1,2}$/.test(trimmed);\r\n}\r\n\r\n/**\r\n * Restore filtering state by looking back at recent user messages\r\n *\r\n * For incremental extraction, we need to check if the last user message\r\n * was a filtered command to correctly initialize the filtering state\r\n *\r\n * @param lines - All lines from the JSONL file\r\n * @param lastReadLine - Last line that was already processed\r\n * @returns FilteringState with both flags initialized\r\n */\r\nexport function restoreFilteringState(lines: string[], lastReadLine: number): FilteringState {\r\n  if (lastReadLine === 0) {\r\n    return { filteringAssistantResponses: false, lastWasZestCommand: false };\r\n  }\r\n\r\n  // Look back at already-processed lines to restore filtering state\r\n  // Check the last few lines (up to 10) to find the most recent user message\r\n  const lookbackLines = lines.slice(Math.max(0, lastReadLine - 10), lastReadLine);\r\n\r\n  for (let i = lookbackLines.length - 1; i >= 0; i--) {\r\n    try {\r\n      const entry: ClaudeJSONLEntry = JSON.parse(lookbackLines[i]);\r\n      if (entry.message?.role === \"user\" && entry.message.content) {\r\n        const textContent = extractTextContent(entry.message.content);\r\n        if (textContent) {\r\n          const isFiltered = shouldExcludeCommand(textContent);\r\n          const isZestCmd = isExplicitZestCommand(textContent);\r\n\r\n          if (isFiltered) {\r\n            // Last user message was filtered - start with filtering enabled\r\n            logger.debug(\r\n              `Restored filtering state: last user message was filtered command: ${textContent.substring(0, 50)}...`,\r\n            );\r\n            return { filteringAssistantResponses: true, lastWasZestCommand: isZestCmd };\r\n          }\r\n        }\r\n        break; // Found the last user message, stop looking\r\n      }\r\n    } catch {\r\n      // Skip invalid lines\r\n    }\r\n  }\r\n\r\n  return { filteringAssistantResponses: false, lastWasZestCommand: false };\r\n}\r\n\r\n/**\r\n * Filtering state for the message parser\r\n */\r\nexport interface FilteringState {\r\n  filteringAssistantResponses: boolean; // Should we filter the next assistant response?\r\n  lastWasZestCommand: boolean; // Was the last user message a zest command?\r\n}\r\n\r\n/**\r\n * Apply state-based filtering logic to a message\r\n *\r\n * State machine:\r\n * - When user sends excluded command: start filtering assistant responses\r\n * - When user sends explicit zest command: mark for potential digit continuation\r\n * - When user sends digit-only message after zest command: filter it and assistant response\r\n * - When user sends normal message: stop filtering assistant responses\r\n * - When assistant message arrives: filter if state flag is true\r\n *\r\n * @param role - Message role (\"user\" or \"assistant\")\r\n * @param textContent - Message text content\r\n * @param currentState - Current filtering state\r\n * @returns Object with shouldFilter flag and updated state\r\n */\r\nexport function applyMessageFilter(\r\n  role: string,\r\n  textContent: string,\r\n  currentState: FilteringState,\r\n): { shouldFilter: boolean; newState: FilteringState } {\r\n  if (role === \"user\") {\r\n    // Check if this is a digit continuation after a zest command\r\n    if (currentState.lastWasZestCommand && isDigitContinuation(textContent)) {\r\n      // Filter this digit message and start filtering assistant responses\r\n      // Reset lastWasZestCommand to prevent subsequent messages from being filtered\r\n      return {\r\n        shouldFilter: true,\r\n        newState: { filteringAssistantResponses: true, lastWasZestCommand: false },\r\n      };\r\n    }\r\n\r\n    // Check if this is an explicit zest command first (more specific check)\r\n    const isZestCmd = isExplicitZestCommand(textContent);\r\n    if (isZestCmd) {\r\n      // User sent a zest command - start filtering assistant responses and set zest flag\r\n      return {\r\n        shouldFilter: true,\r\n        newState: { filteringAssistantResponses: true, lastWasZestCommand: true },\r\n      };\r\n    }\r\n\r\n    // Check if user message matches other excluded command patterns\r\n    if (shouldExcludeCommand(textContent)) {\r\n      // User sent a non-zest excluded command - filter without setting zest flag\r\n      return {\r\n        shouldFilter: true,\r\n        newState: { filteringAssistantResponses: true, lastWasZestCommand: false },\r\n      };\r\n    }\r\n\r\n    // User sent normal message - stop filtering assistant responses and reset zest flag\r\n    return {\r\n      shouldFilter: false,\r\n      newState: { filteringAssistantResponses: false, lastWasZestCommand: false },\r\n    };\r\n  }\r\n\r\n  if (role === \"assistant\") {\r\n    // If we're filtering assistant responses, skip this message\r\n    if (currentState.filteringAssistantResponses) {\r\n      return { shouldFilter: true, newState: currentState };\r\n    }\r\n  }\r\n\r\n  // Don't filter, keep current state\r\n  return { shouldFilter: false, newState: currentState };\r\n}\r\n",
    "/**\r\n * Utility functions for extracting data from Claude JSONL entries\r\n */\r\n\r\nimport { createHash } from \"node:crypto\";\r\nimport {\r\n  MAX_CONTENT_PREVIEW_LENGTH,\r\n  MAX_SESSION_TITLE_LENGTH,\r\n  MIN_SESSION_TITLE_LENGTH,\r\n} from \"../config/constants.js\";\r\nimport type { ClaudeJSONLEntry, ContentBlock, ToolInput, ToolUse } from \"../types/extractors.js\";\r\nimport { shouldExcludeCommand } from \"../utils/command-filters.js\";\r\nimport { getCachedFileContent } from \"../utils/deletion-cache.js\";\r\nimport { sanitizeDiff } from \"../utils/diff-utils.js\";\r\nimport { logger } from \"../utils/logger.js\";\r\n\r\n/**\r\n * Extract text content from message content field\r\n */\r\nexport function extractTextContent(content: string | ContentBlock[]): string {\r\n  if (typeof content === \"string\") {\r\n    return content;\r\n  }\r\n\r\n  if (Array.isArray(content)) {\r\n    const textBlocks = content\r\n      .filter((block) => block.type === \"text\" && block.text)\r\n      .map((block) => block.text);\r\n    return textBlocks.join(\"\\n\");\r\n  }\r\n\r\n  return \"\";\r\n}\r\n\r\n/**\r\n * Parse Bash command to extract file paths from file operation commands\r\n * Handles: rm commands (including multiple files)\r\n * Returns array of operations (one per file)\r\n */\r\nfunction parseBashCommand(command: string): Array<{ operation: string; filePath: string }> {\r\n  if (!command) return [];\r\n\r\n  const cmd = command.trim();\r\n\r\n  // Match rm commands: rm, rm -rf, rm -f, etc.\r\n  // Pattern: rm [options] filepath(s)\r\n  const rmMatch = cmd.match(/^rm\\s+(?:-[a-zA-Z]+\\s+)*(.+)$/);\r\n  if (rmMatch) {\r\n    const pathsString = rmMatch[1].trim();\r\n\r\n    // Split by spaces but respect quotes\r\n    const paths =\r\n      pathsString.match(/(?:[^\\s\"']+|\"[^\"]*\"|'[^']*')+/g)?.map((p) => p.replace(/['\"]/g, \"\")) || [];\r\n\r\n    return paths.map((filePath) => ({ operation: \"Delete\", filePath }));\r\n  }\r\n\r\n  return [];\r\n}\r\n\r\n/**\r\n * Extract tool use information (file path, operation, etc.)\r\n * This captures tool_use content blocks from assistant messages\r\n * Returns an array to support multiple files in a single command (e.g., rm file1 file2)\r\n */\r\nexport async function extractToolUse(\r\n  contentBlock: ContentBlock,\r\n  sessionId: string,\r\n  timestamp?: string,\r\n): Promise<ToolUse[]> {\r\n  try {\r\n    const toolName = contentBlock.name;\r\n    const input: ToolInput = contentBlock.input || {};\r\n\r\n    if (!toolName) return [];\r\n\r\n    // Extract file path from various tool formats\r\n    let filePath: string | undefined;\r\n    let content: string | undefined;\r\n    let operationType: string = toolName; // Default to original tool name\r\n\r\n    // Bash tool (shell commands including file operations)\r\n    if (toolName === \"Bash\" || toolName === \"bash\" || toolName === \"Shell\") {\r\n      const command = input.command || input.cmd;\r\n      if (command) {\r\n        // Filter out excluded commands (Claude Code and Zest plugin commands)\r\n        if (shouldExcludeCommand(command)) {\r\n          logger.debug(`Filtered out excluded bash command: ${command.substring(0, 50)}...`);\r\n          return [];\r\n        }\r\n\r\n        const parsedOperations = parseBashCommand(command);\r\n        if (parsedOperations.length > 0) {\r\n          // Handle multiple file operations from a single Bash command\r\n          const toolUses: ToolUse[] = [];\r\n\r\n          for (const parsed of parsedOperations) {\r\n            const toolUse: ToolUse = {\r\n              session_id: sessionId,\r\n              tool_name: parsed.operation,\r\n              file_path: parsed.filePath,\r\n              timestamp: timestamp || new Date().toISOString(),\r\n            };\r\n\r\n            // For Delete operations, try to retrieve cached file content\r\n            if (parsed.operation === \"Delete\") {\r\n              const cachedContent = await getCachedFileContent(parsed.filePath, sessionId);\r\n\r\n              // Check if cache was found (null means not found, empty string is valid)\r\n              if (cachedContent !== null) {\r\n                toolUse.diff = sanitizeDiff(\r\n                  { old_string: cachedContent, new_string: \"\" },\r\n                  parsed.filePath,\r\n                );\r\n                logger.info(`Generated deletion diff for ${parsed.filePath}`);\r\n              } else {\r\n                logger.warn(\r\n                  `No cached content found for ${parsed.filePath} - tracking without diff`,\r\n                );\r\n              }\r\n            }\r\n\r\n            toolUses.push(toolUse);\r\n          }\r\n\r\n          return toolUses;\r\n        }\r\n      }\r\n    }\r\n    // Write tool (file creation)\r\n    else if (toolName === \"Write\" || toolName === \"write\") {\r\n      filePath = input.file_path || input.path;\r\n      content = input.content || input.contents;\r\n    }\r\n    // Edit tool (StrReplace in Claude Code)\r\n    else if (toolName === \"Edit\" || toolName === \"StrReplace\" || toolName === \"str_replace\") {\r\n      filePath = input.file_path || input.path;\r\n    }\r\n    // Delete tool (file deletion) - keeping for compatibility\r\n    else if (toolName === \"Delete\" || toolName === \"delete\" || toolName === \"rm\") {\r\n      filePath = input.file_path || input.path;\r\n    }\r\n    // EditNotebook tool\r\n    else if (toolName === \"EditNotebook\" || toolName === \"edit_notebook\") {\r\n      filePath = input.target_notebook || input.notebook_path;\r\n    }\r\n    // Read tool (also tracking reads for context)\r\n    else if (toolName === \"Read\" || toolName === \"read\") {\r\n      filePath = input.file_path || input.path;\r\n    }\r\n\r\n    if (!filePath) {\r\n      // Try generic path fields\r\n      filePath = input.path || input.file_path || input.filepath;\r\n    }\r\n\r\n    if (!filePath) {\r\n      return [];\r\n    }\r\n\r\n    const toolUse: ToolUse = {\r\n      session_id: sessionId,\r\n      tool_name: operationType,\r\n      file_path: filePath,\r\n      content: content?.substring(0, MAX_CONTENT_PREVIEW_LENGTH),\r\n      timestamp: timestamp || new Date().toISOString(),\r\n    };\r\n\r\n    // For Write operations (file creation), generate diff from content\r\n    if ((operationType === \"Write\" || operationType === \"write\") && content) {\r\n      toolUse.diff = sanitizeDiff({ old_string: \"\", new_string: content }, filePath);\r\n    }\r\n\r\n    return [toolUse];\r\n  } catch (error) {\r\n    logger.debug(\"Failed to extract tool use:\", error);\r\n    return [];\r\n  }\r\n}\r\n\r\n/**\r\n * Determine tool name based on operation type\r\n * Maps Claude's toolUseResult.type to our standard tool names\r\n */\r\nfunction getToolNameFromResultType(type?: string, oldString?: string, newString?: string): string {\r\n  // Explicit type from Claude\r\n  if (type === \"create\") return \"Write\";\r\n  if (type === \"delete\") return \"Delete\";\r\n\r\n  // Infer from content: if no old content but has new content, it's a create\r\n  if (!oldString && newString) return \"Write\";\r\n\r\n  // Infer from content: if has old content but no new content, it's a delete\r\n  if (oldString && !newString) return \"Delete\";\r\n\r\n  // Default to Edit for modifications\r\n  return \"Edit\";\r\n}\r\n\r\n/**\r\n * Extract tool use result with code diffs\r\n *\r\n * Handles:\r\n * - File creation (type: \"create\", or oldString empty with newString present)\r\n * - File editing (type: \"edit\", or both oldString and newString present)\r\n * - File deletion (type: \"delete\", or oldString present with newString empty)\r\n */\r\nexport function extractToolUseResult(entry: ClaudeJSONLEntry, sessionId: string): ToolUse | null {\r\n  try {\r\n    const result = entry.toolUseResult;\r\n    if (!result || !result.filePath) return null;\r\n\r\n    const toolName = getToolNameFromResultType(result.type, result.oldString, result.newString);\r\n\r\n    const toolUse: ToolUse = {\r\n      session_id: sessionId,\r\n      tool_name: toolName,\r\n      file_path: result.filePath,\r\n      timestamp: entry.timestamp || new Date().toISOString(),\r\n    };\r\n\r\n    // Add diff information if available\r\n    // sanitizeDiff now handles file creation (empty old) and deletion (empty new)\r\n    if (\r\n      result.structuredPatch ||\r\n      result.oldString !== undefined ||\r\n      result.newString !== undefined\r\n    ) {\r\n      const rawDiff = {\r\n        old_string: result.oldString,\r\n        new_string: result.newString,\r\n        structured_patch: result.structuredPatch,\r\n      };\r\n      toolUse.diff = sanitizeDiff(rawDiff, result.filePath);\r\n    }\r\n\r\n    return toolUse;\r\n  } catch (error) {\r\n    logger.debug(\"Failed to extract tool use result:\", error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Extract session title from first user message\r\n */\r\nexport function extractSessionTitleFromContent(content: string): string | null {\r\n  const lines = content.split(\"\\n\").filter((line) => line.trim());\r\n\r\n  // Find first user message\r\n  for (const line of lines) {\r\n    try {\r\n      const entry: ClaudeJSONLEntry = JSON.parse(line);\r\n      if (entry.message?.role === \"user\" && entry.message.content) {\r\n        const text = extractTextContent(entry.message.content);\r\n        if (text && text.length >= MIN_SESSION_TITLE_LENGTH) {\r\n          // Use first MAX_SESSION_TITLE_LENGTH characters as title\r\n          return text.substring(0, MAX_SESSION_TITLE_LENGTH).trim();\r\n        }\r\n      }\r\n    } catch {\r\n      // Skip invalid lines\r\n    }\r\n  }\r\n\r\n  return null;\r\n}\r\n\r\n/**\r\n * Generate a deterministic message ID\r\n */\r\nexport function generateMessageId(sessionId: string, messageIndex: number): string {\r\n  const hash = createHash(\"sha256\").update(`${sessionId}-${messageIndex}`).digest(\"hex\");\r\n  return `msg_${hash.substring(0, 16)}`;\r\n}\r\n\r\n/**\r\n * Log code diff information\r\n */\r\nexport function logDiff(filePath: string, diff?: string): void {\r\n  if (!diff) return;\r\n\r\n  logger.info(`Code change detected in ${filePath}:`);\r\n\r\n  // Log first few lines of the unified diff\r\n  const lines = diff.split(\"\\n\").slice(0, 10);\r\n  for (const line of lines) {\r\n    logger.info(`  ${line}`);\r\n  }\r\n  if (diff.split(\"\\n\").length > 10) {\r\n    logger.info(\"  ...\");\r\n  }\r\n}\r\n",
    "var Diff = /** @class */ (function () {\n    function Diff() {\n    }\n    Diff.prototype.diff = function (oldString, newString, \n    // Type below is not accurate/complete - see above for full possibilities - but it compiles\n    options) {\n        if (options === void 0) { options = {}; }\n        var callback;\n        if (typeof options === 'function') {\n            callback = options;\n            options = {};\n        }\n        else if ('callback' in options) {\n            callback = options.callback;\n        }\n        // Allow subclasses to massage the input prior to running\n        oldString = this.castInput(oldString, options);\n        newString = this.castInput(newString, options);\n        var oldTokens = this.removeEmpty(this.tokenize(oldString, options));\n        var newTokens = this.removeEmpty(this.tokenize(newString, options));\n        return this.diffWithOptionsObj(oldTokens, newTokens, options, callback);\n    };\n    Diff.prototype.diffWithOptionsObj = function (oldTokens, newTokens, options, callback) {\n        var _this = this;\n        var _a;\n        var done = function (value) {\n            value = _this.postProcess(value, options);\n            if (callback) {\n                setTimeout(function () { callback(value); }, 0);\n                return undefined;\n            }\n            else {\n                return value;\n            }\n        };\n        var newLen = newTokens.length, oldLen = oldTokens.length;\n        var editLength = 1;\n        var maxEditLength = newLen + oldLen;\n        if (options.maxEditLength != null) {\n            maxEditLength = Math.min(maxEditLength, options.maxEditLength);\n        }\n        var maxExecutionTime = (_a = options.timeout) !== null && _a !== void 0 ? _a : Infinity;\n        var abortAfterTimestamp = Date.now() + maxExecutionTime;\n        var bestPath = [{ oldPos: -1, lastComponent: undefined }];\n        // Seed editLength = 0, i.e. the content starts with the same values\n        var newPos = this.extractCommon(bestPath[0], newTokens, oldTokens, 0, options);\n        if (bestPath[0].oldPos + 1 >= oldLen && newPos + 1 >= newLen) {\n            // Identity per the equality and tokenizer\n            return done(this.buildValues(bestPath[0].lastComponent, newTokens, oldTokens));\n        }\n        // Once we hit the right edge of the edit graph on some diagonal k, we can\n        // definitely reach the end of the edit graph in no more than k edits, so\n        // there's no point in considering any moves to diagonal k+1 any more (from\n        // which we're guaranteed to need at least k+1 more edits).\n        // Similarly, once we've reached the bottom of the edit graph, there's no\n        // point considering moves to lower diagonals.\n        // We record this fact by setting minDiagonalToConsider and\n        // maxDiagonalToConsider to some finite value once we've hit the edge of\n        // the edit graph.\n        // This optimization is not faithful to the original algorithm presented in\n        // Myers's paper, which instead pointlessly extends D-paths off the end of\n        // the edit graph - see page 7 of Myers's paper which notes this point\n        // explicitly and illustrates it with a diagram. This has major performance\n        // implications for some common scenarios. For instance, to compute a diff\n        // where the new text simply appends d characters on the end of the\n        // original text of length n, the true Myers algorithm will take O(n+d^2)\n        // time while this optimization needs only O(n+d) time.\n        var minDiagonalToConsider = -Infinity, maxDiagonalToConsider = Infinity;\n        // Main worker method. checks all permutations of a given edit length for acceptance.\n        var execEditLength = function () {\n            for (var diagonalPath = Math.max(minDiagonalToConsider, -editLength); diagonalPath <= Math.min(maxDiagonalToConsider, editLength); diagonalPath += 2) {\n                var basePath = void 0;\n                var removePath = bestPath[diagonalPath - 1], addPath = bestPath[diagonalPath + 1];\n                if (removePath) {\n                    // No one else is going to attempt to use this value, clear it\n                    // @ts-expect-error - perf optimisation. This type-violating value will never be read.\n                    bestPath[diagonalPath - 1] = undefined;\n                }\n                var canAdd = false;\n                if (addPath) {\n                    // what newPos will be after we do an insertion:\n                    var addPathNewPos = addPath.oldPos - diagonalPath;\n                    canAdd = addPath && 0 <= addPathNewPos && addPathNewPos < newLen;\n                }\n                var canRemove = removePath && removePath.oldPos + 1 < oldLen;\n                if (!canAdd && !canRemove) {\n                    // If this path is a terminal then prune\n                    // @ts-expect-error - perf optimisation. This type-violating value will never be read.\n                    bestPath[diagonalPath] = undefined;\n                    continue;\n                }\n                // Select the diagonal that we want to branch from. We select the prior\n                // path whose position in the old string is the farthest from the origin\n                // and does not pass the bounds of the diff graph\n                if (!canRemove || (canAdd && removePath.oldPos < addPath.oldPos)) {\n                    basePath = _this.addToPath(addPath, true, false, 0, options);\n                }\n                else {\n                    basePath = _this.addToPath(removePath, false, true, 1, options);\n                }\n                newPos = _this.extractCommon(basePath, newTokens, oldTokens, diagonalPath, options);\n                if (basePath.oldPos + 1 >= oldLen && newPos + 1 >= newLen) {\n                    // If we have hit the end of both strings, then we are done\n                    return done(_this.buildValues(basePath.lastComponent, newTokens, oldTokens)) || true;\n                }\n                else {\n                    bestPath[diagonalPath] = basePath;\n                    if (basePath.oldPos + 1 >= oldLen) {\n                        maxDiagonalToConsider = Math.min(maxDiagonalToConsider, diagonalPath - 1);\n                    }\n                    if (newPos + 1 >= newLen) {\n                        minDiagonalToConsider = Math.max(minDiagonalToConsider, diagonalPath + 1);\n                    }\n                }\n            }\n            editLength++;\n        };\n        // Performs the length of edit iteration. Is a bit fugly as this has to support the\n        // sync and async mode which is never fun. Loops over execEditLength until a value\n        // is produced, or until the edit length exceeds options.maxEditLength (if given),\n        // in which case it will return undefined.\n        if (callback) {\n            (function exec() {\n                setTimeout(function () {\n                    if (editLength > maxEditLength || Date.now() > abortAfterTimestamp) {\n                        return callback(undefined);\n                    }\n                    if (!execEditLength()) {\n                        exec();\n                    }\n                }, 0);\n            }());\n        }\n        else {\n            while (editLength <= maxEditLength && Date.now() <= abortAfterTimestamp) {\n                var ret = execEditLength();\n                if (ret) {\n                    return ret;\n                }\n            }\n        }\n    };\n    Diff.prototype.addToPath = function (path, added, removed, oldPosInc, options) {\n        var last = path.lastComponent;\n        if (last && !options.oneChangePerToken && last.added === added && last.removed === removed) {\n            return {\n                oldPos: path.oldPos + oldPosInc,\n                lastComponent: { count: last.count + 1, added: added, removed: removed, previousComponent: last.previousComponent }\n            };\n        }\n        else {\n            return {\n                oldPos: path.oldPos + oldPosInc,\n                lastComponent: { count: 1, added: added, removed: removed, previousComponent: last }\n            };\n        }\n    };\n    Diff.prototype.extractCommon = function (basePath, newTokens, oldTokens, diagonalPath, options) {\n        var newLen = newTokens.length, oldLen = oldTokens.length;\n        var oldPos = basePath.oldPos, newPos = oldPos - diagonalPath, commonCount = 0;\n        while (newPos + 1 < newLen && oldPos + 1 < oldLen && this.equals(oldTokens[oldPos + 1], newTokens[newPos + 1], options)) {\n            newPos++;\n            oldPos++;\n            commonCount++;\n            if (options.oneChangePerToken) {\n                basePath.lastComponent = { count: 1, previousComponent: basePath.lastComponent, added: false, removed: false };\n            }\n        }\n        if (commonCount && !options.oneChangePerToken) {\n            basePath.lastComponent = { count: commonCount, previousComponent: basePath.lastComponent, added: false, removed: false };\n        }\n        basePath.oldPos = oldPos;\n        return newPos;\n    };\n    Diff.prototype.equals = function (left, right, options) {\n        if (options.comparator) {\n            return options.comparator(left, right);\n        }\n        else {\n            return left === right\n                || (!!options.ignoreCase && left.toLowerCase() === right.toLowerCase());\n        }\n    };\n    Diff.prototype.removeEmpty = function (array) {\n        var ret = [];\n        for (var i = 0; i < array.length; i++) {\n            if (array[i]) {\n                ret.push(array[i]);\n            }\n        }\n        return ret;\n    };\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    Diff.prototype.castInput = function (value, options) {\n        return value;\n    };\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    Diff.prototype.tokenize = function (value, options) {\n        return Array.from(value);\n    };\n    Diff.prototype.join = function (chars) {\n        // Assumes ValueT is string, which is the case for most subclasses.\n        // When it's false, e.g. in diffArrays, this method needs to be overridden (e.g. with a no-op)\n        // Yes, the casts are verbose and ugly, because this pattern - of having the base class SORT OF\n        // assume tokens and values are strings, but not completely - is weird and janky.\n        return chars.join('');\n    };\n    Diff.prototype.postProcess = function (changeObjects, \n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    options) {\n        return changeObjects;\n    };\n    Object.defineProperty(Diff.prototype, \"useLongestToken\", {\n        get: function () {\n            return false;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Diff.prototype.buildValues = function (lastComponent, newTokens, oldTokens) {\n        // First we convert our linked list of components in reverse order to an\n        // array in the right order:\n        var components = [];\n        var nextComponent;\n        while (lastComponent) {\n            components.push(lastComponent);\n            nextComponent = lastComponent.previousComponent;\n            delete lastComponent.previousComponent;\n            lastComponent = nextComponent;\n        }\n        components.reverse();\n        var componentLen = components.length;\n        var componentPos = 0, newPos = 0, oldPos = 0;\n        for (; componentPos < componentLen; componentPos++) {\n            var component = components[componentPos];\n            if (!component.removed) {\n                if (!component.added && this.useLongestToken) {\n                    var value = newTokens.slice(newPos, newPos + component.count);\n                    value = value.map(function (value, i) {\n                        var oldValue = oldTokens[oldPos + i];\n                        return oldValue.length > value.length ? oldValue : value;\n                    });\n                    component.value = this.join(value);\n                }\n                else {\n                    component.value = this.join(newTokens.slice(newPos, newPos + component.count));\n                }\n                newPos += component.count;\n                // Common case\n                if (!component.added) {\n                    oldPos += component.count;\n                }\n            }\n            else {\n                component.value = this.join(oldTokens.slice(oldPos, oldPos + component.count));\n                oldPos += component.count;\n            }\n        }\n        return components;\n    };\n    return Diff;\n}());\nexport default Diff;\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nvar CharacterDiff = /** @class */ (function (_super) {\n    __extends(CharacterDiff, _super);\n    function CharacterDiff() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    return CharacterDiff;\n}(Diff));\nexport var characterDiff = new CharacterDiff();\nexport function diffChars(oldStr, newStr, options) {\n    return characterDiff.diff(oldStr, newStr, options);\n}\n",
    "export function longestCommonPrefix(str1, str2) {\n    var i;\n    for (i = 0; i < str1.length && i < str2.length; i++) {\n        if (str1[i] != str2[i]) {\n            return str1.slice(0, i);\n        }\n    }\n    return str1.slice(0, i);\n}\nexport function longestCommonSuffix(str1, str2) {\n    var i;\n    // Unlike longestCommonPrefix, we need a special case to handle all scenarios\n    // where we return the empty string since str1.slice(-0) will return the\n    // entire string.\n    if (!str1 || !str2 || str1[str1.length - 1] != str2[str2.length - 1]) {\n        return '';\n    }\n    for (i = 0; i < str1.length && i < str2.length; i++) {\n        if (str1[str1.length - (i + 1)] != str2[str2.length - (i + 1)]) {\n            return str1.slice(-i);\n        }\n    }\n    return str1.slice(-i);\n}\nexport function replacePrefix(string, oldPrefix, newPrefix) {\n    if (string.slice(0, oldPrefix.length) != oldPrefix) {\n        throw Error(\"string \".concat(JSON.stringify(string), \" doesn't start with prefix \").concat(JSON.stringify(oldPrefix), \"; this is a bug\"));\n    }\n    return newPrefix + string.slice(oldPrefix.length);\n}\nexport function replaceSuffix(string, oldSuffix, newSuffix) {\n    if (!oldSuffix) {\n        return string + newSuffix;\n    }\n    if (string.slice(-oldSuffix.length) != oldSuffix) {\n        throw Error(\"string \".concat(JSON.stringify(string), \" doesn't end with suffix \").concat(JSON.stringify(oldSuffix), \"; this is a bug\"));\n    }\n    return string.slice(0, -oldSuffix.length) + newSuffix;\n}\nexport function removePrefix(string, oldPrefix) {\n    return replacePrefix(string, oldPrefix, '');\n}\nexport function removeSuffix(string, oldSuffix) {\n    return replaceSuffix(string, oldSuffix, '');\n}\nexport function maximumOverlap(string1, string2) {\n    return string2.slice(0, overlapCount(string1, string2));\n}\n// Nicked from https://stackoverflow.com/a/60422853/1709587\nfunction overlapCount(a, b) {\n    // Deal with cases where the strings differ in length\n    var startA = 0;\n    if (a.length > b.length) {\n        startA = a.length - b.length;\n    }\n    var endB = b.length;\n    if (a.length < b.length) {\n        endB = a.length;\n    }\n    // Create a back-reference for each index\n    //   that should be followed in case of a mismatch.\n    //   We only need B to make these references:\n    var map = Array(endB);\n    var k = 0; // Index that lags behind j\n    map[0] = 0;\n    for (var j = 1; j < endB; j++) {\n        if (b[j] == b[k]) {\n            map[j] = map[k]; // skip over the same character (optional optimisation)\n        }\n        else {\n            map[j] = k;\n        }\n        while (k > 0 && b[j] != b[k]) {\n            k = map[k];\n        }\n        if (b[j] == b[k]) {\n            k++;\n        }\n    }\n    // Phase 2: use these references while iterating over A\n    k = 0;\n    for (var i = startA; i < a.length; i++) {\n        while (k > 0 && a[i] != b[k]) {\n            k = map[k];\n        }\n        if (a[i] == b[k]) {\n            k++;\n        }\n    }\n    return k;\n}\n/**\n * Returns true if the string consistently uses Windows line endings.\n */\nexport function hasOnlyWinLineEndings(string) {\n    return string.includes('\\r\\n') && !string.startsWith('\\n') && !string.match(/[^\\r]\\n/);\n}\n/**\n * Returns true if the string consistently uses Unix line endings.\n */\nexport function hasOnlyUnixLineEndings(string) {\n    return !string.includes('\\r\\n') && string.includes('\\n');\n}\nexport function trailingWs(string) {\n    // Yes, this looks overcomplicated and dumb - why not replace the whole function with\n    //     return string match(/\\s*$/)[0]\n    // you ask? Because:\n    // 1. the trap described at https://markamery.com/blog/quadratic-time-regexes/ would mean doing\n    //    this would cause this function to take O(n) time in the worst case (specifically when\n    //    there is a massive run of NON-TRAILING whitespace in `string`), and\n    // 2. the fix proposed in the same blog post, of using a negative lookbehind, is incompatible\n    //    with old Safari versions that we'd like to not break if possible (see\n    //    https://github.com/kpdecker/jsdiff/pull/550)\n    // It feels absurd to do this with an explicit loop instead of a regex, but I really can't see a\n    // better way that doesn't result in broken behaviour.\n    var i;\n    for (i = string.length - 1; i >= 0; i--) {\n        if (!string[i].match(/\\s/)) {\n            break;\n        }\n    }\n    return string.substring(i + 1);\n}\nexport function leadingWs(string) {\n    // Thankfully the annoying considerations described in trailingWs don't apply here:\n    var match = string.match(/^\\s*/);\n    return match ? match[0] : '';\n}\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nimport { longestCommonPrefix, longestCommonSuffix, replacePrefix, replaceSuffix, removePrefix, removeSuffix, maximumOverlap, leadingWs, trailingWs } from '../util/string.js';\n// Based on https://en.wikipedia.org/wiki/Latin_script_in_Unicode\n//\n// Ranges and exceptions:\n// Latin-1 Supplement, 008000FF\n//  - U+00D7   Multiplication sign\n//  - U+00F7   Division sign\n// Latin Extended-A, 0100017F\n// Latin Extended-B, 0180024F\n// IPA Extensions, 025002AF\n// Spacing Modifier Letters, 02B002FF\n//  - U+02C7   &#711;  Caron\n//  - U+02D8   &#728;  Breve\n//  - U+02D9   &#729;  Dot Above\n//  - U+02DA   &#730;  Ring Above\n//  - U+02DB   &#731;  Ogonek\n//  - U+02DC   &#732;  Small Tilde\n//  - U+02DD   &#733;  Double Acute Accent\n// Latin Extended Additional, 1E001EFF\nvar extendedWordChars = 'a-zA-Z0-9_\\\\u{C0}-\\\\u{FF}\\\\u{D8}-\\\\u{F6}\\\\u{F8}-\\\\u{2C6}\\\\u{2C8}-\\\\u{2D7}\\\\u{2DE}-\\\\u{2FF}\\\\u{1E00}-\\\\u{1EFF}';\n// Each token is one of the following:\n// - A punctuation mark plus the surrounding whitespace\n// - A word plus the surrounding whitespace\n// - Pure whitespace (but only in the special case where this the entire text\n//   is just whitespace)\n//\n// We have to include surrounding whitespace in the tokens because the two\n// alternative approaches produce horribly broken results:\n// * If we just discard the whitespace, we can't fully reproduce the original\n//   text from the sequence of tokens and any attempt to render the diff will\n//   get the whitespace wrong.\n// * If we have separate tokens for whitespace, then in a typical text every\n//   second token will be a single space character. But this often results in\n//   the optimal diff between two texts being a perverse one that preserves\n//   the spaces between words but deletes and reinserts actual common words.\n//   See https://github.com/kpdecker/jsdiff/issues/160#issuecomment-1866099640\n//   for an example.\n//\n// Keeping the surrounding whitespace of course has implications for .equals\n// and .join, not just .tokenize.\n// This regex does NOT fully implement the tokenization rules described above.\n// Instead, it gives runs of whitespace their own \"token\". The tokenize method\n// then handles stitching whitespace tokens onto adjacent word or punctuation\n// tokens.\nvar tokenizeIncludingWhitespace = new RegExp(\"[\".concat(extendedWordChars, \"]+|\\\\s+|[^\").concat(extendedWordChars, \"]\"), 'ug');\nvar WordDiff = /** @class */ (function (_super) {\n    __extends(WordDiff, _super);\n    function WordDiff() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    WordDiff.prototype.equals = function (left, right, options) {\n        if (options.ignoreCase) {\n            left = left.toLowerCase();\n            right = right.toLowerCase();\n        }\n        return left.trim() === right.trim();\n    };\n    WordDiff.prototype.tokenize = function (value, options) {\n        if (options === void 0) { options = {}; }\n        var parts;\n        if (options.intlSegmenter) {\n            var segmenter = options.intlSegmenter;\n            if (segmenter.resolvedOptions().granularity != 'word') {\n                throw new Error('The segmenter passed must have a granularity of \"word\"');\n            }\n            parts = Array.from(segmenter.segment(value), function (segment) { return segment.segment; });\n        }\n        else {\n            parts = value.match(tokenizeIncludingWhitespace) || [];\n        }\n        var tokens = [];\n        var prevPart = null;\n        parts.forEach(function (part) {\n            if ((/\\s/).test(part)) {\n                if (prevPart == null) {\n                    tokens.push(part);\n                }\n                else {\n                    tokens.push(tokens.pop() + part);\n                }\n            }\n            else if (prevPart != null && (/\\s/).test(prevPart)) {\n                if (tokens[tokens.length - 1] == prevPart) {\n                    tokens.push(tokens.pop() + part);\n                }\n                else {\n                    tokens.push(prevPart + part);\n                }\n            }\n            else {\n                tokens.push(part);\n            }\n            prevPart = part;\n        });\n        return tokens;\n    };\n    WordDiff.prototype.join = function (tokens) {\n        // Tokens being joined here will always have appeared consecutively in the\n        // same text, so we can simply strip off the leading whitespace from all the\n        // tokens except the first (and except any whitespace-only tokens - but such\n        // a token will always be the first and only token anyway) and then join them\n        // and the whitespace around words and punctuation will end up correct.\n        return tokens.map(function (token, i) {\n            if (i == 0) {\n                return token;\n            }\n            else {\n                return token.replace((/^\\s+/), '');\n            }\n        }).join('');\n    };\n    WordDiff.prototype.postProcess = function (changes, options) {\n        if (!changes || options.oneChangePerToken) {\n            return changes;\n        }\n        var lastKeep = null;\n        // Change objects representing any insertion or deletion since the last\n        // \"keep\" change object. There can be at most one of each.\n        var insertion = null;\n        var deletion = null;\n        changes.forEach(function (change) {\n            if (change.added) {\n                insertion = change;\n            }\n            else if (change.removed) {\n                deletion = change;\n            }\n            else {\n                if (insertion || deletion) { // May be false at start of text\n                    dedupeWhitespaceInChangeObjects(lastKeep, deletion, insertion, change);\n                }\n                lastKeep = change;\n                insertion = null;\n                deletion = null;\n            }\n        });\n        if (insertion || deletion) {\n            dedupeWhitespaceInChangeObjects(lastKeep, deletion, insertion, null);\n        }\n        return changes;\n    };\n    return WordDiff;\n}(Diff));\nexport var wordDiff = new WordDiff();\nexport function diffWords(oldStr, newStr, options) {\n    // This option has never been documented and never will be (it's clearer to\n    // just call `diffWordsWithSpace` directly if you need that behavior), but\n    // has existed in jsdiff for a long time, so we retain support for it here\n    // for the sake of backwards compatibility.\n    if ((options === null || options === void 0 ? void 0 : options.ignoreWhitespace) != null && !options.ignoreWhitespace) {\n        return diffWordsWithSpace(oldStr, newStr, options);\n    }\n    return wordDiff.diff(oldStr, newStr, options);\n}\nfunction dedupeWhitespaceInChangeObjects(startKeep, deletion, insertion, endKeep) {\n    // Before returning, we tidy up the leading and trailing whitespace of the\n    // change objects to eliminate cases where trailing whitespace in one object\n    // is repeated as leading whitespace in the next.\n    // Below are examples of the outcomes we want here to explain the code.\n    // I=insert, K=keep, D=delete\n    // 1. diffing 'foo bar baz' vs 'foo baz'\n    //    Prior to cleanup, we have K:'foo ' D:' bar ' K:' baz'\n    //    After cleanup, we want:   K:'foo ' D:'bar ' K:'baz'\n    //\n    // 2. Diffing 'foo bar baz' vs 'foo qux baz'\n    //    Prior to cleanup, we have K:'foo ' D:' bar ' I:' qux ' K:' baz'\n    //    After cleanup, we want K:'foo ' D:'bar' I:'qux' K:' baz'\n    //\n    // 3. Diffing 'foo\\nbar baz' vs 'foo baz'\n    //    Prior to cleanup, we have K:'foo ' D:'\\nbar ' K:' baz'\n    //    After cleanup, we want K'foo' D:'\\nbar' K:' baz'\n    //\n    // 4. Diffing 'foo baz' vs 'foo\\nbar baz'\n    //    Prior to cleanup, we have K:'foo\\n' I:'\\nbar ' K:' baz'\n    //    After cleanup, we ideally want K'foo' I:'\\nbar' K:' baz'\n    //    but don't actually manage this currently (the pre-cleanup change\n    //    objects don't contain enough information to make it possible).\n    //\n    // 5. Diffing 'foo   bar baz' vs 'foo  baz'\n    //    Prior to cleanup, we have K:'foo  ' D:'   bar ' K:'  baz'\n    //    After cleanup, we want K:'foo  ' D:' bar ' K:'baz'\n    //\n    // Our handling is unavoidably imperfect in the case where there's a single\n    // indel between keeps and the whitespace has changed. For instance, consider\n    // diffing 'foo\\tbar\\nbaz' vs 'foo baz'. Unless we create an extra change\n    // object to represent the insertion of the space character (which isn't even\n    // a token), we have no way to avoid losing information about the texts'\n    // original whitespace in the result we return. Still, we do our best to\n    // output something that will look sensible if we e.g. print it with\n    // insertions in green and deletions in red.\n    // Between two \"keep\" change objects (or before the first or after the last\n    // change object), we can have either:\n    // * A \"delete\" followed by an \"insert\"\n    // * Just an \"insert\"\n    // * Just a \"delete\"\n    // We handle the three cases separately.\n    if (deletion && insertion) {\n        var oldWsPrefix = leadingWs(deletion.value);\n        var oldWsSuffix = trailingWs(deletion.value);\n        var newWsPrefix = leadingWs(insertion.value);\n        var newWsSuffix = trailingWs(insertion.value);\n        if (startKeep) {\n            var commonWsPrefix = longestCommonPrefix(oldWsPrefix, newWsPrefix);\n            startKeep.value = replaceSuffix(startKeep.value, newWsPrefix, commonWsPrefix);\n            deletion.value = removePrefix(deletion.value, commonWsPrefix);\n            insertion.value = removePrefix(insertion.value, commonWsPrefix);\n        }\n        if (endKeep) {\n            var commonWsSuffix = longestCommonSuffix(oldWsSuffix, newWsSuffix);\n            endKeep.value = replacePrefix(endKeep.value, newWsSuffix, commonWsSuffix);\n            deletion.value = removeSuffix(deletion.value, commonWsSuffix);\n            insertion.value = removeSuffix(insertion.value, commonWsSuffix);\n        }\n    }\n    else if (insertion) {\n        // The whitespaces all reflect what was in the new text rather than\n        // the old, so we essentially have no information about whitespace\n        // insertion or deletion. We just want to dedupe the whitespace.\n        // We do that by having each change object keep its trailing\n        // whitespace and deleting duplicate leading whitespace where\n        // present.\n        if (startKeep) {\n            var ws = leadingWs(insertion.value);\n            insertion.value = insertion.value.substring(ws.length);\n        }\n        if (endKeep) {\n            var ws = leadingWs(endKeep.value);\n            endKeep.value = endKeep.value.substring(ws.length);\n        }\n        // otherwise we've got a deletion and no insertion\n    }\n    else if (startKeep && endKeep) {\n        var newWsFull = leadingWs(endKeep.value), delWsStart = leadingWs(deletion.value), delWsEnd = trailingWs(deletion.value);\n        // Any whitespace that comes straight after startKeep in both the old and\n        // new texts, assign to startKeep and remove from the deletion.\n        var newWsStart = longestCommonPrefix(newWsFull, delWsStart);\n        deletion.value = removePrefix(deletion.value, newWsStart);\n        // Any whitespace that comes straight before endKeep in both the old and\n        // new texts, and hasn't already been assigned to startKeep, assign to\n        // endKeep and remove from the deletion.\n        var newWsEnd = longestCommonSuffix(removePrefix(newWsFull, newWsStart), delWsEnd);\n        deletion.value = removeSuffix(deletion.value, newWsEnd);\n        endKeep.value = replacePrefix(endKeep.value, newWsFull, newWsEnd);\n        // If there's any whitespace from the new text that HASN'T already been\n        // assigned, assign it to the start:\n        startKeep.value = replaceSuffix(startKeep.value, newWsFull, newWsFull.slice(0, newWsFull.length - newWsEnd.length));\n    }\n    else if (endKeep) {\n        // We are at the start of the text. Preserve all the whitespace on\n        // endKeep, and just remove whitespace from the end of deletion to the\n        // extent that it overlaps with the start of endKeep.\n        var endKeepWsPrefix = leadingWs(endKeep.value);\n        var deletionWsSuffix = trailingWs(deletion.value);\n        var overlap = maximumOverlap(deletionWsSuffix, endKeepWsPrefix);\n        deletion.value = removeSuffix(deletion.value, overlap);\n    }\n    else if (startKeep) {\n        // We are at the END of the text. Preserve all the whitespace on\n        // startKeep, and just remove whitespace from the start of deletion to\n        // the extent that it overlaps with the end of startKeep.\n        var startKeepWsSuffix = trailingWs(startKeep.value);\n        var deletionWsPrefix = leadingWs(deletion.value);\n        var overlap = maximumOverlap(startKeepWsSuffix, deletionWsPrefix);\n        deletion.value = removePrefix(deletion.value, overlap);\n    }\n}\nvar WordsWithSpaceDiff = /** @class */ (function (_super) {\n    __extends(WordsWithSpaceDiff, _super);\n    function WordsWithSpaceDiff() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    WordsWithSpaceDiff.prototype.tokenize = function (value) {\n        // Slightly different to the tokenizeIncludingWhitespace regex used above in\n        // that this one treats each individual newline as a distinct tokens, rather\n        // than merging them into other surrounding whitespace. This was requested\n        // in https://github.com/kpdecker/jsdiff/issues/180 &\n        //    https://github.com/kpdecker/jsdiff/issues/211\n        var regex = new RegExp(\"(\\\\r?\\\\n)|[\".concat(extendedWordChars, \"]+|[^\\\\S\\\\n\\\\r]+|[^\").concat(extendedWordChars, \"]\"), 'ug');\n        return value.match(regex) || [];\n    };\n    return WordsWithSpaceDiff;\n}(Diff));\nexport var wordsWithSpaceDiff = new WordsWithSpaceDiff();\nexport function diffWordsWithSpace(oldStr, newStr, options) {\n    return wordsWithSpaceDiff.diff(oldStr, newStr, options);\n}\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nimport { generateOptions } from '../util/params.js';\nvar LineDiff = /** @class */ (function (_super) {\n    __extends(LineDiff, _super);\n    function LineDiff() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.tokenize = tokenize;\n        return _this;\n    }\n    LineDiff.prototype.equals = function (left, right, options) {\n        // If we're ignoring whitespace, we need to normalise lines by stripping\n        // whitespace before checking equality. (This has an annoying interaction\n        // with newlineIsToken that requires special handling: if newlines get their\n        // own token, then we DON'T want to trim the *newline* tokens down to empty\n        // strings, since this would cause us to treat whitespace-only line content\n        // as equal to a separator between lines, which would be weird and\n        // inconsistent with the documented behavior of the options.)\n        if (options.ignoreWhitespace) {\n            if (!options.newlineIsToken || !left.includes('\\n')) {\n                left = left.trim();\n            }\n            if (!options.newlineIsToken || !right.includes('\\n')) {\n                right = right.trim();\n            }\n        }\n        else if (options.ignoreNewlineAtEof && !options.newlineIsToken) {\n            if (left.endsWith('\\n')) {\n                left = left.slice(0, -1);\n            }\n            if (right.endsWith('\\n')) {\n                right = right.slice(0, -1);\n            }\n        }\n        return _super.prototype.equals.call(this, left, right, options);\n    };\n    return LineDiff;\n}(Diff));\nexport var lineDiff = new LineDiff();\nexport function diffLines(oldStr, newStr, options) {\n    return lineDiff.diff(oldStr, newStr, options);\n}\nexport function diffTrimmedLines(oldStr, newStr, options) {\n    options = generateOptions(options, { ignoreWhitespace: true });\n    return lineDiff.diff(oldStr, newStr, options);\n}\n// Exported standalone so it can be used from jsonDiff too.\nexport function tokenize(value, options) {\n    if (options.stripTrailingCr) {\n        // remove one \\r before \\n to match GNU diff's --strip-trailing-cr behavior\n        value = value.replace(/\\r\\n/g, '\\n');\n    }\n    var retLines = [], linesAndNewlines = value.split(/(\\n|\\r\\n)/);\n    // Ignore the final empty token that occurs if the string ends with a new line\n    if (!linesAndNewlines[linesAndNewlines.length - 1]) {\n        linesAndNewlines.pop();\n    }\n    // Merge the content and line separators into single tokens\n    for (var i = 0; i < linesAndNewlines.length; i++) {\n        var line = linesAndNewlines[i];\n        if (i % 2 && !options.newlineIsToken) {\n            retLines[retLines.length - 1] += line;\n        }\n        else {\n            retLines.push(line);\n        }\n    }\n    return retLines;\n}\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nvar SentenceDiff = /** @class */ (function (_super) {\n    __extends(SentenceDiff, _super);\n    function SentenceDiff() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    SentenceDiff.prototype.tokenize = function (value) {\n        return value.split(/(?<=[.!?])(\\s+|$)/);\n    };\n    return SentenceDiff;\n}(Diff));\nexport var sentenceDiff = new SentenceDiff();\nexport function diffSentences(oldStr, newStr, options) {\n    return sentenceDiff.diff(oldStr, newStr, options);\n}\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nvar CssDiff = /** @class */ (function (_super) {\n    __extends(CssDiff, _super);\n    function CssDiff() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    CssDiff.prototype.tokenize = function (value) {\n        return value.split(/([{}:;,]|\\s+)/);\n    };\n    return CssDiff;\n}(Diff));\nexport var cssDiff = new CssDiff();\nexport function diffCss(oldStr, newStr, options) {\n    return cssDiff.diff(oldStr, newStr, options);\n}\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nimport { tokenize } from './line.js';\nvar JsonDiff = /** @class */ (function (_super) {\n    __extends(JsonDiff, _super);\n    function JsonDiff() {\n        var _this = _super !== null && _super.apply(this, arguments) || this;\n        _this.tokenize = tokenize;\n        return _this;\n    }\n    Object.defineProperty(JsonDiff.prototype, \"useLongestToken\", {\n        get: function () {\n            // Discriminate between two lines of pretty-printed, serialized JSON where one of them has a\n            // dangling comma and the other doesn't. Turns out including the dangling comma yields the nicest output:\n            return true;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    JsonDiff.prototype.castInput = function (value, options) {\n        var undefinedReplacement = options.undefinedReplacement, _a = options.stringifyReplacer, stringifyReplacer = _a === void 0 ? function (k, v) { return typeof v === 'undefined' ? undefinedReplacement : v; } : _a;\n        return typeof value === 'string' ? value : JSON.stringify(canonicalize(value, null, null, stringifyReplacer), null, '  ');\n    };\n    JsonDiff.prototype.equals = function (left, right, options) {\n        return _super.prototype.equals.call(this, left.replace(/,([\\r\\n])/g, '$1'), right.replace(/,([\\r\\n])/g, '$1'), options);\n    };\n    return JsonDiff;\n}(Diff));\nexport var jsonDiff = new JsonDiff();\nexport function diffJson(oldStr, newStr, options) {\n    return jsonDiff.diff(oldStr, newStr, options);\n}\n// This function handles the presence of circular references by bailing out when encountering an\n// object that is already on the \"stack\" of items being processed. Accepts an optional replacer\nexport function canonicalize(obj, stack, replacementStack, replacer, key) {\n    stack = stack || [];\n    replacementStack = replacementStack || [];\n    if (replacer) {\n        obj = replacer(key === undefined ? '' : key, obj);\n    }\n    var i;\n    for (i = 0; i < stack.length; i += 1) {\n        if (stack[i] === obj) {\n            return replacementStack[i];\n        }\n    }\n    var canonicalizedObj;\n    if ('[object Array]' === Object.prototype.toString.call(obj)) {\n        stack.push(obj);\n        canonicalizedObj = new Array(obj.length);\n        replacementStack.push(canonicalizedObj);\n        for (i = 0; i < obj.length; i += 1) {\n            canonicalizedObj[i] = canonicalize(obj[i], stack, replacementStack, replacer, String(i));\n        }\n        stack.pop();\n        replacementStack.pop();\n        return canonicalizedObj;\n    }\n    if (obj && obj.toJSON) {\n        obj = obj.toJSON();\n    }\n    if (typeof obj === 'object' && obj !== null) {\n        stack.push(obj);\n        canonicalizedObj = {};\n        replacementStack.push(canonicalizedObj);\n        var sortedKeys = [];\n        var key_1;\n        for (key_1 in obj) {\n            /* istanbul ignore else */\n            if (Object.prototype.hasOwnProperty.call(obj, key_1)) {\n                sortedKeys.push(key_1);\n            }\n        }\n        sortedKeys.sort();\n        for (i = 0; i < sortedKeys.length; i += 1) {\n            key_1 = sortedKeys[i];\n            canonicalizedObj[key_1] = canonicalize(obj[key_1], stack, replacementStack, replacer, key_1);\n        }\n        stack.pop();\n        replacementStack.pop();\n    }\n    else {\n        canonicalizedObj = obj;\n    }\n    return canonicalizedObj;\n}\n",
    "var __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nimport Diff from './base.js';\nvar ArrayDiff = /** @class */ (function (_super) {\n    __extends(ArrayDiff, _super);\n    function ArrayDiff() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    ArrayDiff.prototype.tokenize = function (value) {\n        return value.slice();\n    };\n    ArrayDiff.prototype.join = function (value) {\n        return value;\n    };\n    ArrayDiff.prototype.removeEmpty = function (value) {\n        return value;\n    };\n    return ArrayDiff;\n}(Diff));\nexport var arrayDiff = new ArrayDiff();\nexport function diffArrays(oldArr, newArr, options) {\n    return arrayDiff.diff(oldArr, newArr, options);\n}\n",
    "/**\r\n * Diff utilities\r\n *\r\n * Functions for handling and sanitizing diff data\r\n */\r\n\r\nimport * as Diff from \"diff\";\r\nimport { MAX_DIFF_SIZE_BYTES } from \"../config/constants.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n/**\r\n * Create a unified diff format from old and new strings\r\n * Uses the same library as the VSCode extension\r\n */\r\nexport function createUnifiedDiff(filePath: string, oldString: string, newString: string): string {\r\n  try {\r\n    return Diff.createPatch(filePath, oldString.trimEnd(), newString.trimEnd(), \"\", \"\", {\r\n      context: 3,\r\n    });\r\n  } catch (error) {\r\n    logger.warn(`Failed to create unified diff for ${filePath}`, error);\r\n    return \"\";\r\n  }\r\n}\r\n\r\n/**\r\n * Sanitize diff data to prevent unbounded memory growth\r\n * Converts old_string/new_string to unified diff format to save space\r\n *\r\n * Handles three cases:\r\n * - File creation: old_string is empty/undefined, new_string has content\r\n * - File edit: both old_string and new_string have content\r\n * - File deletion: old_string has content, new_string is empty/undefined\r\n */\r\nexport function sanitizeDiff(\r\n  diff: { old_string?: string; new_string?: string; structured_patch?: unknown } | undefined,\r\n  filePath?: string,\r\n): string | undefined {\r\n  if (!diff || !filePath) {\r\n    return undefined;\r\n  }\r\n\r\n  // Normalize strings - treat undefined/null as empty string\r\n  const oldString = diff.old_string ?? \"\";\r\n  const newString = diff.new_string ?? \"\";\r\n\r\n  // If both strings are empty, there's no meaningful diff\r\n  if (oldString === \"\" && newString === \"\") {\r\n    return undefined;\r\n  }\r\n\r\n  const unifiedDiff = createUnifiedDiff(filePath, oldString, newString);\r\n\r\n  if (!unifiedDiff) {\r\n    return undefined;\r\n  }\r\n\r\n  const sizeBytes = Buffer.byteLength(unifiedDiff, \"utf-8\");\r\n\r\n  if (sizeBytes > MAX_DIFF_SIZE_BYTES) {\r\n    logger.warn(\r\n      `Diff size ${sizeBytes} bytes exceeds limit of ${MAX_DIFF_SIZE_BYTES} bytes, skipping`,\r\n    );\r\n    return undefined;\r\n  }\r\n\r\n  return unifiedDiff;\r\n}\r\n",
    "/**\r\n * Message parsing logic for Claude JSONL files\r\n */\r\n\r\nimport { readFile } from \"node:fs/promises\";\r\nimport type { ClaudeJSONLEntry, ToolUse } from \"../types/extractors.js\";\r\nimport type { ClaudeExtractedMessage } from \"../types/index.js\";\r\nimport { applyMessageFilter, restoreFilteringState } from \"../utils/command-filters.js\";\r\nimport { logger } from \"../utils/logger.js\";\r\nimport {\r\n  extractTextContent,\r\n  extractToolUse,\r\n  extractToolUseResult,\r\n  generateMessageId,\r\n  logDiff,\r\n} from \"./extraction-utils.js\";\r\n\r\n/**\r\n * Extract only NEW messages and tool uses from JSONL file (incremental extraction)\r\n *\r\n * @param filePath - Path to conversation.jsonl file\r\n * @param sessionId - Session identifier\r\n * @param lastReadLine - Last line number that was read (0-indexed)\r\n * @returns New messages, tool uses, and updated line number\r\n */\r\nexport async function extractNewMessagesFromFile(\r\n  filePath: string,\r\n  sessionId: string,\r\n  lastReadLine = 0,\r\n): Promise<{\r\n  messages: ClaudeExtractedMessage[];\r\n  toolUses: ToolUse[];\r\n  newLastReadLine: number;\r\n  totalLines: number;\r\n}> {\r\n  const messages: ClaudeExtractedMessage[] = [];\r\n  const toolUses: ToolUse[] = [];\r\n\r\n  try {\r\n    logger.debug(`Incremental extraction for ${sessionId}: reading from line ${lastReadLine}`);\r\n\r\n    const content = await readFile(filePath, \"utf-8\");\r\n    const lines = content.split(\"\\n\").filter((line) => line.trim());\r\n    const totalLines = lines.length;\r\n\r\n    // Check if there are new lines to process\r\n    if (totalLines <= lastReadLine) {\r\n      logger.debug(`No new lines for ${sessionId}: total=${totalLines}, lastRead=${lastReadLine}`);\r\n      return { messages, toolUses, newLastReadLine: lastReadLine, totalLines };\r\n    }\r\n\r\n    // Process only new lines\r\n    const newLines = lines.slice(lastReadLine);\r\n    logger.info(\r\n      `Processing ${newLines.length} new lines for session ${sessionId} (lines ${lastReadLine + 1}-${totalLines})`,\r\n    );\r\n\r\n    // Extract messages without worrying about message_index\r\n    // (will be assigned sequentially during queuing)\r\n    let tempMessageCounter = 0;\r\n\r\n    // State flags: filter assistant responses after excluded user command\r\n    // and track if last command was a zest command for digit continuation detection\r\n    // Initialize by checking the last user message from already-processed lines\r\n    let filteringState = restoreFilteringState(lines, lastReadLine);\r\n\r\n    for (let i = 0; i < newLines.length; i++) {\r\n      const line = newLines[i];\r\n      const lineNumber = lastReadLine + i;\r\n\r\n      try {\r\n        const entry: ClaudeJSONLEntry = JSON.parse(line);\r\n\r\n        // Skip entries without message field\r\n        if (!entry.message) continue;\r\n\r\n        const role = entry.message.role;\r\n        const content = entry.message.content;\r\n\r\n        // Extract user or assistant messages\r\n        if ((role === \"user\" || role === \"assistant\") && content) {\r\n          const textContent = extractTextContent(content);\r\n\r\n          if (textContent) {\r\n            // Apply state-based filtering logic\r\n            const filterResult = applyMessageFilter(role, textContent, filteringState);\r\n            filteringState = filterResult.newState;\r\n\r\n            if (filterResult.shouldFilter) {\r\n              continue;\r\n            }\r\n\r\n            const messageId = entry.uuid || generateMessageId(sessionId, tempMessageCounter);\r\n\r\n            messages.push({\r\n              id: messageId,\r\n              session_id: sessionId,\r\n              role: role,\r\n              content: textContent,\r\n              created_at: entry.timestamp || new Date().toISOString(),\r\n              message_index: tempMessageCounter, // Temporary - reassigned sequentially during queuing\r\n            });\r\n            tempMessageCounter++;\r\n\r\n            logger.debug(\r\n              `Extracted ${role} message at line ${lineNumber + 1}: ${textContent.substring(0, 50)}...`,\r\n            );\r\n          }\r\n        }\r\n\r\n        // Extract tool use results with diffs (primary source)\r\n        // This contains the actual results and diffs after tool execution\r\n        if (entry.toolUseResult) {\r\n          const toolUseWithDiff = extractToolUseResult(entry, sessionId);\r\n          if (toolUseWithDiff) {\r\n            toolUses.push(toolUseWithDiff);\r\n\r\n            logger.debug(\r\n              `Extracted tool result at line ${lineNumber + 1}: ${toolUseWithDiff.file_path}`,\r\n            );\r\n\r\n            logDiff(toolUseWithDiff.file_path || \"\", toolUseWithDiff.diff);\r\n          }\r\n        }\r\n        // Fallback: Check message content array for tool uses without results\r\n        // This handles Bash commands and other tools that don't have toolUseResult\r\n        else if (Array.isArray(content)) {\r\n          for (const contentBlock of content) {\r\n            if (contentBlock.type === \"tool_use\") {\r\n              const extractedToolUses = await extractToolUse(\r\n                contentBlock,\r\n                sessionId,\r\n                entry.timestamp,\r\n              );\r\n              for (const toolUse of extractedToolUses) {\r\n                toolUses.push(toolUse);\r\n                logger.debug(\r\n                  `Extracted tool use at line ${lineNumber + 1}: ${toolUse.tool_name} on ${toolUse.file_path}`,\r\n                );\r\n              }\r\n            }\r\n          }\r\n        }\r\n      } catch (parseError) {\r\n        logger.debug(\r\n          `Failed to parse JSONL line ${lineNumber + 1}: ${line.substring(0, 100)}...`,\r\n          parseError,\r\n        );\r\n      }\r\n    }\r\n\r\n    logger.info(\r\n      `Incremental extraction complete: ${messages.length} messages, ${toolUses.length} tool uses`,\r\n    );\r\n\r\n    return {\r\n      messages,\r\n      toolUses,\r\n      newLastReadLine: totalLines,\r\n      totalLines,\r\n    };\r\n  } catch (error) {\r\n    logger.error(`Failed to incrementally read conversation file ${filePath}:`, error);\r\n    return {\r\n      messages,\r\n      toolUses,\r\n      newLastReadLine: lastReadLine,\r\n      totalLines: lastReadLine,\r\n    };\r\n  }\r\n}\r\n",
    "/**\r\n * Local queue management for data persistence\r\n *\r\n * Manages JSONL queue files for events, sessions, and messages\r\n * Uses file-based locking to prevent corruption from concurrent access\r\n */\r\n\r\nimport { appendFile, readFile, stat, unlink, writeFile } from \"node:fs/promises\";\r\nimport { dirname } from \"node:path\";\r\nimport {\r\n  EVENTS_QUEUE_FILE,\r\n  MESSAGES_QUEUE_FILE,\r\n  QUEUE_DIR,\r\n  SESSIONS_QUEUE_FILE,\r\n} from \"../config/constants.js\";\r\nimport type {\r\n  ClaudeExtractedEvent,\r\n  ClaudeExtractedMessage,\r\n  ClaudeExtractedSession,\r\n} from \"../types/index.js\";\r\nimport { withFileLock } from \"./file-lock.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\n/**\r\n * Read all entries from a JSONL file\r\n */\r\nasync function readJsonl<T>(filePath: string): Promise<T[]> {\r\n  try {\r\n    const content = await readFile(filePath, \"utf8\");\r\n    const lines = content.trim().split(\"\\n\").filter(Boolean);\r\n\r\n    const results: T[] = [];\r\n    for (let i = 0; i < lines.length; i++) {\r\n      try {\r\n        results.push(JSON.parse(lines[i]));\r\n      } catch (error) {\r\n        logger.warn(`Failed to parse line ${i + 1} in ${filePath}:`, error);\r\n        // Continue processing other lines\r\n      }\r\n    }\r\n\r\n    return results;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist yet, return empty array\r\n      return [];\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Count lines in a JSONL file\r\n */\r\nasync function countLines(filePath: string): Promise<number> {\r\n  try {\r\n    const content = await readFile(filePath, \"utf8\");\r\n    const lines = content.trim().split(\"\\n\").filter(Boolean);\r\n    return lines.length;\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      return 0;\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Delete a file (clear queue)\r\n */\r\nasync function deleteFile(filePath: string): Promise<void> {\r\n  try {\r\n    await unlink(filePath);\r\n  } catch (error) {\r\n    if ((error as NodeJS.ErrnoException).code === \"ENOENT\") {\r\n      // File doesn't exist, nothing to delete\r\n      return;\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Public API\r\n// ============================================================================\r\n\r\n/**\r\n * Enqueue a code digest event extracted from Claude Code CLI\r\n * Skips events that are already in the queue (deduplication)\r\n */\r\nexport async function enqueueEvent(event: ClaudeExtractedEvent): Promise<void> {\r\n  try {\r\n    // Use lock to ensure atomicity of read-check-write\r\n    await withFileLock(EVENTS_QUEUE_FILE, async () => {\r\n      // Check if event already exists (inside lock to prevent race conditions)\r\n      const existingEvents = await readJsonl<ClaudeExtractedEvent>(EVENTS_QUEUE_FILE);\r\n      const isDuplicate = existingEvents.some((evt) => evt.id === event.id);\r\n\r\n      if (isDuplicate) {\r\n        logger.debug(\"Skipping duplicate event\", {\r\n          eventId: event.id,\r\n          documentUri: event.document_uri,\r\n        });\r\n        return;\r\n      }\r\n\r\n      // Ensure directory exists\r\n      await ensureDirectory(dirname(EVENTS_QUEUE_FILE));\r\n\r\n      // Append JSON line\r\n      const line = JSON.stringify(event) + \"\\n\";\r\n      await appendFile(EVENTS_QUEUE_FILE, line, \"utf8\");\r\n\r\n      logger.debug(\"Enqueued event\", { eventId: event.id, documentUri: event.document_uri });\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to enqueue event:\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Enqueue a chat session extracted from Claude Code CLI\r\n * Skips sessions that are already in the queue (deduplication)\r\n */\r\nexport async function enqueueChatSession(session: ClaudeExtractedSession): Promise<void> {\r\n  try {\r\n    // Use lock to ensure atomicity of read-check-write\r\n    await withFileLock(SESSIONS_QUEUE_FILE, async () => {\r\n      // Check if session already exists (inside lock to prevent race conditions)\r\n      const existingSessions = await readJsonl<ClaudeExtractedSession>(SESSIONS_QUEUE_FILE);\r\n      const isDuplicate = existingSessions.some((sess) => sess.id === session.id);\r\n\r\n      if (isDuplicate) {\r\n        logger.debug(\"Skipping duplicate session\", { sessionId: session.id });\r\n        return;\r\n      }\r\n\r\n      // Ensure directory exists\r\n      await ensureDirectory(dirname(SESSIONS_QUEUE_FILE));\r\n\r\n      // Append JSON line\r\n      const line = JSON.stringify(session) + \"\\n\";\r\n      await appendFile(SESSIONS_QUEUE_FILE, line, \"utf8\");\r\n\r\n      logger.debug(\"Enqueued session\", { sessionId: session.id });\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to enqueue session:\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Enqueue a chat message extracted from Claude Code CLI\r\n * Skips messages that are already in the queue (deduplication)\r\n */\r\nexport async function enqueueChatMessage(message: ClaudeExtractedMessage): Promise<void> {\r\n  try {\r\n    // Use lock to ensure atomicity of read-check-write\r\n    await withFileLock(MESSAGES_QUEUE_FILE, async () => {\r\n      // Check if message already exists (inside lock to prevent race conditions)\r\n      const existingMessages = await readJsonl<ClaudeExtractedMessage>(MESSAGES_QUEUE_FILE);\r\n      const isDuplicate = existingMessages.some((msg) => msg.id === message.id);\r\n\r\n      if (isDuplicate) {\r\n        logger.debug(\"Skipping duplicate message\", {\r\n          messageId: message.id,\r\n          sessionId: message.session_id,\r\n          messageIndex: message.message_index,\r\n        });\r\n        return;\r\n      }\r\n\r\n      // Ensure directory exists\r\n      await ensureDirectory(dirname(MESSAGES_QUEUE_FILE));\r\n\r\n      // Append JSON line\r\n      const line = JSON.stringify(message) + \"\\n\";\r\n      await appendFile(MESSAGES_QUEUE_FILE, line, \"utf8\");\r\n\r\n      logger.debug(\"Enqueued message\", {\r\n        sessionId: message.session_id,\r\n        messageIndex: message.message_index,\r\n      });\r\n    });\r\n  } catch (error) {\r\n    logger.error(\"Failed to enqueue message:\", error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Read all entries from a queue file\r\n */\r\nexport async function readQueue<T>(queueFile: string): Promise<T[]> {\r\n  try {\r\n    return await readJsonl<T>(queueFile);\r\n  } catch (error) {\r\n    logger.error(`Failed to read queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Write entries to a queue file (overwrites existing content)\r\n */\r\nexport async function writeQueue<T>(queueFile: string, items: T[]): Promise<void> {\r\n  try {\r\n    await withFileLock(queueFile, async () => {\r\n      await ensureDirectory(dirname(queueFile));\r\n\r\n      // Write all items as JSONL\r\n      const content =\r\n        items.map((item) => JSON.stringify(item)).join(\"\\n\") + (items.length > 0 ? \"\\n\" : \"\");\r\n      await writeFile(queueFile, content, \"utf8\");\r\n\r\n      logger.debug(`Wrote ${items.length} items to queue file: ${queueFile}`);\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to write queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Atomically update queue files with a transform function\r\n * Ensures no race condition between read and write\r\n *\r\n * The entire read-modify-write cycle happens inside a lock\r\n */\r\nexport async function atomicUpdateQueue<T>(\r\n  queueFile: string,\r\n  transform: (currentItems: T[]) => T[],\r\n): Promise<void> {\r\n  try {\r\n    await withFileLock(queueFile, async () => {\r\n      // Read current state (inside lock)\r\n      const currentItems = await readJsonl<T>(queueFile);\r\n\r\n      // Apply transformation\r\n      const newItems = transform(currentItems);\r\n\r\n      // Write back (still inside lock)\r\n      await ensureDirectory(dirname(queueFile));\r\n      const content =\r\n        newItems.map((item) => JSON.stringify(item)).join(\"\\n\") + (newItems.length > 0 ? \"\\n\" : \"\");\r\n      await writeFile(queueFile, content, \"utf8\");\r\n\r\n      logger.debug(\r\n        `Atomically updated queue file: ${queueFile} (${currentItems.length}  ${newItems.length} items)`,\r\n      );\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to atomically update queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Clear a queue file (delete it)\r\n */\r\nexport async function clearQueue(queueFile: string): Promise<void> {\r\n  try {\r\n    await withFileLock(queueFile, async () => {\r\n      await deleteFile(queueFile);\r\n      logger.debug(`Cleared queue file: ${queueFile}`);\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to clear queue file ${queueFile}:`, error);\r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Get statistics about queued items\r\n */\r\nexport async function getQueueStats(): Promise<{\r\n  events: number;\r\n  sessions: number;\r\n  messages: number;\r\n}> {\r\n  try {\r\n    // Ensure queue directory exists before reading (defensive programming)\r\n    await ensureDirectory(QUEUE_DIR);\r\n\r\n    const [events, sessions, messages] = await Promise.all([\r\n      countLines(EVENTS_QUEUE_FILE),\r\n      countLines(SESSIONS_QUEUE_FILE),\r\n      countLines(MESSAGES_QUEUE_FILE),\r\n    ]);\r\n\r\n    return { events, sessions, messages };\r\n  } catch (error) {\r\n    logger.error(\"Failed to get queue stats:\", error);\r\n    return { events: 0, sessions: 0, messages: 0 };\r\n  }\r\n}\r\n\r\n/**\r\n * Ensure queue directory exists (call on initialization)\r\n */\r\nexport async function initializeQueue(): Promise<void> {\r\n  try {\r\n    await ensureDirectory(QUEUE_DIR);\r\n    logger.debug(\"Queue directory initialized\");\r\n  } catch (error) {\r\n    logger.error(\"Failed to initialize queue directory:\", error);\r\n    throw error;\r\n  }\r\n}\r\n",
    "/**\r\n * State manager for tracking extraction progress per session\r\n *\r\n * Stores last read line number for each session to enable\r\n * incremental extraction without re-reading entire files\r\n */\r\n\r\nimport { readFile, writeFile } from \"node:fs/promises\";\r\nimport { join } from \"node:path\";\r\nimport { STATE_DIR } from \"../config/constants.js\";\r\nimport { withFileLock } from \"./file-lock.js\";\r\nimport { ensureDirectory } from \"./fs-utils.js\";\r\nimport { logger } from \"./logger.js\";\r\n\r\ninterface SessionState {\r\n  sessionId: string;\r\n  lastReadLine: number;\r\n  lastMessageIndex: number; // Last message_index that was queued\r\n  filePath: string;\r\n}\r\n\r\n/**\r\n * Get state file path for a session\r\n */\r\nfunction getStateFilePath(sessionId: string): string {\r\n  return join(STATE_DIR, `${sessionId}.json`);\r\n}\r\n\r\n/**\r\n * Read session state with file locking to prevent race conditions\r\n */\r\nexport async function readSessionState(sessionId: string): Promise<SessionState | null> {\r\n  try {\r\n    const stateFile = getStateFilePath(sessionId);\r\n\r\n    // Use file lock to prevent reading while another process is writing\r\n    return await withFileLock(stateFile, async () => {\r\n      try {\r\n        const content = await readFile(stateFile, \"utf-8\");\r\n        return JSON.parse(content) as SessionState;\r\n      } catch (error) {\r\n        // State file doesn't exist yet - this is normal for new sessions\r\n        logger.debug(`No state found for session ${sessionId} (new session)`);\r\n        return null;\r\n      }\r\n    });\r\n  } catch (error) {\r\n    logger.debug(`Failed to read state for session ${sessionId}:`, error);\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Write session state with file locking to prevent race conditions\r\n */\r\nexport async function writeSessionState(state: SessionState): Promise<void> {\r\n  try {\r\n    await ensureDirectory(STATE_DIR);\r\n    const stateFile = getStateFilePath(state.sessionId);\r\n\r\n    // Use file lock to ensure atomic read-modify-write\r\n    await withFileLock(stateFile, async () => {\r\n      await writeFile(stateFile, JSON.stringify(state, null, 2), \"utf-8\");\r\n      logger.debug(\r\n        `Updated state for session ${state.sessionId}: lastReadLine=${state.lastReadLine}`,\r\n      );\r\n    });\r\n  } catch (error) {\r\n    logger.error(`Failed to write state for session ${state.sessionId}:`, error);\r\n  }\r\n}\r\n\r\n/**\r\n * Update last read line number and last message index for a session\r\n */\r\nexport async function updateLastReadLine(\r\n  sessionId: string,\r\n  filePath: string,\r\n  lineNumber: number,\r\n  lastMessageIndex: number,\r\n): Promise<void> {\r\n  const newState: SessionState = {\r\n    sessionId,\r\n    lastReadLine: lineNumber,\r\n    lastMessageIndex,\r\n    filePath,\r\n  };\r\n  await writeSessionState(newState);\r\n}\r\n"
  ],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;AAIA;AACA;AAAA,IAIa,oBACA,qBACA,sBAGA,iBACA,WACA,UACA,WACA,oBAGA,cACA,eACA,iBACA,wBACA,mBAGA,mBACA,qBACA,qBAaA,gBAAgB,IAChB,mBAAmB,KAGnB,cAUA,uBAGA,qBAAqB,GAGrB,gCAGA,qBAOA,sBA6BA;AAAA;AAAA,EA7FA,qBAAqB,QAAQ,IAAI,uBAAuB,KAAK,QAAQ,GAAG,SAAS;AAAA,EACjF,sBAAsB,KAAK,oBAAoB,UAAU;AAAA,EACzD,uBAAuB,KAAK,oBAAoB,eAAe;AAAA,EAG/D,kBAAkB,KAAK,oBAAoB,MAAM,cAAc;AAAA,EAC/D,YAAY,KAAK,iBAAiB,OAAO;AAAA,EACzC,WAAW,KAAK,iBAAiB,MAAM;AAAA,EACvC,YAAY,KAAK,iBAAiB,OAAO;AAAA,EACzC,qBAAqB,KAAK,iBAAiB,SAAS,WAAW;AAAA,EAG/D,eAAe,KAAK,iBAAiB,cAAc;AAAA,EACnD,gBAAgB,KAAK,iBAAiB,eAAe;AAAA,EACrD,kBAAkB,KAAK,iBAAiB,YAAY;AAAA,EACpD,yBAAyB,KAAK,iBAAiB,gBAAgB;AAAA,EAC/D,oBAAoB,KAAK,iBAAiB,mBAAmB;AAAA,EAG7D,oBAAoB,KAAK,WAAW,cAAc;AAAA,EAClD,sBAAsB,KAAK,WAAW,qBAAqB;AAAA,EAC3D,sBAAsB,KAAK,WAAW,qBAAqB;AAAA,EAiB3D,eAAe,KAAK,iBAAiB,UAAU;AAAA,EAU/C,wBAAwB,IAAI,KAAK;AAAA,EAMjC,iCAAiC,IAAI,KAAK;AAAA,EAG1C,sBAAsB,KAAK,OAAO;AAAA,EAOlC,uBAAuB,IAAI,KAAK,KAAK,KAAK;AAAA,EA6B1C,4BAA4B,KAAK,KAAK;AAAA;;;AC7FnD;AAQA,eAAsB,eAAe,CAAC,SAAgC;AAAA,EACpE,IAAI;AAAA,IACF,MAAM,KAAK,OAAO;AAAA,IAClB,MAAM;AAAA,IACN,MAAM,MAAM,SAAS,EAAE,WAAW,MAAM,MAAM,IAAM,CAAC;AAAA;AAAA;AAAA;;;ACfzD;AACA,iBAAS;AAYF,SAAS,aAAa,GAAW;AAAA,EACtC,OAAO,IAAI,KAAK,EAAE,YAAY,EAAE,MAAM,GAAG,EAAE;AAAA;AAQtC,SAAS,eAAe,CAAC,WAA2B;AAAA,EACzD,MAAM,UAAU,cAAc;AAAA,EAC9B,OAAO,MAAK,UAAU,GAAG,aAAa,aAAa;AAAA;AASrD,SAAS,qBAAqB,CAAC,UAAkB,WAAgC;AAAA,EAC/E,MAAM,UAAU,IAAI,OAAO,IAAI,yCAAyC;AAAA,EACxE,MAAM,QAAQ,SAAS,MAAM,OAAO;AAAA,EAEpC,IAAI,CAAC,OAAO;AAAA,IACV,OAAO;AAAA,EACT;AAAA,EAEA,MAAM,OAAO,IAAI,KAAK,MAAM,KAAK,YAAY;AAAA,EAC7C,OAAO,OAAO,MAAM,KAAK,QAAQ,CAAC,IAAI,OAAO;AAAA;AAS/C,eAAsB,gBAAgB,CAAC,WAAkC;AAAA,EACvE,MAAM,MAAM,KAAK,IAAI;AAAA,EACrB,MAAM,cAAc,gBAAgB,cAAc;AAAA,EAGlD,IAAI,MAAM,cAAc,qBAAqB;AAAA,IAC3C;AAAA,EACF;AAAA,EAEA,gBAAgB,aAAa;AAAA,EAE7B,IAAI;AAAA,IACF,MAAM,gBAAgB,QAAQ;AAAA,IAC9B,MAAM,QAAQ,MAAM,QAAQ,QAAQ;AAAA,IACpC,MAAM,aAAa,IAAI,KAAK,MAAM,qBAAqB,KAAK,KAAK,KAAK,IAAI;AAAA,IAE1E,WAAW,QAAQ,OAAO;AAAA,MACxB,MAAM,WAAW,sBAAsB,MAAM,SAAS;AAAA,MAEtD,IAAI,YAAY,WAAW,YAAY;AAAA,QACrC,MAAM,WAAW,MAAK,UAAU,IAAI;AAAA,QACpC,IAAI;AAAA,UACF,MAAM,OAAO,QAAQ;AAAA,UACrB,OAAO,OAAO;AAAA,UACd,OAAO,MAAM,iCAAiC,QAAQ,KAAK;AAAA;AAAA,MAE/D;AAAA,IACF;AAAA,IACA,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,8BAA8B,KAAK;AAAA;AAAA;AAAA,IAzE9C,qBACF;AAAA;AAAA,EANJ;AAAA,EACA;AAAA,EACA;AAAA,EAGM,sBAAsB,KAAK,KAAK;AAAA,EAClC,kBAA0C,CAAC;AAAA;;;ACN/C;AACA;AAAA;AAMA,MAAM,OAAO;AAAA,EACH,WAAqB;AAAA,EACZ;AAAA,EAET,SAAmC;AAAA,IACzC,OAAO;AAAA,IACP,MAAM;AAAA,IACN,MAAM;AAAA,IACN,OAAO;AAAA,EACT;AAAA,EAEA,WAAW,CAAC,YAAY,UAAU;AAAA,IAChC,KAAK,YAAY;AAAA;AAAA,EAGnB,QAAQ,CAAC,OAAuB;AAAA,IAC9B,KAAK,WAAW;AAAA;AAAA,OAGJ,YAAW,CAAC,SAAgC;AAAA,IACxD,IAAI;AAAA,MAEF,MAAM,cAAc,gBAAgB,KAAK,SAAS;AAAA,MAClD,MAAM,gBAAgB,QAAQ,WAAW,CAAC;AAAA,MAC1C,MAAM,YAAY,IAAI,KAAK,EAAE,YAAY;AAAA,MACzC,MAAM,WAAW,aAAa,IAAI,cAAc;AAAA,GAAa,OAAO;AAAA,MAGpE,iBAAiB,KAAK,SAAS;AAAA,MAC/B,OAAO,OAAO;AAAA,MAEd,QAAQ,MAAM,gCAAgC,KAAK;AAAA;AAAA;AAAA,EAI/C,SAAS,CAAC,OAA0B;AAAA,IAC1C,OAAO,KAAK,OAAO,UAAU,KAAK,OAAO,KAAK;AAAA;AAAA,EAGhD,KAAK,CAAC,YAAoB,MAAuB;AAAA,IAC/C,IAAI,KAAK,UAAU,OAAO,GAAG;AAAA,MAE3B,KAAK,YAAY,UAAU,WAAW,KAAK,SAAS,IAAI,KAAK,UAAU,IAAI,IAAI,IAAI;AAAA,IACrF;AAAA;AAAA,EAGF,IAAI,CAAC,YAAoB,MAAuB;AAAA,IAC9C,IAAI,KAAK,UAAU,MAAM,GAAG;AAAA,MAE1B,KAAK,YAAY,SAAS,WAAW,KAAK,SAAS,IAAI,KAAK,UAAU,IAAI,IAAI,IAAI;AAAA,IACpF;AAAA;AAAA,EAGF,IAAI,CAAC,YAAoB,MAAuB;AAAA,IAC9C,IAAI,KAAK,UAAU,MAAM,GAAG;AAAA,MAE1B,QAAQ,KAAK,eAAe,WAAW,GAAG,IAAI;AAAA,MAC9C,KAAK,YAAY,SAAS,WAAW,KAAK,SAAS,IAAI,KAAK,UAAU,IAAI,IAAI,IAAI;AAAA,IACpF;AAAA;AAAA,EAGF,KAAK,CAAC,SAAiB,OAAuB;AAAA,IAC5C,IAAI,KAAK,UAAU,OAAO,GAAG;AAAA,MAE3B,QAAQ,MAAM,gBAAgB,WAAW,KAAK;AAAA,MAC9C,KAAK,YACH,UAAU,WAAW,iBAAiB,QAAQ,MAAM,QAAQ,KAAK,UAAU,KAAK,GAClF;AAAA,IACF;AAAA;AAEJ;AAAA,IAEa;AAAA;AAAA,EA7Eb;AAAA,EACA;AAAA,EA4Ea,SAAS,IAAI;AAAA;;;;EC9E1B;AAAA,EACA;AAAA,EACA;AAAA;;;ACAA;AACA,oBAAS,kBAAS;AAClB,0BAAS;;;ACET;AAFA,oBAAS,sBAAS,mBAAU,iBAAM,sBAAQ;AAC1C,iBAAS;;;ACDT;AAFA,oBAAS,8BAAmB;AAC5B,oBAAS;;;ACHT,oBAAS,kBAAS;AAClB;AAEA;AAMA;AACA;AAGA,IAAM,sBAAsB,MAAK,iBAAiB,qBAAqB;AAEvE,IAAM,cAAa,cAAc,YAAY,GAAG;AAChD,IAAM,aAAY,SAAQ,WAAU;AAM7B,SAAS,gBAAgB,CAAC,KAAsB;AAAA,EACrD,IAAI;AAAA,IACF,QAAQ,KAAK,KAAK,CAAC;AAAA,IACnB,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO;AAAA;AAAA;;;ADrBX;AACA;AAWA,IAAM,kBAAkB,IAAI;AAO5B,SAAS,WAAW,CAAC,UAA6B;AAAA,EAChD,OAAO,CAAC,iBAAiB,SAAS,GAAG;AAAA;AASvC,eAAe,eAAe,CAAC,UAAoC;AAAA,EACjE,MAAM,WAAW,GAAG;AAAA,EACpB,MAAM,WAAqB;AAAA,IACzB,KAAK,QAAQ;AAAA,IACb,WAAW,KAAK,IAAI;AAAA,EACtB;AAAA,EAEA,IAAI;AAAA,IAEF,MAAM,gBAAgB,SAAQ,QAAQ,CAAC;AAAA,IAGvC,MAAM,UAAU,UAAU,KAAK,UAAU,QAAQ,GAAG,EAAE,MAAM,KAAK,CAAC;AAAA,IAClE,gBAAgB,IAAI,QAAQ;AAAA,IAC5B,OAAO;AAAA,IACP,OAAO,OAAO;AAAA,IACd,IAAK,MAAgC,SAAS,UAAU;AAAA,MAEtD,MAAM,UAAW,MAAgC;AAAA,MACjD,IAAI,YAAY,YAAY,YAAY,UAAU;AAAA,QAChD,OAAO,MAAM,8BAA8B,aAAa,KAAK;AAAA,MAC/D;AAAA,MACA,MAAM;AAAA,IACR;AAAA,IAGA,IAAI;AAAA,MACF,MAAM,UAAU,MAAM,SAAS,UAAU,MAAM;AAAA,MAC/C,MAAM,eAAyB,KAAK,MAAM,OAAO;AAAA,MAEjD,IAAI,YAAY,YAAY,GAAG;AAAA,QAE7B,OAAO,MAAM,2BAA2B,iBAAiB,aAAa,cAAc;AAAA,QACpF,MAAM,QAAO,QAAQ,EAAE,MAAM,MAAM,EAAE;AAAA,QACrC,OAAO,gBAAgB,QAAQ;AAAA,MACjC;AAAA,MACA,MAAM;AAAA,MAGN,OAAO,MAAM,iBAAiB,+CAA+C;AAAA,MAC7E,MAAM,QAAO,QAAQ,EAAE,MAAM,MAAM,EAAE;AAAA,MACrC,OAAO,gBAAgB,QAAQ;AAAA;AAAA,IAGjC,OAAO;AAAA;AAAA;AAOX,eAAe,eAAe,CAAC,UAAiC;AAAA,EAC9D,MAAM,WAAW,GAAG;AAAA,EACpB,gBAAgB,OAAO,QAAQ;AAAA,EAC/B,MAAM,QAAO,QAAQ,EAAE,MAAM,MAAM,EAAE;AAAA;AAiFvC,eAAsB,YAAe,CAAC,UAAkB,IAAkC;AAAA,EAExF,IAAI,UAAU;AAAA,EACd,OAAO,CAAE,MAAM,gBAAgB,QAAQ,GAAI;AAAA,IACzC,IAAI,EAAE,WAAW,kBAAkB;AAAA,MACjC,MAAM,IAAI,MAAM,8BAA8B,kBAAkB,iBAAiB;AAAA,IACnF;AAAA,IACA,MAAM,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,aAAa,CAAC;AAAA,EACnE;AAAA,EAEA,IAAI;AAAA,IACF,OAAO,MAAM,GAAG;AAAA,YAChB;AAAA,IACA,MAAM,gBAAgB,QAAQ;AAAA;AAAA;;;AD/KlC;AACA;AA8EA,eAAsB,iBAAiB,CAAC,UAAkB,WAAoC;AAAA,EAC5F,MAAM,eAAe,MAAK,cAAc,YAAY,YAAY,gBAAgB;AAAA,EAEhF,IAAI;AAAA,IACF,MAAM,gBAAgB,YAAY;AAAA,IAGlC,OAAO,MAAM,aAAa,cAAc,YAAY;AAAA,MAClD,MAAM,MAAM,KAAK,IAAI;AAAA,MACrB,IAAI,QAAQ;AAAA,MAGZ,IAAI;AAAA,QACF,MAAM,UAAU,MAAM,UAAS,cAAc,OAAO;AAAA,QACpD,MAAM,OAAqB,KAAK,MAAM,OAAO;AAAA,QAG7C,IAAI,MAAM,KAAK,YAAY,MAAM;AAAA,UAE/B,SAAS,KAAK,SAAS,KAAK;AAAA,QAC9B;AAAA,QACA,MAAM;AAAA,MAKR,MAAM,UAAwB;AAAA,QAC5B,WAAW;AAAA,QACX,KAAK,QAAQ;AAAA,QACb;AAAA,MACF;AAAA,MACA,MAAM,WAAU,cAAc,KAAK,UAAU,OAAO,GAAG,OAAO;AAAA,MAE9D,OAAO,MAAM,cAAc,aAAa,qBAAqB,WAAW;AAAA,MACxE,OAAO;AAAA,KACR;AAAA,IACD,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,4BAA4B,KAAK;AAAA,IAC9C,OAAO;AAAA;AAAA;;;AG/HX,iBAAS;AACT,2BAAmB;;ACEnB;AAMA;AACA;;;ADNA;;;AELA;;;ACDA;AAOA;;;ACZA,IAAI,OAAsB,QAAS,GAAG;AAAA,EAClC,SAAS,KAAI,GAAG;AAAA,EAEhB,MAAK,UAAU,OAAO,QAAS,CAAC,WAAW,WAE3C,SAAS;AAAA,IACL,IAAI,YAAiB,WAAG;AAAA,MAAE,UAAU,CAAC;AAAA,IAAG;AAAA,IACxC,IAAI;AAAA,IACJ,IAAI,OAAO,YAAY,YAAY;AAAA,MAC/B,WAAW;AAAA,MACX,UAAU,CAAC;AAAA,IACf,EACK,SAAI,cAAc,SAAS;AAAA,MAC5B,WAAW,QAAQ;AAAA,IACvB;AAAA,IAEA,YAAY,KAAK,UAAU,WAAW,OAAO;AAAA,IAC7C,YAAY,KAAK,UAAU,WAAW,OAAO;AAAA,IAC7C,IAAI,YAAY,KAAK,YAAY,KAAK,SAAS,WAAW,OAAO,CAAC;AAAA,IAClE,IAAI,YAAY,KAAK,YAAY,KAAK,SAAS,WAAW,OAAO,CAAC;AAAA,IAClE,OAAO,KAAK,mBAAmB,WAAW,WAAW,SAAS,QAAQ;AAAA;AAAA,EAE1E,MAAK,UAAU,qBAAqB,QAAS,CAAC,WAAW,WAAW,SAAS,UAAU;AAAA,IACnF,IAAI,QAAQ;AAAA,IACZ,IAAI;AAAA,IACJ,IAAI,OAAO,QAAS,CAAC,OAAO;AAAA,MACxB,QAAQ,MAAM,YAAY,OAAO,OAAO;AAAA,MACxC,IAAI,UAAU;AAAA,QACV,WAAW,QAAS,GAAG;AAAA,UAAE,SAAS,KAAK;AAAA,WAAM,CAAC;AAAA,QAC9C;AAAA,MACJ,EACK;AAAA,QACD,OAAO;AAAA;AAAA;AAAA,IAGf,IAAI,SAAS,UAAU,QAAQ,SAAS,UAAU;AAAA,IAClD,IAAI,aAAa;AAAA,IACjB,IAAI,gBAAgB,SAAS;AAAA,IAC7B,IAAI,QAAQ,iBAAiB,MAAM;AAAA,MAC/B,gBAAgB,KAAK,IAAI,eAAe,QAAQ,aAAa;AAAA,IACjE;AAAA,IACA,IAAI,oBAAoB,KAAK,QAAQ,aAAa,QAAQ,OAAY,YAAI,KAAK;AAAA,IAC/E,IAAI,sBAAsB,KAAK,IAAI,IAAI;AAAA,IACvC,IAAI,WAAW,CAAC,EAAE,QAAQ,IAAI,eAAe,UAAU,CAAC;AAAA,IAExD,IAAI,SAAS,KAAK,cAAc,SAAS,IAAI,WAAW,WAAW,GAAG,OAAO;AAAA,IAC7E,IAAI,SAAS,GAAG,SAAS,KAAK,UAAU,SAAS,KAAK,QAAQ;AAAA,MAE1D,OAAO,KAAK,KAAK,YAAY,SAAS,GAAG,eAAe,WAAW,SAAS,CAAC;AAAA,IACjF;AAAA,IAkBA,IAAI,wBAAwB,WAAW,wBAAwB;AAAA,IAE/D,IAAI,iBAAiB,QAAS,GAAG;AAAA,MAC7B,SAAS,eAAe,KAAK,IAAI,uBAAuB,CAAC,UAAU,EAAG,gBAAgB,KAAK,IAAI,uBAAuB,UAAU,GAAG,gBAAgB,GAAG;AAAA,QAClJ,IAAI,WAAgB;AAAA,QACpB,IAAI,aAAa,SAAS,eAAe,IAAI,UAAU,SAAS,eAAe;AAAA,QAC/E,IAAI,YAAY;AAAA,UAGZ,SAAS,eAAe,KAAK;AAAA,QACjC;AAAA,QACA,IAAI,SAAS;AAAA,QACb,IAAI,SAAS;AAAA,UAET,IAAI,gBAAgB,QAAQ,SAAS;AAAA,UACrC,SAAS,WAAW,KAAK,iBAAiB,gBAAgB;AAAA,QAC9D;AAAA,QACA,IAAI,YAAY,cAAc,WAAW,SAAS,IAAI;AAAA,QACtD,IAAI,CAAC,UAAU,CAAC,WAAW;AAAA,UAGvB,SAAS,gBAAgB;AAAA,UACzB;AAAA,QACJ;AAAA,QAIA,IAAI,CAAC,aAAc,UAAU,WAAW,SAAS,QAAQ,QAAS;AAAA,UAC9D,WAAW,MAAM,UAAU,SAAS,MAAM,OAAO,GAAG,OAAO;AAAA,QAC/D,EACK;AAAA,UACD,WAAW,MAAM,UAAU,YAAY,OAAO,MAAM,GAAG,OAAO;AAAA;AAAA,QAElE,SAAS,MAAM,cAAc,UAAU,WAAW,WAAW,cAAc,OAAO;AAAA,QAClF,IAAI,SAAS,SAAS,KAAK,UAAU,SAAS,KAAK,QAAQ;AAAA,UAEvD,OAAO,KAAK,MAAM,YAAY,SAAS,eAAe,WAAW,SAAS,CAAC,KAAK;AAAA,QACpF,EACK;AAAA,UACD,SAAS,gBAAgB;AAAA,UACzB,IAAI,SAAS,SAAS,KAAK,QAAQ;AAAA,YAC/B,wBAAwB,KAAK,IAAI,uBAAuB,eAAe,CAAC;AAAA,UAC5E;AAAA,UACA,IAAI,SAAS,KAAK,QAAQ;AAAA,YACtB,wBAAwB,KAAK,IAAI,uBAAuB,eAAe,CAAC;AAAA,UAC5E;AAAA;AAAA,MAER;AAAA,MACA;AAAA;AAAA,IAMJ,IAAI,UAAU;AAAA,OACT,SAAS,IAAI,GAAG;AAAA,QACb,WAAW,QAAS,GAAG;AAAA,UACnB,IAAI,aAAa,iBAAiB,KAAK,IAAI,IAAI,qBAAqB;AAAA,YAChE,OAAO,SAAS,SAAS;AAAA,UAC7B;AAAA,UACA,IAAI,CAAC,eAAe,GAAG;AAAA,YACnB,KAAK;AAAA,UACT;AAAA,WACD,CAAC;AAAA,SACN;AAAA,IACN,EACK;AAAA,MACD,OAAO,cAAc,iBAAiB,KAAK,IAAI,KAAK,qBAAqB;AAAA,QACrE,IAAI,MAAM,eAAe;AAAA,QACzB,IAAI,KAAK;AAAA,UACL,OAAO;AAAA,QACX;AAAA,MACJ;AAAA;AAAA;AAAA,EAGR,MAAK,UAAU,YAAY,QAAS,CAAC,MAAM,OAAO,SAAS,WAAW,SAAS;AAAA,IAC3E,IAAI,OAAO,KAAK;AAAA,IAChB,IAAI,QAAQ,CAAC,QAAQ,qBAAqB,KAAK,UAAU,SAAS,KAAK,YAAY,SAAS;AAAA,MACxF,OAAO;AAAA,QACH,QAAQ,KAAK,SAAS;AAAA,QACtB,eAAe,EAAE,OAAO,KAAK,QAAQ,GAAG,OAAc,SAAkB,mBAAmB,KAAK,kBAAkB;AAAA,MACtH;AAAA,IACJ,EACK;AAAA,MACD,OAAO;AAAA,QACH,QAAQ,KAAK,SAAS;AAAA,QACtB,eAAe,EAAE,OAAO,GAAG,OAAc,SAAkB,mBAAmB,KAAK;AAAA,MACvF;AAAA;AAAA;AAAA,EAGR,MAAK,UAAU,gBAAgB,QAAS,CAAC,UAAU,WAAW,WAAW,cAAc,SAAS;AAAA,IAC5F,IAAI,SAAS,UAAU,QAAQ,SAAS,UAAU;AAAA,IAClD,IAAI,SAAS,SAAS,QAAQ,SAAS,SAAS,cAAc,cAAc;AAAA,IAC5E,OAAO,SAAS,IAAI,UAAU,SAAS,IAAI,UAAU,KAAK,OAAO,UAAU,SAAS,IAAI,UAAU,SAAS,IAAI,OAAO,GAAG;AAAA,MACrH;AAAA,MACA;AAAA,MACA;AAAA,MACA,IAAI,QAAQ,mBAAmB;AAAA,QAC3B,SAAS,gBAAgB,EAAE,OAAO,GAAG,mBAAmB,SAAS,eAAe,OAAO,OAAO,SAAS,MAAM;AAAA,MACjH;AAAA,IACJ;AAAA,IACA,IAAI,eAAe,CAAC,QAAQ,mBAAmB;AAAA,MAC3C,SAAS,gBAAgB,EAAE,OAAO,aAAa,mBAAmB,SAAS,eAAe,OAAO,OAAO,SAAS,MAAM;AAAA,IAC3H;AAAA,IACA,SAAS,SAAS;AAAA,IAClB,OAAO;AAAA;AAAA,EAEX,MAAK,UAAU,SAAS,QAAS,CAAC,MAAM,OAAO,SAAS;AAAA,IACpD,IAAI,QAAQ,YAAY;AAAA,MACpB,OAAO,QAAQ,WAAW,MAAM,KAAK;AAAA,IACzC,EACK;AAAA,MACD,OAAO,SAAS,SACR,CAAC,CAAC,QAAQ,cAAc,KAAK,YAAY,MAAM,MAAM,YAAY;AAAA;AAAA;AAAA,EAGjF,MAAK,UAAU,cAAc,QAAS,CAAC,OAAO;AAAA,IAC1C,IAAI,MAAM,CAAC;AAAA,IACX,SAAS,IAAI,EAAG,IAAI,MAAM,QAAQ,KAAK;AAAA,MACnC,IAAI,MAAM,IAAI;AAAA,QACV,IAAI,KAAK,MAAM,EAAE;AAAA,MACrB;AAAA,IACJ;AAAA,IACA,OAAO;AAAA;AAAA,EAGX,MAAK,UAAU,YAAY,QAAS,CAAC,OAAO,SAAS;AAAA,IACjD,OAAO;AAAA;AAAA,EAGX,MAAK,UAAU,WAAW,QAAS,CAAC,OAAO,SAAS;AAAA,IAChD,OAAO,MAAM,KAAK,KAAK;AAAA;AAAA,EAE3B,MAAK,UAAU,OAAO,QAAS,CAAC,OAAO;AAAA,IAKnC,OAAO,MAAM,KAAK,EAAE;AAAA;AAAA,EAExB,MAAK,UAAU,cAAc,QAAS,CAAC,eAEvC,SAAS;AAAA,IACL,OAAO;AAAA;AAAA,EAEX,OAAO,eAAe,MAAK,WAAW,mBAAmB;AAAA,IACrD,KAAK,QAAS,GAAG;AAAA,MACb,OAAO;AAAA;AAAA,IAEX,YAAY;AAAA,IACZ,cAAc;AAAA,EAClB,CAAC;AAAA,EACD,MAAK,UAAU,cAAc,QAAS,CAAC,eAAe,WAAW,WAAW;AAAA,IAGxE,IAAI,aAAa,CAAC;AAAA,IAClB,IAAI;AAAA,IACJ,OAAO,eAAe;AAAA,MAClB,WAAW,KAAK,aAAa;AAAA,MAC7B,gBAAgB,cAAc;AAAA,MAC9B,OAAO,cAAc;AAAA,MACrB,gBAAgB;AAAA,IACpB;AAAA,IACA,WAAW,QAAQ;AAAA,IACnB,IAAI,eAAe,WAAW;AAAA,IAC9B,IAAI,eAAe,GAAG,SAAS,GAAG,SAAS;AAAA,IAC3C,MAAO,eAAe,cAAc,gBAAgB;AAAA,MAChD,IAAI,YAAY,WAAW;AAAA,MAC3B,IAAI,CAAC,UAAU,SAAS;AAAA,QACpB,IAAI,CAAC,UAAU,SAAS,KAAK,iBAAiB;AAAA,UAC1C,IAAI,QAAQ,UAAU,MAAM,QAAQ,SAAS,UAAU,KAAK;AAAA,UAC5D,QAAQ,MAAM,IAAI,QAAS,CAAC,QAAO,GAAG;AAAA,YAClC,IAAI,WAAW,UAAU,SAAS;AAAA,YAClC,OAAO,SAAS,SAAS,OAAM,SAAS,WAAW;AAAA,WACtD;AAAA,UACD,UAAU,QAAQ,KAAK,KAAK,KAAK;AAAA,QACrC,EACK;AAAA,UACD,UAAU,QAAQ,KAAK,KAAK,UAAU,MAAM,QAAQ,SAAS,UAAU,KAAK,CAAC;AAAA;AAAA,QAEjF,UAAU,UAAU;AAAA,QAEpB,IAAI,CAAC,UAAU,OAAO;AAAA,UAClB,UAAU,UAAU;AAAA,QACxB;AAAA,MACJ,EACK;AAAA,QACD,UAAU,QAAQ,KAAK,KAAK,UAAU,MAAM,QAAQ,SAAS,UAAU,KAAK,CAAC;AAAA,QAC7E,UAAU,UAAU;AAAA;AAAA,IAE5B;AAAA,IACA,OAAO;AAAA;AAAA,EAEX,OAAO;AAAA,EACT;AACF,IAAe;;;ACtQf,IAAI,YAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAEH,IAAI,gBAA+B,QAAS,CAAC,QAAQ;AAAA,EACjD,UAAU,gBAAe,MAAM;AAAA,EAC/B,SAAS,cAAa,GAAG;AAAA,IACrB,OAAO,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA;AAAA,EAE/D,OAAO;AAAA,EACT,YAAI;AACC,IAAI,gBAAgB,IAAI;;;ACvBxB,SAAS,mBAAmB,CAAC,MAAM,MAAM;AAAA,EAC5C,IAAI;AAAA,EACJ,KAAK,IAAI,EAAG,IAAI,KAAK,UAAU,IAAI,KAAK,QAAQ,KAAK;AAAA,IACjD,IAAI,KAAK,MAAM,KAAK,IAAI;AAAA,MACpB,OAAO,KAAK,MAAM,GAAG,CAAC;AAAA,IAC1B;AAAA,EACJ;AAAA,EACA,OAAO,KAAK,MAAM,GAAG,CAAC;AAAA;AAEnB,SAAS,mBAAmB,CAAC,MAAM,MAAM;AAAA,EAC5C,IAAI;AAAA,EAIJ,IAAI,CAAC,QAAQ,CAAC,QAAQ,KAAK,KAAK,SAAS,MAAM,KAAK,KAAK,SAAS,IAAI;AAAA,IAClE,OAAO;AAAA,EACX;AAAA,EACA,KAAK,IAAI,EAAG,IAAI,KAAK,UAAU,IAAI,KAAK,QAAQ,KAAK;AAAA,IACjD,IAAI,KAAK,KAAK,UAAU,IAAI,OAAO,KAAK,KAAK,UAAU,IAAI,KAAK;AAAA,MAC5D,OAAO,KAAK,MAAM,CAAC,CAAC;AAAA,IACxB;AAAA,EACJ;AAAA,EACA,OAAO,KAAK,MAAM,CAAC,CAAC;AAAA;AAEjB,SAAS,aAAa,CAAC,QAAQ,WAAW,WAAW;AAAA,EACxD,IAAI,OAAO,MAAM,GAAG,UAAU,MAAM,KAAK,WAAW;AAAA,IAChD,MAAM,MAAM,UAAU,OAAO,KAAK,UAAU,MAAM,GAAG,6BAA6B,EAAE,OAAO,KAAK,UAAU,SAAS,GAAG,iBAAiB,CAAC;AAAA,EAC5I;AAAA,EACA,OAAO,YAAY,OAAO,MAAM,UAAU,MAAM;AAAA;AAE7C,SAAS,aAAa,CAAC,QAAQ,WAAW,WAAW;AAAA,EACxD,IAAI,CAAC,WAAW;AAAA,IACZ,OAAO,SAAS;AAAA,EACpB;AAAA,EACA,IAAI,OAAO,MAAM,CAAC,UAAU,MAAM,KAAK,WAAW;AAAA,IAC9C,MAAM,MAAM,UAAU,OAAO,KAAK,UAAU,MAAM,GAAG,2BAA2B,EAAE,OAAO,KAAK,UAAU,SAAS,GAAG,iBAAiB,CAAC;AAAA,EAC1I;AAAA,EACA,OAAO,OAAO,MAAM,GAAG,CAAC,UAAU,MAAM,IAAI;AAAA;AAEzC,SAAS,YAAY,CAAC,QAAQ,WAAW;AAAA,EAC5C,OAAO,cAAc,QAAQ,WAAW,EAAE;AAAA;AAEvC,SAAS,YAAY,CAAC,QAAQ,WAAW;AAAA,EAC5C,OAAO,cAAc,QAAQ,WAAW,EAAE;AAAA;AAEvC,SAAS,cAAc,CAAC,SAAS,SAAS;AAAA,EAC7C,OAAO,QAAQ,MAAM,GAAG,aAAa,SAAS,OAAO,CAAC;AAAA;AAG1D,SAAS,YAAY,CAAC,GAAG,GAAG;AAAA,EAExB,IAAI,SAAS;AAAA,EACb,IAAI,EAAE,SAAS,EAAE,QAAQ;AAAA,IACrB,SAAS,EAAE,SAAS,EAAE;AAAA,EAC1B;AAAA,EACA,IAAI,OAAO,EAAE;AAAA,EACb,IAAI,EAAE,SAAS,EAAE,QAAQ;AAAA,IACrB,OAAO,EAAE;AAAA,EACb;AAAA,EAIA,IAAI,MAAM,MAAM,IAAI;AAAA,EACpB,IAAI,IAAI;AAAA,EACR,IAAI,KAAK;AAAA,EACT,SAAS,IAAI,EAAG,IAAI,MAAM,KAAK;AAAA,IAC3B,IAAI,EAAE,MAAM,EAAE,IAAI;AAAA,MACd,IAAI,KAAK,IAAI;AAAA,IACjB,EACK;AAAA,MACD,IAAI,KAAK;AAAA;AAAA,IAEb,OAAO,IAAI,KAAK,EAAE,MAAM,EAAE,IAAI;AAAA,MAC1B,IAAI,IAAI;AAAA,IACZ;AAAA,IACA,IAAI,EAAE,MAAM,EAAE,IAAI;AAAA,MACd;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,IAAI;AAAA,EACJ,SAAS,IAAI,OAAQ,IAAI,EAAE,QAAQ,KAAK;AAAA,IACpC,OAAO,IAAI,KAAK,EAAE,MAAM,EAAE,IAAI;AAAA,MAC1B,IAAI,IAAI;AAAA,IACZ;AAAA,IACA,IAAI,EAAE,MAAM,EAAE,IAAI;AAAA,MACd;AAAA,IACJ;AAAA,EACJ;AAAA,EACA,OAAO;AAAA;AAcJ,SAAS,UAAU,CAAC,QAAQ;AAAA,EAY/B,IAAI;AAAA,EACJ,KAAK,IAAI,OAAO,SAAS,EAAG,KAAK,GAAG,KAAK;AAAA,IACrC,IAAI,CAAC,OAAO,GAAG,MAAM,IAAI,GAAG;AAAA,MACxB;AAAA,IACJ;AAAA,EACJ;AAAA,EACA,OAAO,OAAO,UAAU,IAAI,CAAC;AAAA;AAE1B,SAAS,SAAS,CAAC,QAAQ;AAAA,EAE9B,IAAI,QAAQ,OAAO,MAAM,MAAM;AAAA,EAC/B,OAAO,QAAQ,MAAM,KAAK;AAAA;;;AC9H9B,IAAI,aAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAqBH,IAAI,oBAAoB;AAyBxB,IAAI,8BAA8B,IAAI,OAAO,IAAI,OAAO,mBAAmB,YAAY,EAAE,OAAO,mBAAmB,GAAG,GAAG,IAAI;AAC7H,IAAI,WAA0B,QAAS,CAAC,QAAQ;AAAA,EAC5C,WAAU,WAAU,MAAM;AAAA,EAC1B,SAAS,SAAQ,GAAG;AAAA,IAChB,OAAO,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA;AAAA,EAE/D,UAAS,UAAU,SAAS,QAAS,CAAC,MAAM,OAAO,SAAS;AAAA,IACxD,IAAI,QAAQ,YAAY;AAAA,MACpB,OAAO,KAAK,YAAY;AAAA,MACxB,QAAQ,MAAM,YAAY;AAAA,IAC9B;AAAA,IACA,OAAO,KAAK,KAAK,MAAM,MAAM,KAAK;AAAA;AAAA,EAEtC,UAAS,UAAU,WAAW,QAAS,CAAC,OAAO,SAAS;AAAA,IACpD,IAAI,YAAiB,WAAG;AAAA,MAAE,UAAU,CAAC;AAAA,IAAG;AAAA,IACxC,IAAI;AAAA,IACJ,IAAI,QAAQ,eAAe;AAAA,MACvB,IAAI,YAAY,QAAQ;AAAA,MACxB,IAAI,UAAU,gBAAgB,EAAE,eAAe,QAAQ;AAAA,QACnD,MAAM,IAAI,MAAM,wDAAwD;AAAA,MAC5E;AAAA,MACA,QAAQ,MAAM,KAAK,UAAU,QAAQ,KAAK,GAAG,QAAS,CAAC,SAAS;AAAA,QAAE,OAAO,QAAQ;AAAA,OAAU;AAAA,IAC/F,EACK;AAAA,MACD,QAAQ,MAAM,MAAM,2BAA2B,KAAK,CAAC;AAAA;AAAA,IAEzD,IAAI,SAAS,CAAC;AAAA,IACd,IAAI,WAAW;AAAA,IACf,MAAM,QAAQ,QAAS,CAAC,MAAM;AAAA,MAC1B,IAAK,KAAM,KAAK,IAAI,GAAG;AAAA,QACnB,IAAI,YAAY,MAAM;AAAA,UAClB,OAAO,KAAK,IAAI;AAAA,QACpB,EACK;AAAA,UACD,OAAO,KAAK,OAAO,IAAI,IAAI,IAAI;AAAA;AAAA,MAEvC,EACK,SAAI,YAAY,QAAS,KAAM,KAAK,QAAQ,GAAG;AAAA,QAChD,IAAI,OAAO,OAAO,SAAS,MAAM,UAAU;AAAA,UACvC,OAAO,KAAK,OAAO,IAAI,IAAI,IAAI;AAAA,QACnC,EACK;AAAA,UACD,OAAO,KAAK,WAAW,IAAI;AAAA;AAAA,MAEnC,EACK;AAAA,QACD,OAAO,KAAK,IAAI;AAAA;AAAA,MAEpB,WAAW;AAAA,KACd;AAAA,IACD,OAAO;AAAA;AAAA,EAEX,UAAS,UAAU,OAAO,QAAS,CAAC,QAAQ;AAAA,IAMxC,OAAO,OAAO,IAAI,QAAS,CAAC,OAAO,GAAG;AAAA,MAClC,IAAI,KAAK,GAAG;AAAA,QACR,OAAO;AAAA,MACX,EACK;AAAA,QACD,OAAO,MAAM,QAAS,QAAS,EAAE;AAAA;AAAA,KAExC,EAAE,KAAK,EAAE;AAAA;AAAA,EAEd,UAAS,UAAU,cAAc,QAAS,CAAC,SAAS,SAAS;AAAA,IACzD,IAAI,CAAC,WAAW,QAAQ,mBAAmB;AAAA,MACvC,OAAO;AAAA,IACX;AAAA,IACA,IAAI,WAAW;AAAA,IAGf,IAAI,YAAY;AAAA,IAChB,IAAI,WAAW;AAAA,IACf,QAAQ,QAAQ,QAAS,CAAC,QAAQ;AAAA,MAC9B,IAAI,OAAO,OAAO;AAAA,QACd,YAAY;AAAA,MAChB,EACK,SAAI,OAAO,SAAS;AAAA,QACrB,WAAW;AAAA,MACf,EACK;AAAA,QACD,IAAI,aAAa,UAAU;AAAA,UACvB,gCAAgC,UAAU,UAAU,WAAW,MAAM;AAAA,QACzE;AAAA,QACA,WAAW;AAAA,QACX,YAAY;AAAA,QACZ,WAAW;AAAA;AAAA,KAElB;AAAA,IACD,IAAI,aAAa,UAAU;AAAA,MACvB,gCAAgC,UAAU,UAAU,WAAW,IAAI;AAAA,IACvE;AAAA,IACA,OAAO;AAAA;AAAA,EAEX,OAAO;AAAA,EACT,YAAI;AACC,IAAI,WAAW,IAAI;AAW1B,SAAS,+BAA+B,CAAC,WAAW,UAAU,WAAW,SAAS;AAAA,EA0C9E,IAAI,YAAY,WAAW;AAAA,IACvB,IAAI,cAAc,UAAU,SAAS,KAAK;AAAA,IAC1C,IAAI,cAAc,WAAW,SAAS,KAAK;AAAA,IAC3C,IAAI,cAAc,UAAU,UAAU,KAAK;AAAA,IAC3C,IAAI,cAAc,WAAW,UAAU,KAAK;AAAA,IAC5C,IAAI,WAAW;AAAA,MACX,IAAI,iBAAiB,oBAAoB,aAAa,WAAW;AAAA,MACjE,UAAU,QAAQ,cAAc,UAAU,OAAO,aAAa,cAAc;AAAA,MAC5E,SAAS,QAAQ,aAAa,SAAS,OAAO,cAAc;AAAA,MAC5D,UAAU,QAAQ,aAAa,UAAU,OAAO,cAAc;AAAA,IAClE;AAAA,IACA,IAAI,SAAS;AAAA,MACT,IAAI,iBAAiB,oBAAoB,aAAa,WAAW;AAAA,MACjE,QAAQ,QAAQ,cAAc,QAAQ,OAAO,aAAa,cAAc;AAAA,MACxE,SAAS,QAAQ,aAAa,SAAS,OAAO,cAAc;AAAA,MAC5D,UAAU,QAAQ,aAAa,UAAU,OAAO,cAAc;AAAA,IAClE;AAAA,EACJ,EACK,SAAI,WAAW;AAAA,IAOhB,IAAI,WAAW;AAAA,MACX,IAAI,KAAK,UAAU,UAAU,KAAK;AAAA,MAClC,UAAU,QAAQ,UAAU,MAAM,UAAU,GAAG,MAAM;AAAA,IACzD;AAAA,IACA,IAAI,SAAS;AAAA,MACT,IAAI,KAAK,UAAU,QAAQ,KAAK;AAAA,MAChC,QAAQ,QAAQ,QAAQ,MAAM,UAAU,GAAG,MAAM;AAAA,IACrD;AAAA,EAEJ,EACK,SAAI,aAAa,SAAS;AAAA,IAC3B,IAAI,YAAY,UAAU,QAAQ,KAAK,GAAG,aAAa,UAAU,SAAS,KAAK,GAAG,WAAW,WAAW,SAAS,KAAK;AAAA,IAGtH,IAAI,aAAa,oBAAoB,WAAW,UAAU;AAAA,IAC1D,SAAS,QAAQ,aAAa,SAAS,OAAO,UAAU;AAAA,IAIxD,IAAI,WAAW,oBAAoB,aAAa,WAAW,UAAU,GAAG,QAAQ;AAAA,IAChF,SAAS,QAAQ,aAAa,SAAS,OAAO,QAAQ;AAAA,IACtD,QAAQ,QAAQ,cAAc,QAAQ,OAAO,WAAW,QAAQ;AAAA,IAGhE,UAAU,QAAQ,cAAc,UAAU,OAAO,WAAW,UAAU,MAAM,GAAG,UAAU,SAAS,SAAS,MAAM,CAAC;AAAA,EACtH,EACK,SAAI,SAAS;AAAA,IAId,IAAI,kBAAkB,UAAU,QAAQ,KAAK;AAAA,IAC7C,IAAI,mBAAmB,WAAW,SAAS,KAAK;AAAA,IAChD,IAAI,UAAU,eAAe,kBAAkB,eAAe;AAAA,IAC9D,SAAS,QAAQ,aAAa,SAAS,OAAO,OAAO;AAAA,EACzD,EACK,SAAI,WAAW;AAAA,IAIhB,IAAI,oBAAoB,WAAW,UAAU,KAAK;AAAA,IAClD,IAAI,mBAAmB,UAAU,SAAS,KAAK;AAAA,IAC/C,IAAI,UAAU,eAAe,mBAAmB,gBAAgB;AAAA,IAChE,SAAS,QAAQ,aAAa,SAAS,OAAO,OAAO;AAAA,EACzD;AAAA;AAEJ,IAAI,qBAAoC,QAAS,CAAC,QAAQ;AAAA,EACtD,WAAU,qBAAoB,MAAM;AAAA,EACpC,SAAS,mBAAkB,GAAG;AAAA,IAC1B,OAAO,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA;AAAA,EAE/D,oBAAmB,UAAU,WAAW,QAAS,CAAC,OAAO;AAAA,IAMrD,IAAI,QAAQ,IAAI,OAAO,cAAc,OAAO,mBAAmB,qBAAqB,EAAE,OAAO,mBAAmB,GAAG,GAAG,IAAI;AAAA,IAC1H,OAAO,MAAM,MAAM,KAAK,KAAK,CAAC;AAAA;AAAA,EAElC,OAAO;AAAA,EACT,YAAI;AACC,IAAI,qBAAqB,IAAI;;;AC1SpC,IAAI,aAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAGH,IAAI,WAA0B,QAAS,CAAC,QAAQ;AAAA,EAC5C,WAAU,WAAU,MAAM;AAAA,EAC1B,SAAS,SAAQ,GAAG;AAAA,IAChB,IAAI,QAAQ,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA,IAChE,MAAM,WAAW;AAAA,IACjB,OAAO;AAAA;AAAA,EAEX,UAAS,UAAU,SAAS,QAAS,CAAC,MAAM,OAAO,SAAS;AAAA,IAQxD,IAAI,QAAQ,kBAAkB;AAAA,MAC1B,IAAI,CAAC,QAAQ,kBAAkB,CAAC,KAAK,SAAS;AAAA,CAAI,GAAG;AAAA,QACjD,OAAO,KAAK,KAAK;AAAA,MACrB;AAAA,MACA,IAAI,CAAC,QAAQ,kBAAkB,CAAC,MAAM,SAAS;AAAA,CAAI,GAAG;AAAA,QAClD,QAAQ,MAAM,KAAK;AAAA,MACvB;AAAA,IACJ,EACK,SAAI,QAAQ,sBAAsB,CAAC,QAAQ,gBAAgB;AAAA,MAC5D,IAAI,KAAK,SAAS;AAAA,CAAI,GAAG;AAAA,QACrB,OAAO,KAAK,MAAM,GAAG,EAAE;AAAA,MAC3B;AAAA,MACA,IAAI,MAAM,SAAS;AAAA,CAAI,GAAG;AAAA,QACtB,QAAQ,MAAM,MAAM,GAAG,EAAE;AAAA,MAC7B;AAAA,IACJ;AAAA,IACA,OAAO,OAAO,UAAU,OAAO,KAAK,MAAM,MAAM,OAAO,OAAO;AAAA;AAAA,EAElE,OAAO;AAAA,EACT,YAAI;AACC,IAAI,WAAW,IAAI;AASnB,SAAS,QAAQ,CAAC,OAAO,SAAS;AAAA,EACrC,IAAI,QAAQ,iBAAiB;AAAA,IAEzB,QAAQ,MAAM,QAAQ,SAAS;AAAA,CAAI;AAAA,EACvC;AAAA,EACA,IAAI,WAAW,CAAC,GAAG,mBAAmB,MAAM,MAAM,WAAW;AAAA,EAE7D,IAAI,CAAC,iBAAiB,iBAAiB,SAAS,IAAI;AAAA,IAChD,iBAAiB,IAAI;AAAA,EACzB;AAAA,EAEA,SAAS,IAAI,EAAG,IAAI,iBAAiB,QAAQ,KAAK;AAAA,IAC9C,IAAI,OAAO,iBAAiB;AAAA,IAC5B,IAAI,IAAI,KAAK,CAAC,QAAQ,gBAAgB;AAAA,MAClC,SAAS,SAAS,SAAS,MAAM;AAAA,IACrC,EACK;AAAA,MACD,SAAS,KAAK,IAAI;AAAA;AAAA,EAE1B;AAAA,EACA,OAAO;AAAA;;;ACjFX,IAAI,aAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAEH,IAAI,eAA8B,QAAS,CAAC,QAAQ;AAAA,EAChD,WAAU,eAAc,MAAM;AAAA,EAC9B,SAAS,aAAY,GAAG;AAAA,IACpB,OAAO,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA;AAAA,EAE/D,cAAa,UAAU,WAAW,QAAS,CAAC,OAAO;AAAA,IAC/C,OAAO,MAAM,MAAM,mBAAmB;AAAA;AAAA,EAE1C,OAAO;AAAA,EACT,YAAI;AACC,IAAI,eAAe,IAAI;;;AC1B9B,IAAI,aAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAEH,IAAI,UAAyB,QAAS,CAAC,QAAQ;AAAA,EAC3C,WAAU,UAAS,MAAM;AAAA,EACzB,SAAS,QAAO,GAAG;AAAA,IACf,OAAO,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA;AAAA,EAE/D,SAAQ,UAAU,WAAW,QAAS,CAAC,OAAO;AAAA,IAC1C,OAAO,MAAM,MAAM,eAAe;AAAA;AAAA,EAEtC,OAAO;AAAA,EACT,YAAI;AACC,IAAI,UAAU,IAAI;;;AC1BzB,IAAI,aAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAGH,IAAI,WAA0B,QAAS,CAAC,QAAQ;AAAA,EAC5C,WAAU,WAAU,MAAM;AAAA,EAC1B,SAAS,SAAQ,GAAG;AAAA,IAChB,IAAI,QAAQ,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA,IAChE,MAAM,WAAW;AAAA,IACjB,OAAO;AAAA;AAAA,EAEX,OAAO,eAAe,UAAS,WAAW,mBAAmB;AAAA,IACzD,KAAK,QAAS,GAAG;AAAA,MAGb,OAAO;AAAA;AAAA,IAEX,YAAY;AAAA,IACZ,cAAc;AAAA,EAClB,CAAC;AAAA,EACD,UAAS,UAAU,YAAY,QAAS,CAAC,OAAO,SAAS;AAAA,IACrD,MAAmC,sBAAmC,mBAAb,OAAK,SAA2B,oBAAoB,OAAY,YAAI,QAAS,CAAC,GAAG,GAAG;AAAA,MAAE,OAAO,OAAO,MAAM,cAAc,uBAAuB;AAAA,QAAO;AAAA,IAC/M,OAAO,OAAO,UAAU,WAAW,QAAQ,KAAK,UAAU,aAAa,OAAO,MAAM,MAAM,iBAAiB,GAAG,MAAM,IAAI;AAAA;AAAA,EAE5H,UAAS,UAAU,SAAS,QAAS,CAAC,MAAM,OAAO,SAAS;AAAA,IACxD,OAAO,OAAO,UAAU,OAAO,KAAK,MAAM,KAAK,QAAQ,cAAc,IAAI,GAAG,MAAM,QAAQ,cAAc,IAAI,GAAG,OAAO;AAAA;AAAA,EAE1H,OAAO;AAAA,EACT,YAAI;AACC,IAAI,WAAW,IAAI;AAMnB,SAAS,YAAY,CAAC,KAAK,OAAO,kBAAkB,UAAU,KAAK;AAAA,EACtE,QAAQ,SAAS,CAAC;AAAA,EAClB,mBAAmB,oBAAoB,CAAC;AAAA,EACxC,IAAI,UAAU;AAAA,IACV,MAAM,SAAS,QAAQ,YAAY,KAAK,KAAK,GAAG;AAAA,EACpD;AAAA,EACA,IAAI;AAAA,EACJ,KAAK,IAAI,EAAG,IAAI,MAAM,QAAQ,KAAK,GAAG;AAAA,IAClC,IAAI,MAAM,OAAO,KAAK;AAAA,MAClB,OAAO,iBAAiB;AAAA,IAC5B;AAAA,EACJ;AAAA,EACA,IAAI;AAAA,EACJ,IAAyB,OAAO,UAAU,SAAS,KAAK,GAAG,MAAvD,kBAA0D;AAAA,IAC1D,MAAM,KAAK,GAAG;AAAA,IACd,mBAAmB,IAAI,MAAM,IAAI,MAAM;AAAA,IACvC,iBAAiB,KAAK,gBAAgB;AAAA,IACtC,KAAK,IAAI,EAAG,IAAI,IAAI,QAAQ,KAAK,GAAG;AAAA,MAChC,iBAAiB,KAAK,aAAa,IAAI,IAAI,OAAO,kBAAkB,UAAU,OAAO,CAAC,CAAC;AAAA,IAC3F;AAAA,IACA,MAAM,IAAI;AAAA,IACV,iBAAiB,IAAI;AAAA,IACrB,OAAO;AAAA,EACX;AAAA,EACA,IAAI,OAAO,IAAI,QAAQ;AAAA,IACnB,MAAM,IAAI,OAAO;AAAA,EACrB;AAAA,EACA,IAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;AAAA,IACzC,MAAM,KAAK,GAAG;AAAA,IACd,mBAAmB,CAAC;AAAA,IACpB,iBAAiB,KAAK,gBAAgB;AAAA,IACtC,IAAI,aAAa,CAAC;AAAA,IAClB,IAAI;AAAA,IACJ,KAAK,SAAS,KAAK;AAAA,MAEf,IAAI,OAAO,UAAU,eAAe,KAAK,KAAK,KAAK,GAAG;AAAA,QAClD,WAAW,KAAK,KAAK;AAAA,MACzB;AAAA,IACJ;AAAA,IACA,WAAW,KAAK;AAAA,IAChB,KAAK,IAAI,EAAG,IAAI,WAAW,QAAQ,KAAK,GAAG;AAAA,MACvC,QAAQ,WAAW;AAAA,MACnB,iBAAiB,SAAS,aAAa,IAAI,QAAQ,OAAO,kBAAkB,UAAU,KAAK;AAAA,IAC/F;AAAA,IACA,MAAM,IAAI;AAAA,IACV,iBAAiB,IAAI;AAAA,EACzB,EACK;AAAA,IACD,mBAAmB;AAAA;AAAA,EAEvB,OAAO;AAAA;;;AClGX,IAAI,aAAyC,QAAS,GAAG;AAAA,EACrD,IAAI,gBAAgB,QAAS,CAAC,GAAG,GAAG;AAAA,IAChC,gBAAgB,OAAO,kBAClB,EAAE,WAAW,CAAC,EAAE,aAAa,SAAS,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,GAAE,YAAY;AAAA,SACvE,QAAS,CAAC,IAAG,IAAG;AAAA,MAAE,SAAS,KAAK;AAAA,QAAG,IAAI,OAAO,UAAU,eAAe,KAAK,IAAG,CAAC;AAAA,UAAG,GAAE,KAAK,GAAE;AAAA;AAAA,IAChG,OAAO,cAAc,GAAG,CAAC;AAAA;AAAA,EAE7B,OAAO,QAAS,CAAC,GAAG,GAAG;AAAA,IACnB,IAAI,OAAO,MAAM,cAAc,MAAM;AAAA,MACjC,MAAM,IAAI,UAAU,yBAAyB,OAAO,CAAC,IAAI,+BAA+B;AAAA,IAC5F,cAAc,GAAG,CAAC;AAAA,IAClB,SAAS,EAAE,GAAG;AAAA,MAAE,KAAK,cAAc;AAAA;AAAA,IACnC,EAAE,YAAY,MAAM,OAAO,OAAO,OAAO,CAAC,KAAK,GAAG,YAAY,EAAE,WAAW,IAAI;AAAA;AAAA,EAEpF;AAEH,IAAI,YAA2B,QAAS,CAAC,QAAQ;AAAA,EAC7C,WAAU,YAAW,MAAM;AAAA,EAC3B,SAAS,UAAS,GAAG;AAAA,IACjB,OAAO,WAAW,QAAQ,OAAO,MAAM,MAAM,SAAS,KAAK;AAAA;AAAA,EAE/D,WAAU,UAAU,WAAW,QAAS,CAAC,OAAO;AAAA,IAC5C,OAAO,MAAM,MAAM;AAAA;AAAA,EAEvB,WAAU,UAAU,OAAO,QAAS,CAAC,OAAO;AAAA,IACxC,OAAO;AAAA;AAAA,EAEX,WAAU,UAAU,cAAc,QAAS,CAAC,OAAO;AAAA,IAC/C,OAAO;AAAA;AAAA,EAEX,OAAO;AAAA,EACT,YAAI;AACC,IAAI,YAAY,IAAI;;;ACzB3B;AACA;;;AVMA;;;ADLA;;;AYDA;;;AdYA;;;AeXA;AAYA;AACA;;;ACbA;AAEA;AACA;;;AhB4HA,eAAsB,oBAAoB,CACxC,YACuF;AAAA,EACvF,IAAI;AAAA,IAEF,MAAM,gBAAgB,WAAW,QAAQ,OAAO,GAAG;AAAA,IACnD,MAAM,cAAc,MAAK,qBAAqB,aAAa;AAAA,IAE3D,OAAO,MAAM,kCAAkC,aAAa;AAAA,IAG5D,IAAI;AAAA,MACF,MAAM,MAAK,WAAW;AAAA,MACtB,MAAM;AAAA,MACN,OAAO,KAAK,gCAAgC,aAAa;AAAA,MACzD,OAAO;AAAA;AAAA,IAIT,QAAQ,sBAAY,MAAa;AAAA,IACjC,MAAM,UAAU,MAAM,SAAQ,WAAW;AAAA,IACzC,MAAM,aAAa,QAAQ,OAAO,CAAC,MAAM,EAAE,SAAS,QAAQ,CAAC;AAAA,IAE7D,IAAI,WAAW,WAAW,GAAG;AAAA,MAC3B,OAAO,KAAK,6BAA6B,aAAa;AAAA,MACtD,OAAO;AAAA,IACT;AAAA,IAGA,IAAI,iBAAiB,WAAW;AAAA,IAChC,IAAI,iBAAiB;AAAA,IAErB,WAAW,QAAQ,YAAY;AAAA,MAC7B,MAAM,WAAW,MAAK,aAAa,IAAI;AAAA,MACvC,MAAM,QAAQ,MAAM,MAAK,QAAQ;AAAA,MACjC,IAAI,MAAM,UAAU,gBAAgB;AAAA,QAClC,iBAAiB,MAAM;AAAA,QACvB,iBAAiB;AAAA,MACnB;AAAA,IACF;AAAA,IAEA,MAAM,mBAAmB,MAAK,aAAa,cAAc;AAAA,IACzD,MAAM,YAAY,SAAS,gBAAgB,QAAQ;AAAA,IACnD,MAAM,YAAY,MAAM,MAAK,gBAAgB;AAAA,IAE7C,OAAO,EAAE,kBAAkB,WAAW,UAAU;AAAA,IAChD,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,qCAAqC,KAAK;AAAA,IACvD,OAAO;AAAA;AAAA;;;AJxKX;AAGA,IAAM,cAAa,eAAc,YAAY,GAAG;AAChD,IAAM,aAAY,SAAQ,WAAU;AAEpC,eAAe,IAAI,GAAG;AAAA,EACpB,MAAM,aAAa,QAAQ,IAAI;AAAA,EAE/B,IAAI;AAAA,IACF,IAAI,CAAC,YAAY;AAAA,MACf,OAAO,KAAK,4BAA4B;AAAA,MACxC,QAAQ,KAAK,CAAC;AAAA,IAChB;AAAA,IAEA,MAAM,cAAc,MAAM,qBAAqB,UAAU;AAAA,IACzD,IAAI,CAAC,aAAa;AAAA,MAChB,OAAO,KAAK,kCAAkC;AAAA,MAC9C,QAAQ,KAAK,CAAC;AAAA,IAChB;AAAA,IAEA,QAAQ,kBAAkB,cAAc;AAAA,IAGxC,MAAM,kBAAkB,eAAe,SAAS;AAAA,IAGhD,sBAAsB,WAAW,gBAAgB;AAAA,IACjD,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,6CAA6C,KAAK;AAAA,IAE/D,QAAQ,KAAK,CAAC;AAAA;AAAA;AAQlB,SAAS,qBAAqB,CAAC,WAAmB,kBAAgC;AAAA,EAChF,IAAI;AAAA,IACF,MAAM,uBAAuB,MAAK,YAAW,0BAA0B;AAAA,IAGvE,MAAM,QAAQ,MAAM,QAAQ,CAAC,sBAAsB,WAAW,gBAAgB,GAAG;AAAA,MAC/E,UAAU;AAAA,MACV,OAAO;AAAA,MACP,KAAK,QAAQ;AAAA,IACf,CAAC;AAAA,IAGD,MAAM,MAAM;AAAA,IACZ,OAAO,OAAO;AAAA,IACd,OAAO,MAAM,sCAAsC,KAAK;AAAA;AAAA;AAK5D,KAAK,EAAE,MAAM,CAAC,UAAU;AAAA,EACtB,QAAQ,MAAM,gCAAgC,KAAK;AAAA,EACnD,QAAQ,KAAK,CAAC;AAAA,CACf;",
  "debugId": "D18F75993CA8FE7364756E2164756E21",
  "names": []
}